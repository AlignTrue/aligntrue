id: local-rules
version: 1.0.0
spec_version: "1"
sections:
  - heading: Debugging
    content: >

      # Systematic debugging workflow


      This align establishes systematic debugging practices: reproduce
      deterministically, reduce to the smallest failing case, classify failures,
      inspect evidence, and prevent recurrence with tests.


      ## Debugging workflow


      Follow this systematic workflow for complex debugging sessions:


      1. **Reproduce deterministically** before changing code

      2. **Reduce** to smallest failing case

      3. **Classify** the failure type

      4. **Inspect evidence**, not vibes

      5. **Trace data flow** and invariants

      6. **Bisect** recent changes if new

      7. **Write failing test** before fixing

      8. **Minimal change** that passes

      9. **Clean up** and harden

      10. **Validate broadly** before merge


      ## Reproduction scripts


      **Requirement:** Non-trivial bugs require a minimal reproduction script.


      Create a reproduction script showing the exact failure:


      - Format: `scripts/repro*.{sh,ts,js,py}`

      - Minimal and runnable

      - Documents the failure condition

      - Used in regression testing


      ## Regression prevention


      **Requirement:** Bug fix PRs must include regression tests.


      Before implementing the fix:


      - Add a failing test that proves the bug

      - Make the test pass with the fix

      - Ensure test would catch this bug in future


      ## Temp artifact policy


      Prefix AI-generated debug artifacts with `temp-`:


      - Store under logs/ or local scratch

      - Add to .gitignore

      - Never commit

      - Examples: `temp-debug-output.txt`, `temp-trace.log`, `temp-profile.json`


      **Error:** Debug artifacts committed to repo without `temp-` prefix are
      not allowed.


      ## Root cause communication


      In PR description, explain:


      - **Root cause** - What was broken and why

      - **Minimal fix** - The smallest change that resolves it

      - **Prevention** - How test prevents recurrence


      ## Common debugging mistakes


      - Changing code before reproducing

      - Not reducing to minimal case

      - Fixing symptoms instead of root cause

      - Forgetting regression test

      - Committing debug artifacts


      ## Tools and Techniques


      - Use debuggers instead of print statements

      - Bisect for finding introduction point

      - Profile for performance issues

      - Mock external systems deterministically

      - Capture state snapshots for analysis
    level: 2
    fingerprint: aligns-base-base-debugging
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/debugging.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-debugging
          version: 1.0.0
          summary:
            "Systematic debugging workflow: reproduce, reduce, root-cause, fix,
            prevent"
          tags:
            - debugging
            - troubleshooting
            - determinism
            - paved-road
          title: Debugging
    scope: personal
  - heading: Docs
    content: >

      # Docs-as-Code Baseline


      This align establishes documentation standards: readme-first approach,
      CI-enforced checks, copy-pasteable snippets, and minimal DRY-based
      references.


      ## Core principles


      - **Readme-first**: Single authoritative README at repo root

      - **Change behavior? Change docs**: Update documentation in the same PR

      - **Copy-pasteable snippets**: Verified, minimal, runnable examples

      - **DRY and reference-first**: Link to docs, don't duplicate

      - **CI-enforced**: Lint, link-check, spell-check in CI


      ## Repository structure


      Short-form at top level:


      - `README.md` - Main entry point

      - `CONTRIBUTING.md` - How to contribute

      - `CHANGELOG.md` - Changes by version

      - `LICENSE` - Licensing info


      Longer docs under `docs/`:


      - One topic per page

      - Keep pages concise and focused

      - Cross-reference with relative links


      ## README Requirements


      Every repository must have a README with:


      **Required:** Quickstart section with runnable commands


      - Clear, copy-pasteable commands

      - Minimal dependencies

      - Shows immediate value


      **Example sections:**


      - What it is

      - How to try it

      - How to run tests

      - How to build

      - How to contribute


      ## Behavioral changes


      **Requirement:** Behavior changes must include documentation updates.


      If you modify functionality:


      - Update README or relevant docs in same PR

      - Keep examples current

      - Remove obsolete guidance

      - Verify links still work


      ## CI Enforcement


      Automated checks in every PR:


      - **Lint markdown** - Consistent formatting

      - **Check links** - No broken references

      - **Spell-check** - Where configured

      - **Generated sites** - Built but not committed to repo


      ## Release notes


      Maintain changelog with:


      - **CHANGELOG.md** or generate from Conventional Commits

      - Link releases to relevant docs

      - Group changes by type: Added, Changed, Fixed, Removed

      - Clear, user-facing descriptions


      ## Documentation anti-patterns


      - Outdated examples

      - Broken links

      - Duplicated content

      - Over-technical README

      - Docs that need a tutorial to understand
    level: 2
    fingerprint: aligns-base-base-docs
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/docs.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-docs
          version: 1.0.0
          summary:
            "Docs-as-code baseline: readme-first, CI-enforced, minimal and
            testable"
          tags:
            - documentation
            - readme
            - changelog
            - paved-road
          title: Docs
    scope: personal
  - heading: Global
    content: >

      # Global baseline for AI-assisted repos


      This align establishes paved-road commands and consistent workflow
      patterns for AI-assisted repositories. It complements docs, testing, and
      TDD aligns while deferring to security requirements.


      ## Core principles


      - Establish paved-road commands and use them consistently

      - Keep PRs focused and small

      - Require CI gates on every PR (tests + lint)

      - Enforce deterministic behavior

      - Update docs when behavior changes

      - Keep generated artifacts out of VCS


      ## PR and Commit Discipline


      Use Conventional Commits format for all commit messages:


      ```

      type(scope): description


      Examples:

      - feat: add server pagination

      - fix(auth): resolve token expiry issue

      - docs: update API reference

      ```


      Keep one cohesive change per PR. CI must pass before merge.


      ## CI Gates Required


      Every repository must have CI workflow configuration:


      - Tests must run on every PR

      - Linting must pass before merge

      - Missing CI workflow configuration is an error


      Add CI workflow in `.github/workflows/` that runs tests and lints on every
      PR.


      ## Version control hygiene


      Keep generated artifacts out of version control:


      - Add `dist/`, `build/`, `out/`, `.tsbuildinfo` to `.gitignore`

      - Remove any accidentally committed build artifacts

      - Verify with: `git ls-files | grep -E
      '(dist/|build/|out/|\\.tsbuildinfo)'` (should return nothing)


      ## Deterministic behavior


      Ensure reproducible builds and behavior:


      - Pin tool versions in package managers

      - Seed randomness in tests

      - Use stable ordering for collections

      - Delegate supply-chain specifics to security align


      ## Documentation updates


      - Update docs and examples when interfaces change

      - Reference other aligns using @ notation

      - Keep README and guides in sync with code


      ## Output contract


      For significant changes:


      1. Summary of change

      2. Rationale

      3. Updated rule text only

      4. Impacted areas/precedence

      5. Tests/examples

      6. Conflict check


      ## Examples


      **Good:** Run tests and lint in CI; block merge on failure


      **Bad:** Merge first and fix tests later
    level: 2
    fingerprint: aligns-base-base-global
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/global.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-global
          version: 1.0.0
          summary:
            "Global baseline for AI-assisted repos: CI gates, contribution
            workflow, deterministic behavior"
          tags:
            - global
            - baseline
            - ci
            - paved-road
          title: Global
    scope: personal
  - heading: Rule Authoring
    content: >

      # Rule authoring guideline


      Guidelines for writing clear, actionable, and maintainable rules with
      explicit scope and precedence.


      ## Core Principles


      - **Write for the Agent** - Imperative, actionable, deterministic

      - **One topic per rule** - Focused scope

      - **Declare scope and exclusions explicitly** - Where does this apply?

      - **Lead with hard constraints** - Most important requirements first

      - **Encode precedence** - If conflicts possible, state it


      ## Rule Structure


      ### Header


      - `id` - Unique identifier (e.g., `aligns/base/base-testing`)

      - `version` - Semantic version

      - `summary` - One-line description

      - `tags` - Searchable tags

      - `spec_version` - AlignTrue spec version


      ### Metadata


      - `scope` - Where rule applies:
        - `applies_to` - Glob patterns
        - `includes` - Additional files
        - `excludes` - Excluded patterns

      ### Body


      - `rules` - Machine-checkable rules with severity

      - `notes` - Clarifications for maintainers

      - `guidance` - Extended documentation


      ## Precedence Encoding


      Use explicit verbs in notes field:


      - **"overrides @target"** - Takes precedence over target

      - **"defers to @target"** - Target takes precedence

      - **"complements @target"** - Work together without conflict


      Example:


      ```

      Precedence: overrides @base-global, complements @base-testing, defers to
      @base-security

      ```


      ## Best Practices


      - Keep rules ≤500 lines - Split large rules

      - Add minimal examples - Show expected output

      - Prefer paved-road patterns - Over prohibitions

      - Reference other rules with @ notation

      - Keep diffs minimal - Only change what's necessary

      - Remove obsolete parts - Don't accumulate cruft


      ## Writing Guidelines


      **For agents:**


      - Use imperative language: "Add", "Remove", "Ensure"

      - Be specific: "Add @ts-ignore comment" not "Fix type issue"

      - Include examples: "Example: `export { config as default }`"


      **For humans:**


      - Explain the why

      - Link to standards or RFCs

      - Document exceptions and their reasons

      - Keep notes short and clear


      ## Rule Topics


      Recommended rule topics (avoid mixing):


      - Code quality (linting, style)

      - Testing and determinism

      - Documentation and README

      - Security and secrets

      - Performance and profiling

      - Accessibility

      - Compatibility and versions

      - File organization

      - Dependencies


      ## Conflict Resolution


      If your rule might conflict:


      1. Declare precedence in notes

      2. Add conditional sections for conflicts

      3. Reference related rules by @ notation

      4. Include examples of precedence in guidance
    level: 2
    fingerprint: aligns-base-base-rule-authoring
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/rule-authoring.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-rule-authoring
          version: 1.0.0
          summary:
            "Rule authoring guideline: clear scope, actionable directives, explicit
            precedence"
          tags:
            - meta
            - rule-authoring
            - governance
            - paved-road
          title: Rule Authoring
    scope: personal
  - heading: Security
    content: >

      # Security and Compliance Baseline


      Security standards: never commit secrets, control dependencies, enforce
      compliance, and build with least privilege.


      ## Core principles


      - **Never commit secrets** - Treat repo as public

      - **Control dependencies** - Lockfiles and audit required

      - **Enforce license compliance** - Approved licenses only

      - **Run static analysis** - SAST in CI

      - **Build with least privilege** - Limited access and provenance

      - **Keep data and logs safe** - No production data in tests


      ## Secrets management


      **Requirement:** Pre-commit and CI scans required.


      Never commit:


      - API keys, tokens, or passwords

      - Database credentials

      - Private encryption keys

      - SSH keys or certificates

      - OAuth secrets


      **If leaked:**


      1. Revoke immediately

      2. Rotate credentials

      3. Add regression check to prevent recurrence

      4. Document in security incident tracking


      ## Supply chain security


      Require:


      - **Lockfiles** for all package managers
        - `package-lock.json`, `pnpm-lock.yaml`, `yarn.lock`
        - `Cargo.lock`, `poetry.lock`, `Gemfile.lock`
      - **Pinned versions** - No floating ranges in production

      - **No floating ranges** - `^`, `~`, `*`, `latest` forbidden

      - **Audit on every PR** - `pnpm audit`, `cargo audit`, etc.

      - **Only approved registries** - Block public registry if private required


      Maintenance:


      - **Schedule regular updates** - Weekly or monthly

      - **Test updates** before merging

      - **Document security updates** in changelog


      ## Dependency audit


      **Requirement:** High and critical vulnerabilities must be resolved.


      Run audits:


      ```bash

      pnpm audit --audit-level=high

      npm audit

      cargo audit

      pip-audit

      ```


      **Resolution options:**


      1. Update the package

      2. Add explicit waiver with tracking issue

      3. Remove the dependency if unused


      ## License compliance


      Check third-party licenses:


      - **Block disallowed licenses** - GPL in proprietary code, etc.

      - **Document exceptions** - With justification

      - **Use license-check tools** - SPDX compliance


      ## Static application security testing (SAST)


      In CI:


      - **High findings block** - No merge

      - **Scan all branches** - PRs and main

      - **Surface reports** - As artifacts

      - **Fix or waive** - With issue tracking


      ## Environment configuration


      **Requirement:** `.env.example` documents required variables.


      Template with placeholder values:


      ```

      API_KEY=your-api-key-here

      DATABASE_URL=postgres://user:pass@localhost/db

      DEBUG=false

      ```


      For runtime:


      - Store secrets in approved manager (Vault, KMS, cloud provider)

      - Never hardcode

      - Rotate regularly


      ## Build and Container Security


      - **CI with least privilege** - Limited permissions

      - **Pinned base images** - No `latest` tags

      - **Generate SBOM** - Software Bill of Materials per release

      - **Sign artifacts** - When enabled

      - **Scan containers** - For vulnerabilities


      ## Data safety


      - **No production data** in tests

      - **Redact secrets/PII** in logs

      - **Follow data classification** - Internal vs public

      - **Cleanup** - Remove temporary test data

      - **Backup** - Secure backups with encryption


      ## CI Gates


      - **Block merge on scan failures** - No exceptions without review

      - **Surface reports** - Make findings visible

      - **Keep logs secret-free** - Redact before storage

      - **Audit access** - Track who reviewed waivers
    level: 2
    fingerprint: aligns-base-base-security
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/security.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-security
          version: 1.0.0
          summary:
            "Security and compliance: secrets, dependencies, supply chain, least
            privilege"
          tags:
            - security
            - compliance
            - secrets
            - supply-chain
            - paved-road
          title: Security
    scope: personal
  - heading: TDD
    content: >

      # Test-Driven Development Guide


      Test-driven development workflow: red-green-refactor, design from tests,
      and emergent architecture.


      ## TDD Workflow


      The TDD cycle:


      1. **Red** - Write failing test

      2. **Green** - Simplest code that passes

      3. **Refactor** - Improve without changing behavior

      4. **Repeat** - For each behavior


      ## Benefits


      - **Design emerges** from requirements

      - **Fewer bugs** - Tested from the start

      - **Confidence** - Comprehensive test coverage

      - **Documentation** - Tests show usage

      - **Faster debugging** - Failures caught immediately


      ## Small steps


      Keep steps tiny:


      - One assertion per test

      - Focus on single behavior

      - Make tests fail before passing

      - Refactor safely with tests passing


      **Avoid:**


      - Skipping red-phase

      - Large leaps in green-phase

      - Mixing refactoring with new code

      - Testing implementation details


      ## Design from Tests


      Tests shape design:


      - **Hard to test** - Design is likely poor

      - **Simple to test** - Design is likely good

      - **Tests are first client** - What would users need?

      - **Dependencies come later** - Inject what you need


      If tests are hard to write:


      - Reconsider responsibilities

      - Check for tight coupling

      - Look for hidden assumptions

      - Redesign, don't force tests


      ## Test organization


      - **Organize by domain**, not type

      - **Describe behavior**, not implementation

      - **Mirror production structure** in test structure

      - **Keep tests near code** - Same directory or `tests/` folder


      ## Mocking and Doubles


      - **Mock external dependencies** - HTTP, databases, filesystems

      - **Spy on behavior** - Track calls, arguments

      - **Stub returns** - Controlled, predictable responses

      - **Test real units** - Don't mock the code under test


      ## Refactoring discipline


      Safe refactoring:


      1. **Tests pass** (green phase)

      2. **Make small changes** - Rename, extract, move

      3. **Run tests after each change** - Catch mistakes immediately

      4. **Revert if needed** - Git diff shows exactly what changed

      5. **Commit** - Before next feature


      ## Emerging architecture


      Don't design upfront:


      - **Let tests guide structure** - What's natural to test?

      - **Refactor to patterns** - Not into patterns

      - **DRY emerges** - Through refactoring

      - **Boundaries become clear** - Through mocking and testing


      ## Common TDD mistakes


      - **Writing all tests first** - Defeats incremental design

      - **Tests too large** - Hard to diagnose failures

      - **Testing implementation** - Should test behavior only

      - **Skipping refactor** - Code gets messy

      - **Mocking too much** - Lose integration coverage

      - **Stubborn design** - Refactor when tests make it hard


      ## Integration with Team


      - **Code review tests** - Are they good tests?

      - **Pair on hard problems** - TDD with a partner

      - **Review design** - Emerging from tests

      - **Retrospective** - What could be simpler?
    level: 2
    fingerprint: aligns-base-base-tdd
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/tdd.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-tdd
          version: 1.0.0
          summary:
            "Test-driven development: red-green-refactor, small steps, design from
            tests"
          tags:
            - tdd
            - testing
            - design
            - paved-road
          title: TDD
    scope: personal
  - heading: Testing
    content: >

      # Testing baseline


      This align establishes testing standards for fast, deterministic, and
      useful tests. It complements the global baseline and TDD practices while
      deferring to security requirements.


      ## 5-Question Test Decision


      Before adding a test:


      1. Has this broken in CI or real usage?

      2. Is this a public contract or critical behavior?

      3. Can a unit test prove it deterministically?

      4. Will it remain fast and stable?

      5. Is maintenance worth it?


      ## Test pyramid


      - **Default to unit tests** - Fast, isolated, deterministic

      - **Use integration only for cross-cutting seams** - Database, API
      boundaries

      - **Minimal e2e** - Only where system seams require it


      Prefer unit over integration over e2e. Add more unit tests if pyramid is
      imbalanced.


      ## Determinism requirements


      Tests must be deterministic:


      - **No real network** - Use fakes or mocks

      - **No filesystem side effects** - Use in-memory or temp directories

      - **No clocks or randomness without fakes** - Freeze time, seed randomness

      - **Stub boundaries** - Replace external systems with fakes

      - **No sleeps for synchronization** - Wait on explicit conditions with
      timeouts


      **Error:** Sleep-based synchronization (`sleep`, `setTimeout`,
      `time.sleep`, `Thread.sleep`) is not allowed in tests. Wait on explicit
      conditions with timeouts instead.


      ## Speed requirements


      Target sub-second per test:


      - **Fast tests** - Most tests should run in <100ms

      - **Investigate tests >1s** - Optimize or use isolated units

      - **Use local fakes** - Instead of spinning up real services


      ## Structure


      - **Organize by type:** `tests/unit/`, `tests/integration/`, `tests/e2e/`

      - **One behavioral topic per test file**

      - **Name files after behavior under test:** `user-auth.test.ts`, not
      `test1.ts`


      ## Assertions


      - **Prove behavior, not implementation** - Test what, not how

      - **Prefer public interfaces** - Avoid testing private methods

      - **Observable outcomes** - Assert on side effects and return values


      ## Fixtures


      - **Keep small and local** - Near the tests that use them

      - **Prefer builders/factories** - Over large JSON fixtures

      - **Golden files only for stable outputs** - Screenshots, API responses


      ## External systems


      - **Use fakes or emulators** - Database, queue, cache, HTTP

      - **Replace real services** - testcontainers, in-memory equivalents

      - **Isolate true e2e** - Keep minimal, run separately


      ## Flakiness


      - **Don't mark flaky by default** - Fix or delete instead

      - **Quarantine with issue link** - `skip("Flaky: #123")` with link

      - **Short timebox** - Fix within 1-2 sprints or delete

      - **Fix or delete** - Don't accumulate skipped tests


      **Error:** Flaky tests without issue links are not allowed. Add issue link
      (`// Flaky: https://github.com/.../issues/123`) or fix/delete the test.


      ## Coverage


      - **Enforce threshold in CI** - Typically 70-80%

      - **Don't chase 100%** - Focus on critical paths and public APIs

      - **Block CI on threshold miss** - If coverage drops below configured
      threshold


      ## CI Integration


      - **Block on test failures** - No merge if tests fail

      - **Publish test reports** - For visibility and trends

      - **Fail on coverage threshold miss** - If configured


      Run tests with: `[[plug:test.cmd]]`


      For coverage reporting: `[[plug:test.cmd]] --coverage`
    level: 2
    fingerprint: aligns-base-base-testing
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/testing.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-testing
          version: 1.0.0
          summary:
            "Testing baseline: fast, deterministic, useful tests with clear
            strategy"
          tags:
            - testing
            - quality
            - determinism
            - paved-road
          plugs:
            slots:
              test.cmd:
                description: Command to run tests
                format: command
                required: true
                example: pnpm test
          title: Testing
    scope: personal
  - heading: Typescript
    content: >

      # TypeScript Strict Mode Guide


      TypeScript standards: strict mode, comprehensive type coverage, input
      validation at boundaries, and minimal `any`.


      ## Core principles


      - **Strict mode is the baseline** - All strict flags enabled

      - **Types are documentation** - Keep types clear and obvious

      - **Validate at boundaries** - APIs, filesystems, external inputs

      - **Avoid `any`** - Use proper types or `unknown`

      - **Tight tsconfig** - Minimal escape hatches


      ## TypeScript Configuration


      Recommended `tsconfig.json`:


      ```json

      {
        "compilerOptions": {
          "strict": true,
          "noImplicitAny": true,
          "strictNullChecks": true,
          "strictFunctionTypes": true,
          "strictBindCallApply": true,
          "strictPropertyInitialization": true,
          "noImplicitThis": true,
          "alwaysStrict": true,
          "noUnusedLocals": true,
          "noUnusedParameters": true,
          "noImplicitReturns": true,
          "noFallthroughCasesInSwitch": true,
          "noUncheckedIndexedAccess": true,
          "exactOptionalPropertyTypes": true,
          "module": "esnext",
          "target": "es2020",
          "skipLibCheck": true,
          "forceConsistentCasingInFileNames": true
        }
      }

      ```


      ## Type coverage


      - **Public APIs fully typed** - Exported functions, classes, types

      - **Avoid `any` at all costs** - Use `unknown` if you must

      - **Type function parameters and returns** - No implicit types

      - **Type class properties** - Initialize or declare in constructor

      - **Export types for public APIs** - Consumers need them


      ## Validation at Boundaries


      **Requirement:** Validate all external inputs.


      Boundaries:


      - **API endpoints** - Validate request bodies with Zod

      - **File I/O** - Parse and validate content

      - **Environment variables** - Parse with defaults

      - **User input** - Always validate and sanitize

      - **Database queries** - Type results


      **Pattern:**


      ```typescript

      import { z } from "zod";


      const userSchema = z.object({
        id: z.number(),
        name: z.string(),
        email: z.string().email(),
      });


      export async function getUser(data: unknown): User {
        return userSchema.parse(data);
      }

      ```


      ## Union types and discriminated unions


      **Use discriminated unions for error handling:**


      ```typescript

      type Result<T> = { ok: true; value: T } | { ok: false; error: Error };

      ```


      **Avoid optional boolean:**


      ```typescript

      // ❌ Bad

      const result: { isError?: boolean; value?: T } = ...;


      // ✅ Good

      type Result<T> =
        | { type: "success"; value: T }
        | { type: "error"; error: string };
      ```


      ## Type inference


      - **Prefer inference** where type is obvious

      - **Explicit types** for public APIs

      - **Annotate function parameters** - Let returns infer


      ```typescript

      // ✅ Good: infer return type

      export function computeHash(input: string) {
        return crypto.createHash("sha256").update(input).digest("hex");
      }


      // ✅ Good: explicit for clarity

      export function authenticate(token: string): User | null {
        // ...
      }

      ```


      ## Generics


      - **Use sparingly** - Only when needed

      - **Constrain generics** - `<T extends Base>`

      - **Name clearly** - `T`, `K`, `V` are fine for short functions

      - **Document type parameters** in JSDoc


      ## Any and Unknown


      **Never use `any`** unless:


      - Legacy migration

      - Dynamic JSON with explicit runtime parsing

      - Third-party library with poor types


      **Use `unknown` instead:**


      ```typescript

      // ❌ Bad

      function process(input: any) {
        return input.value;
      }


      // ✅ Good

      function process(input: unknown): string {
        if (typeof input === "object" && input !== null && "value" in input) {
          return String(input.value);
        }
        throw new Error("Invalid input");
      }

      ```


      ## Const assertions


      - **Use `as const`** for literal types

      - **Preserve shape** - Arrays, objects, strings

      - **Avoid spreading const** - Types widen


      ```typescript

      const DIRECTIONS = ["north", "south", "east", "west"] as const;

      type Direction = (typeof DIRECTIONS)[number]; // "north" | "south" |
      "east" | "west"

      ```


      ## ESLint + TypeScript


      Recommended rules:


      - `@typescript-eslint/no-explicit-any` - Warn

      - `@typescript-eslint/no-unused-vars` - Error

      - `@typescript-eslint/explicit-function-return-types` - Error for public
      APIs

      - `@typescript-eslint/no-non-null-assertion` - Error (use optional
      chaining)


      ## Common patterns


      ### Optional chaining and nullish coalescing


      ```typescript

      // ✅ Safe property access

      const name = user?.profile?.name ?? "Anonymous";


      // ❌ Avoid

      const name = user!.profile!.name || "Anonymous";

      ```


      ### Type narrowing


      ```typescript

      if (typeof input === "string") {
        // input is narrowed to string
      }


      if (input instanceof Error) {
        // input is narrowed to Error
      }

      ```


      ### Exhaustive checks


      ```typescript

      function handle(result: Result<T>): void {
        if (result.ok) {
          console.log(result.value);
        } else {
          console.error(result.error);
        }
        // TypeScript ensures all cases covered
      }

      ```


      ## Type performance


      - **Avoid recursive types** - Can slow type-checking

      - **Avoid deep unions** - Limit to practical depth

      - **Check compilation time** - `tsc --diagnostics`

      - **Use `skipLibCheck`** - Trust library types


      ## Type checking


      Run type checking with: `[[plug:lint.cmd]]`


      Configure TypeScript in: `[[plug:tsconfig.file]]`
    level: 2
    fingerprint: aligns-base-base-typescript
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/typescript.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-typescript
          version: 1.0.0
          summary:
            "TypeScript strict mode: tight types, comprehensive checks, input
            validation at boundaries"
          tags:
            - typescript
            - types
            - quality
            - paved-road
          plugs:
            slots:
              tsconfig.file:
                description: Path to TypeScript configuration file
                format: file
                required: false
                example: tsconfig.json
              lint.cmd:
                description: Command to run TypeScript type checking
                format: command
                required: false
                example: pnpm tsc --noEmit
          title: Typescript
    scope: personal
  - heading: Web Quality
    content: >

      # Web quality baseline


      Web standards: accessibility, performance, resilience, and mobile-first
      design.


      ## Accessibility (a11y)


      **WCAG 2.1 Level AA minimum:**


      - **Keyboard navigation** - All functions accessible by keyboard

      - **Color contrast** - 4.5:1 for normal text, 3:1 for large text

      - **Alt text** - For all images and complex graphics

      - **Semantic HTML** - `<button>`, `<label>`, `<nav>`, etc.

      - **ARIA only when semantic markup insufficient** - Use native elements
      first


      **Testing:**


      - Screen reader testing (NVDA, JAWS, VoiceOver)

      - Axe DevTools automated checks

      - Keyboard-only navigation

      - Color contrast analyzer


      ## Performance


      **Mobile-first metrics (p75):**


      - **LCP** - Largest Contentful Paint ≤ 2.5s

      - **INP** - Interaction to Next Paint ≤ 200ms

      - **CLS** - Cumulative Layout Shift ≤ 0.1

      - **TTFB** - Time to First Byte ≤ 800ms


      **Budgets per route:**


      - **JavaScript** - ≤150 KB gzipped

      - **CSS** - ≤50 KB gzipped

      - **Hero image** - ≤200 KB

      - **Fonts** - ≤150 KB total


      **Techniques:**


      - Image optimization and lazy loading

      - Code splitting and dynamic imports

      - Service workers for offline support

      - Resource hints (preload, prefetch, dns-prefetch)


      ## Responsive Design


      - **Mobile-first** - Start with mobile, enhance for larger screens

      - **Flexible layouts** - Use CSS grid and flexbox

      - **Responsive images** - `srcset` and `sizes`

      - **Touch-friendly** - 44×44px minimum tap targets

      - **Typography scaling** - `clamp()` for fluid scaling


      ## Form Accessibility


      - **Label all inputs** - `<label for="id">`

      - **Error messages** - Clear, associated with inputs

      - **Focus management** - Visible focus indicator

      - **Validation** - Client and server side

      - **Success feedback** - Confirm submission


      ## Navigation


      - **Skip links** - Jump to main content

      - **Breadcrumbs** - Show location in site hierarchy

      - **Consistent navigation** - Same location and behavior

      - **Clear current page** - Highlight active link

      - **Logical link text** - "Learn more" is bad, "Learn more about pricing"
      is good


      ## Mobile Experience


      - **Viewport meta tag** - `<meta name="viewport"
      content="width=device-width, initial-scale=1">`

      - **Touch targets** - 44×44px minimum

      - **Mobile menu** - Accessible hamburger menu

      - **Avoid pop-ups** - Use modals sparingly

      - **Test on real devices** - Not just browser emulation


      ## Resilience


      - **Graceful degradation** - Works without JavaScript

      - **Error pages** - 404, 500, offline states

      - **Loading states** - Show progress for slow operations

      - **Retry logic** - For failed requests

      - **Offline support** - Service worker caching


      ## SEO


      - **Semantic HTML** - Proper heading hierarchy

      - **Meta tags** - Title, description, canonical

      - **Open Graph** - Social media previews

      - **Structured data** - Schema.org markup

      - **XML sitemap** - For discovery

      - **robots.txt** - Crawling directives


      ## Security


      - **HTTPS only** - Secure transport

      - **CSP headers** - Content Security Policy

      - **CORS headers** - Cross-Origin Resource Sharing

      - **XSS prevention** - Escape output, use framework defaults

      - **CSRF protection** - Token validation


      ## Testing


      - **Lighthouse CI** - Automated performance checks

      - **Axe automation** - Accessibility scanning

      - **Visual regression** - Screenshot comparisons

      - **E2E on real devices** - Verifying mobile experience

      - **Accessibility audit** - Manual review


      ## Deployment Checklist


      - [ ] Lighthouse score ≥90 (desktop), ≥80 (mobile)

      - [ ] No accessibility violations (Axe)

      - [ ] Meta tags complete and correct

      - [ ] Sitemap submitted to search engines

      - [ ] robots.txt configured

      - [ ] Analytics configured

      - [ ] Error tracking configured

      - [ ] Performance monitoring enabled
    level: 2
    fingerprint: aligns-base-base-web-quality
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/web_quality.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/base/base-web-quality
          version: 1.0.0
          summary:
            "Web quality baseline: accessibility, performance, resilience,
            mobile-first"
          tags:
            - web
            - accessibility
            - performance
            - quality
            - paved-road
          title: Web Quality
    scope: personal
  - heading: Nextjs APP Router
    content: >

      # Next.js App Router Guide


      Best practices for Next.js App Router: server components by default,
      explicit caching strategies, validated server actions, and colocated route
      files.


      ## Core principles


      1. **Server Components by default** - Only use Client Components for
      interactivity or browser APIs

      2. **Client only for interaction** - useState, useEffect, useRef, browser
      APIs

      3. **Validate at boundaries** - Cache reads, revalidate on writes

      4. **Deterministic routing** - Metadata and routing determined at build
      time

      5. **Keep files small** - Focused, easy-to-understand components


      ## File layout


      File organization:


      - Use `(group)` folders to organize routes logically

      - Colocate `loading.tsx`, `error.tsx`, `not-found.tsx` near routes

      - **No default exports** in `lib/` shared code

      - Use named exports only in shared libraries


      ## Server components vs client components


      **Default to Server Components:**


      - Serve HTML directly

      - Access databases and secrets safely

      - Keep dependencies private

      - Reduce JavaScript sent to browser


      **Client Components only when you need:**


      - `useState`, `useContext`, `useReducer`, `useCallback`

      - `useEffect`, `useLayoutEffect`, `useRef`

      - Browser APIs: localStorage, geolocation, etc.


      **Pattern: Thin Client Wrapper**


      Wrap Server Components with minimal Client logic.


      ## Data fetching and caching


      Reads should be cacheable and explicit:


      - **Cacheable reads**: Set `revalidate` or `fetchCache`

      - **Dynamic-only when necessary**: Use `noStore()` for truly dynamic data

      - **Revalidate after mutations**: Use `revalidateTag()` or
      `revalidatePath()`

      - **Cache fetch by default**: `fetch()` is cached by default in Server
      Components


      ## Server actions for mutations


      Server Actions require:


      - **Validate inputs** with Zod or similar schema validation

      - **Mutate**, then **revalidate** with tags or paths

      - **Return small Result objects** - Errors as fields, not thrown

      - **No long-running operations** - Keep to <30 seconds


      ## Error handling


      - `error.tsx` - Client Component boundary handler

      - `loading.tsx` - Suspense-like loading UI (doesn't fetch)

      - `not-found.tsx` - 404 page component

      - Use `throw notFound()` for 404s


      ## Metadata and SEO


      - **Static metadata** when possible

      - **generateMetadata()** for dynamic pages

      - `next/font` for font optimization

      - `next/image` for all images


      ## Common pitfalls


      - Marking entire route trees with `'use client'`

      - Forgetting to set `revalidate` or `fetchCache` on pages

      - Default exports in `lib/` shared code

      - Storing auth tokens in localStorage

      - Not validating Server Action inputs
    level: 2
    fingerprint: aligns-stacks-nextjs-app-router
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/nextjs_app_router.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/stacks/nextjs-app-router
          version: 1.0.0
          summary:
            "Best practices for Next.js App Router: server/client boundaries,
            caching, data fetching"
          tags:
            - nextjs
            - react
            - app-router
            - paved-road
          title: Nextjs APP Router
    scope: personal
  - heading: Vercel Deployments
    content: >

      # Vercel deployment guide


      Best practices for deploying Next.js apps on Vercel: environment
      management, performance optimization, and reliability.


      ## Environment configuration


      **Three tiers:**


      - **Development** - Local `vercel dev` and preview environment

      - **Preview** - Ephemeral previews on each PR

      - **Production** - Main branch deployment


      Secrets management:


      - Server-only secrets - No prefix, stored as JSON

      - Client-visible - Prefix with `NEXT_PUBLIC_`

      - Pull locally - `vercel env pull .env.local`


      **Never hardcode secrets:**


      ```javascript

      // ❌ Bad

      const API_KEY = "sk-1234567890";


      // ✅ Good

      const API_KEY = process.env.API_KEY;

      ```


      ## Build optimization


      **Output format:**


      - Set `output: "standalone"` for smaller deployments

      - Enable compression in next.config.js

      - Analyze bundle size with `@next/bundle-analyzer`


      **Build settings:**


      - Region: Closest to users

      - Node version: Latest LTS

      - Install command: `pnpm install --frozen-lockfile`

      - Build command: `pnpm build`

      - Output directory: `.next`


      ## Environment variables


      **Tier strategy:**


      ```

      NEXT_PUBLIC_API_URL=https://api.example.com   # All tiers

      API_KEY=sk-xxx                                  # Server-only

      DATABASE_URL=postgres://...                     # Server-only

      ```


      **Hierarchy:**


      1. Environment tier settings

      2. Project-level secrets

      3. Team-level secrets

      4. Local `.env.local` (not committed)


      ## Performance optimization


      **Core Web Vitals targets:**


      - **LCP** ≤ 2.5s - Largest paint

      - **INP** ≤ 200ms - Interaction response

      - **CLS** ≤ 0.1 - Layout shift

      - **TTFB** ≤ 800ms - Time to first byte


      **Vercel tools:**


      - **Analytics** - Real user metrics

      - **Web Vitals** - Field data

      - **Lighthouse** - Lab data in CI


      **Optimization:**


      - Preload critical resources

      - Image optimization with `next/image`

      - Code splitting and lazy loading

      - Cache headers strategy


      ## ISR and Revalidation


      **Incremental Static Regeneration:**


      ```typescript

      export const revalidate = 3600; // 1 hour

      ```


      **On-demand revalidation:**


      ```typescript

      import { revalidatePath } from "next/cache";


      export async function updatePost(id: string) {
        // ... update data ...
        revalidatePath(`/posts/${id}`);
      }

      ```


      ## Error handling and monitoring


      **Error page:**


      - Create `app/error.tsx` for error UI

      - Log errors for debugging

      - User-friendly messages


      **Monitoring:**


      - Error reporting (Sentry, etc.)

      - Performance monitoring

      - Uptime monitoring

      - Log aggregation


      ## Deployment workflow


      **GitHub integration:**


      - Auto-deploy main branch to production

      - Preview on every PR

      - Preview URL in PR comment

      - Rollback by redeploying previous commit


      **Pre-deployment checks:**


      - Tests pass

      - Linting clean

      - Build succeeds

      - Performance budgets met


      ## Secrets rotation


      **Schedule:**


      - Rotate API keys quarterly

      - Database passwords annually

      - OAuth secrets on compromise


      **Deployment:**


      - Update secret in Vercel dashboard

      - Redeploy without code change

      - Verify new secret works


      ## Zero-Downtime Deploys


      - Vercel handles automatic rollback on build failure

      - Keep database migrations backward compatible

      - Use feature flags for risky changes

      - Blue-green deploys for staged rollout


      ## Common issues


      **Build timeout:**


      - Reduce build dependencies

      - Optimize images before build

      - Use `skipLibCheck` in tsconfig


      **Large function:**


      - Split into multiple functions

      - Use separate APIs for heavy logic

      - Consider edge functions for lightweight tasks


      **Cold starts:**


      - Keep function sizes small

      - Preload dependencies

      - Use connection pooling
    level: 2
    fingerprint: aligns-stacks-vercel-deployments
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/aligns/vercel_deployments.md
    vendor:
      aligntrue:
        frontmatter:
          id: aligns/stacks/vercel-deployments
          version: 1.0.0
          summary:
            "Vercel deployment best practices: environment management, performance,
            reliability"
          tags:
            - vercel
            - deployment
            - nextjs
            - paved-road
          title: Vercel Deployments
    scope: personal
  - heading: CI Troubleshooting
    content: |

      # CI troubleshooting and status checking

      **When to apply:** The user asks about CI status, why a build failed, or requests to check GitHub Actions/Workflows.

      ## Core principle

      **Conserve API Rate Limits.** AI agents and scripts can easily hit GitHub API rate limits (60/hr unauthenticated, 5000/hr authenticated). Always prefer local verification and efficient API usage.

      ## Troubleshooting workflow

      Follow this priority order when investigating CI issues:

      ### 1. Local reproduction (zero API cost)

      Always attempt to reproduce failures locally first. This is faster and uses no API quota.

      ```bash
      # Run the full validation suite (matches CI)
      pnpm validate:all

      # Or specific checks
      pnpm test               # Unit tests
      pnpm build:packages     # Build
      pnpm lint               # Linting
      ```

      ### 2. CI error details (low API cost)

      If local checks pass but CI fails, fetch actual error details directly:

      ```bash
      # Fetches the most recent failed CI run and displays error details
      pnpm ci:errors
      ```

      This shows test failures, assertion errors, and other actionable details in one command.

      ### 3. Code scanning and security alerts (low API cost)

      If you need to check GitHub code scanning (CodeQL) alerts:

      ```bash
      # Check code scanning alerts and security issues
      pnpm codeql:status
      ```

      This efficiently fetches and displays alerts by severity, with direct links to review them.

      ### 4. Web UI (fallback)

      If rate limits are hit or complex debugging is needed, direct the user to the browser:

      - **Actions Tab:** https://github.com/AlignTrue/aligntrue/actions
      - **Current Branch:** https://github.com/AlignTrue/aligntrue/actions?query=branch%3A<branch-name>
      - **Code Scanning:** https://github.com/AlignTrue/aligntrue/security/code-scanning

      ## Anti-patterns to avoid

      - ❌ **DO NOT** run `gh run list` repeatedly in a loop.
      - ❌ **DO NOT** use `gh api` for simple status checks without checking rate limits.
      - ❌ **DO NOT** assume CI failure implies code error; check for flakes or infrastructure issues.
      - ❌ **DO NOT** blindly retry CI jobs without understanding the failure.

      ## Rate limit awareness

      If you encounter `API rate limit exceeded` or HTTP 403/429 errors:

      1.  Stop making API calls immediately.
      2.  Direct the user to the Web UI.
      3.  Explain that the rate limit was hit.

      ## Integration

      - **CI Workflow File:** `.github/workflows/ci.yml` (Defines what actually runs)
      - **CI Errors Script:** `scripts/check-ci-errors.mjs` (Fetches and displays failed CI error details)
      - **CodeQL Status Script:** `scripts/check-codeql-status.mjs` (Checks code scanning alerts)
      - **CodeQL Workflow File:** `.github/workflows/codeql.yml` (Defines code scanning configuration)
    level: 2
    fingerprint: ci-troubleshooting
    source_file: .aligntrue/rules/ci_troubleshooting.md
    vendor:
      aligntrue:
        frontmatter:
          description:
            Guidance for troubleshooting CI/CD failures and checking GitHub
            Actions status
          globs:
            - .github/workflows/*.yml
            - scripts/check-ci-errors.mjs
            - scripts/check-codeql-status.mjs
          content_hash: 2a57260e7f9653ae3fc792b8f023867a1a084bf5f21c2c8830931eca8e89b02a
          title: CI Troubleshooting
  - heading: CLI Testing Comp Prompts
    content: >

      Put together a plan to systematically, thoroughly and manually execute
      this test plan:


      DO NOT edit any code, except in your own test env for testing purposes. DO
      NOT try to fix any code. Your job is just to test thoroughly and report
      issues you find with recommendations.


      Catalog packs: Align packs are catalog-native only. When a workflow
      involves packs, create and use a real catalog entry via the catalog UI,
      and clean it up after testing. Do not create repo/demo packs or assume
      local pack manifests.


      ## Kick-Off Prompts


      Use these to invoke AI-driven test execution. Each prompt triggers actual
      command execution in a hermetic environment.


      ### Layer 1: Smoke Tests


      ```

      Execute Layer 1 (Smoke Tests) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      EXECUTION PROTOCOL:

      1. Set up hermetic test environment in /tmp/aligntrue-test-{timestamp}

      2. Build all workspace packages: cd /path/to/workspace && pnpm build

      3. Run distribution simulation script: cd packages/cli && bash
      tests/scripts/test-distribution.sh

      4. Set environment: TZ=UTC, NODE_ENV=test

      5. Execute smoke test scenarios:
         - Distribution script verification (package creation, tarball contents)
         - CLI binary execution with absolute path
         - aligntrue --help (must return <1s)
         - aligntrue --version
         - First run with no config
      6. Capture all outputs, exit codes, and execution times

      7. Validate against expected behavior

      8. Report findings with severity (P0-P3)

      9. Clean up test environment


      OUTPUT: Structured report in .internal_docs/TEST_LOG.md format with:

      - Commands executed

      - Pass/fail status

      - Issues found with root causes

      - Performance metrics

      ```


      ### Layer 2: Solo Golden Paths


      ```

      Execute Layer 2 (Solo Golden Paths) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      EXECUTION PROTOCOL:

      1. Set up hermetic test environment in /tmp/aligntrue-test-{timestamp}

      2. Build command inventory from packages/cli/src/commands/

      3. Execute core solo workflows:
         - Init new project → sync to agents
         - Edit AGENTS.md → sync → verify round-trip
         - Edit Cursor scope file → sync → verify IR update
         - Override rule → check changes
         - Add rule (one-time import) → validate → export
         - Add source (connected source) → sync → verify updates
      4. Execute new feature workflows:
         - Ignore file management (auto-detection of format conflicts)
         - Backup creation and restoration on destructive operations
         - Config-based plugs fills (config-only fills; set/unset; formats: command/text, file/url deprecated and treated as text; sync fails if required plugs unresolved)
      5. For each workflow:
         - Run exact commands
         - Capture stdout, stderr, exit codes
         - Verify resulting files (config, IR, exports)
         - Test idempotency (run twice, compare outputs)
      6. Validate against expected behavior from docs

      7. Report findings with severity

      8. Clean up test environment


      OUTPUT: Structured report with workflow results and issues found.

      ```


      ### Layer 3: Team Golden Paths


      ```

      Execute Layer 3 (Team Golden Paths) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      **CURRENT IMPLEMENTATION STATUS:**

      The automated test file
      `packages/cli/tests/comprehensive/layers/layer-3-team.ts` now implements
      all six git-based scenarios (A–F) from Section 3.1 using the
      `TeamScenario` interface and `execSync` for git commands.


      EXECUTION PROTOCOL:

      1. Set up git-based test environment:
         - Create bare git repository in /tmp/team-repo.git
         - Configure git user for test isolation (GIT_AUTHOR_NAME, GIT_AUTHOR_EMAIL)
         - Set up two hermetic test environments: user-a and user-b in /tmp
      2. Execute team workflows:
         - Solo → team migration (user-a)
         - Git repository setup and team initialization (user-a pushes, user-b clones)
         - Remotes setup (user-a)
         - Joining existing team via git clone (user-b) — run `aligntrue team join --yes` after cloning to create personal config and gitignore entries
         - Team rule changes with PR workflow (using git branch mode)
         - Personal rule changes (no approval)
         - Drift detection and resolution
         - Multi-file agent editing
         - Read-only file edit detection
      3. Execute git integration testing (REQUIRED - ALL scenarios):
         - **A. Git Repository Setup and Team Initialization** - REQUIRED (See implementation status in section 3.1)
         - **B. Git Integration Modes Testing** - REQUIRED (See implementation status in section 3.1)
         - **C. Merge Conflict Scenarios** - REQUIRED (See implementation status in section 3.1)
         - **D. PR Workflow Testing** - REQUIRED (See implementation status in section 3.1)
         - **E. Git Source Update Workflows** - REQUIRED (See implementation status in section 3.1)
         - **F. Remote Backup Testing** - REQUIRED (See implementation status in section 3.1)
      4. Execute team-specific new features:
         - Backup creation and restoration in team mode
         - Ignore file management in team transitions
         - Backup inheritance when cloning team repository
      5. For each workflow:
         - Run exact commands in sequence
         - Capture all outputs
         - Verify lockfile generation and git commit
         - Test conflict detection (both git and lockfile conflicts)
         - Validate git operations (clone, pull, push, merge, branch)
         - Verify git integration modes work correctly
         - Verify backup directory structure and restore functionality
      6. Report findings with severity

      7. Clean up both test environments and bare repository


      OUTPUT: Structured report with team workflow results, git operation
      validation, and collaboration issues.

      ```


      ### Layer 4: Command Coverage


      ```

      Execute Layer 4 (Command Coverage) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      EXECUTION PROTOCOL:

      1. Set up hermetic test environment in /tmp

      2. Build complete command inventory from
      packages/cli/src/commands/index.ts

      3. For each command exported (derive list from codebase, do NOT hardcode
      count):
         - Execute happy path with valid inputs
         - Test with missing required flags
         - Test with invalid inputs
         - Test with conflicting flags
         - Verify --help exists and is accurate
         - Validate exit codes (0=success, non-zero=failure)
      4. Specific focus areas:
         - aligntrue status: Verify output shows exporters, sync health, mode
         - aligntrue doctor: Run health checks, verify diagnostics
         - aligntrue onboard: Generate checklist, test --ci flag with SARIF input
         - aligntrue plugs set/unset: Test format validation and fill management
         - aligntrue backup cleanup: Test cleanup with retention_days and minimum_keep
         - aligntrue remotes push: Test remote push to configured destinations
         - aligntrue remotes status: Test remote status display with file assignments
         - aligntrue add link/remote: Test new subcommand structure
         - aligntrue rules list: Test rule listing by agent
         - aligntrue remove: Test link removal from config
         - aligntrue uninstall: Test clean removal with options
      5. Capture all outputs and error messages

      6. Validate error messages include what/why/how

      7. Report findings with severity

      8. Clean up test environment


      OUTPUT: Command coverage matrix with pass/fail status and issues per
      command.

      ```


      ### Layer 5: Statefulness


      ```

      Execute Layer 5 (Statefulness) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      EXECUTION PROTOCOL:

      1. Set up hermetic test environment in /tmp

      2. Test state scenarios:
         - No config (first run)
         - Valid config
         - Corrupted config (malformed YAML)
         - Partial state (cache exists, config missing)
      3. For each scenario:
         - Run commands and capture behavior
         - Verify error handling
         - Test state recovery
         - Validate cache invalidation
      4. Test backup system state management:
         - Verify .aligntrue/.backups/ directory structure
         - Validate retention_days and minimum_keep configuration
         - Test backup restoration from various states
         - Verify backup cleanup respects age-based retention policy
         - Confirm concurrent operations use unique timestamps (PID-SEQ)
      5. Verify state stored in documented locations

      6. Report findings with severity

      7. Clean up test environment


      OUTPUT: State management report with scenarios tested and issues found.

      ```


      ### Layer 6: Environment Matrix


      ```

      Execute Layer 6 (Environment Matrix) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      EXECUTION PROTOCOL:

      1. Identify current platform (macOS/Linux/Windows)

      2. Set up hermetic test environment in /tmp

      3. Test environment variations:
         - Current shell (bash/zsh/fish/cmd/powershell)
         - Node versions (20, 22, latest)
         - Different path separators
         - CI environment simulation
      4. Execute core workflows on current platform

      5. Validate:
         - Commands are scriptable
         - Outputs are deterministic
         - Paths use correct separators
         - No platform-specific assumptions
      6. Report platform-specific issues

      7. Clean up test environment


      OUTPUT: Environment compatibility report with platform-specific findings.

      ```


      ### Layer 7: Error & UX


      ```

      Execute Layer 7 (Error & UX) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      EXECUTION PROTOCOL:

      1. Set up hermetic test environment in /tmp

      2. Test error scenarios:
         - Invalid commands
         - Missing required arguments
         - File not found errors
         - Permission errors
         - Network failures (if applicable)
         - Validation errors
      3. For each error:
         - Capture error message
         - Verify exit code follows conventions
         - Validate message includes what/why/how
         - Check for sensitive data in logs
      4. Test UX elements:
         - Progress indicators (operations >10s)
         - Deterministic outputs (same inputs → same outputs)
         - Help text accuracy
      5. Report findings with severity

      6. Clean up test environment


      OUTPUT: Error/UX report with message quality assessment and issues found.

      ```


      ### Layer 8: Exploratory


      ```

      Execute Layer 8 (Exploratory) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.


      EXECUTION PROTOCOL:

      1. Set up hermetic test environment in /tmp

      2. Design 10-15 strange but plausible sequences:
         - Rapid mode switches (solo → team → solo)
         - Conflicting config changes
         - Partial file deletions mid-operation
         - Race conditions (two terminals, same repo)
         - Edge cases from real usage patterns
      3. For each sequence:
         - State what bug/confusion you are probing
         - Execute the commands
         - Capture actual behavior
         - Compare against expected behavior
         - Assign severity if issue found
      4. Report all unexpected behaviors

      5. Clean up test environment


      OUTPUT: Exploratory findings report with edge cases discovered and
      severity.

      ```


      ### All layers: Comprehensive run


      ```

      Execute all layers from .aligntrue/rules/cli_testing_playbook_COMP.md
      sequentially.


      EXECUTION PROTOCOL:

      1. Set up hermetic test environment in /tmp

      2. Execute layers 1-8 in order

      3. Aggregate results across all layers

      4. Generate comprehensive report in .internal_docs/TEST_LOG.md

      5. Provide summary with:
         - Total scenarios executed
         - Issues found by severity (P0-P3)
         - Coverage percentage
         - Gaps for next run
      6. Clean up test environment


      OUTPUT: Comprehensive test report with full findings and recommendations.

      ```
    level: 2
    fingerprint: cli-testing-comp-prompts
    source_file: .aligntrue/rules/cli_testing_COMP_prompts.md
    vendor:
      aligntrue:
        frontmatter:
          description: Test prompts for the COMP plan
          enabled: false
          title: CLI Testing Comp Prompts
  - heading: CLI Testing Playbook
    content: >

      # CLI Testing Playbook


      **Purpose:** Validate AlignTrue CLI by exploring real user workflows like
      an AI-driven test would. Find issues that automated tests miss.


      **When to use:** Before releases, or when explicitly asked to test the CLI
      comprehensively.


      **Key principle:** AI acts like a user—exploring features, discovering
      issues, reporting findings. Not a script to execute mechanically.


      ---


      ## Before you start


      ### Safety rules


      **⚠️ CRITICAL: Never test in workspace root**


      - Always create test directories in `/tmp/`

      - AlignTrue will detect existing `.aligntrue/` config and use it

      - Testing in workspace root risks corrupting your local setup

      - Create new test dir: `mkdir /tmp/aligntrue-test-$(date +%s) && cd $_`

      - Some commands do not support `--yes` (e.g., `plugs set`, `override add`,
      certain revert flows). Be ready to run them interactively.


      ### Setup


      1. **Build the CLI:**

         ```bash
         cd /path/to/aligntrue
         pnpm build
         ```

      2. **Create test directory:**

         ```bash
         cd /tmp
         TEST_DIR="aligntrue-test-$(date +%s)"
         mkdir "$TEST_DIR" && cd "$TEST_DIR"
         ```

      3. **Use absolute path to CLI:**
         ```bash
         CLI="/path/to/aligntrue/packages/cli/dist/index.js"
         $CLI --version  # Verify it works
         ```

      ---


      ## Seven exploration areas


      Complete each area sequentially. After finishing each area, record
      findings before moving to the next.


      Catalog packs (testing note):


      - Align packs are catalog-native only; there is no `.align.yaml` pack
      authoring path

      - To test pack flows, create a temporary pack in the catalog UI and clean
      it up after

      - Avoid creating repo/demo packs or assuming local pack manifests; use
      live catalog entries instead


      ### Area 1: Core Workflow


      **Goal:** Test basic solo developer setup and sync.


      **Commands:** `init`, `sync`, `check`, `status`


      **What to try:**


      1. Fresh init (solo mode):

         ```bash
         $CLI init --mode solo --yes
         ```

         - Does `.aligntrue/config.yaml` get created?
         - Does `.aligntrue/rules/` directory exist?
         - Do exporters get auto-detected?

      2. Create a rule and sync:

         ```bash
         echo "## Test Rule

         This is a test." > .aligntrue/rules/test.md
         $CLI sync
         ```

         - Does AGENTS.md get created?
         - Do Cursor files appear in `.cursor/rules/`?
         - Does backup get created automatically?

      3. Check command:

         ```bash
         $CLI check
         ```

         - Does it validate the config?
         - Are errors clear?

      4. Status command:

         ```bash
         $CLI status
         ```

         - Does it show sync health?
         - Are exporters listed correctly?

      5. (Watch command removed) Skip watch; use repeat syncs to validate
      idempotency.


      6. Content modes (if multiple exporters):

         ```bash
         $CLI sync --content-mode inline
         $CLI sync --content-mode links
         ```

         - Does content mode affect exports?

      **Report findings:**


      - [ ] All files created correctly

      - [ ] Backups created on sync

      - [ ] Status shows accurate info

      - [ ] Any errors or unexpected behaviors?


      ---


      ### Area 2: Source Management


      **Goal:** Test multi-source rules and targeting.


      **Commands:** `add`, `remove`, `sources`, `rules`


      **What to try:**


      1. List sources:

         ```bash
         $CLI sources list
         ```

         - Shows local rules directory?
         - Section counts accurate?

      2. Add an external source (one-time import; use `add link <url>` for
      linked sources):

         ```bash
         $CLI add https://github.com/AlignTrue/examples/blob/main/aligns/global.md --yes
         ```

         - Does it fetch the file?
         - Is it added to config?

      3. List rules by agent:

         ```bash
         $CLI rules --by-agent
         ```

         - Shows rules per agent?
         - Accurate counts?

      4. Per-rule targeting (create rule with targeting):

         ```bash
         cat > .aligntrue/rules/cursor-only.md <<'EOF'
         ---
         title: Cursor Only Rule
         export_only_to:
           - cursor
         ---

         ## This rule only appears in Cursor

         Content here.
         EOF
         $CLI sync
         ```

         - Does rule only appear in `.cursor/rules/`?
         - Does AGENTS.md exclude it?

      5. Remove a source:

         ```bash
         $CLI remove link <url> --yes
         ```

         - Remove only works for linked sources (remove link <url>)
         - Is it removed from config?

      **Report findings:**


      - [ ] Sources list works

      - [ ] Add fetches correctly

      - [ ] Targeting rules respected

      - [ ] Remove works

      - [ ] Any errors?


      ---


      ### Area 3: Team Collaboration


      **Goal:** Test team mode, lockfiles, and drift detection.


      **Note:** Team mode uses two config files:


      - `config.team.yaml` - Team settings (committed)

      - `config.yaml` - Personal settings (gitignored)


      **Commands:** `team`, `drift`


      **What to try:**


      1. Enable team mode:

         ```bash
         $CLI team enable --yes
         ```

         - Does `.aligntrue/config.team.yaml` get created?
         - Does `.aligntrue/lock.json` get created?
         - Is `.aligntrue/config.yaml` added to `.gitignore`?
         - Team settings (mode, lockfile) in `config.team.yaml`?

      2. Team status:

         ```bash
         $CLI team status
         ```

         - Shows current approval status?

      3. Simulate drift (edit rule, check drift):

         ```bash
         echo "### Unapproved change" >> .aligntrue/rules/test.md
         $CLI drift --gates
         ```

         - Does it detect the change?
         - Does exit code indicate drift?

      4. Update lockfile (approve changes via sync):

         ```bash
         $CLI sync
         ```

         - Does lockfile get updated?

      5. Verify no drift after sync:

         ```bash
         $CLI drift --gates
         ```

         - Should pass (no drift)?

      **Report findings:**


      - [ ] Lockfile created and valid

      - [ ] Drift detection works

      - [ ] Sync updates lockfile

      - [ ] Git modes work (if testing git)

      - [ ] Any errors?


      ---


      ### Area 4: Customization


      **Goal:** Test scopes, plugs, and overlays.


      **Commands:** `scopes`, `plugs`, `override`


      **What to try:**


      1. Configure scopes for monorepo:
         ```bash
         mkdir -p apps/web packages/api
         cat > .aligntrue/config.yaml <<'EOF'
         mode: solo
         scopes:
           - path: apps/web
             rulesets: []
           - path: packages/api
             rulesets: []
         exporters:
           - cursor
           - agents
         EOF
         ```
      2. List scopes:

         ```bash
         $CLI scopes
         ```

         - Shows all scopes?
         - Paths correct?

      3. Test plugs (config-only fills, strict required plugs):

         ```bash
         cat > .aligntrue/rules/with-plugs.md <<'EOF'
         ---
         title: Rule with Plugs
         plugs:
           slots:
             test.cmd:
               description: Test command
               format: command
               required: true
         ---

         ## Testing

         Run: [[plug:test.cmd]]
         EOF
         $CLI sync && echo "FAIL: sync should fail when required plug missing"

         # Fill required plug (formats: command, text; file/url deprecated and treated as text)
         $CLI plugs set test.cmd "pnpm test"
         $CLI plugs
         $CLI sync
         ```

         - Does status show required plugs filled? Does sync succeed after fill?

      4. Test overlays (selectors limited, conflicts fail by default):

         ```bash
         $CLI override add --selector "rule[id=some-rule]" --set "severity=error"
         $CLI override  # default status + diff
         ```

         - Conflicts should fail unless `--allow-overlay-conflicts` is provided.

      **Report findings:**


      - [ ] Scopes resolve correctly

      - [ ] Plugs audit works

      - [ ] Plugs set saves fills

      - [ ] Overlays apply

      - [ ] Any errors?


      ---


      ### Area 5: Config & Exporters


      **Goal:** Test configuration management and agent detection.


      **Commands:** `config`, `exporters`, `doctor`


      **What to try:**


      1. Show config:

         ```bash
         $CLI config show
         ```

         - Does it display full config?

      2. Get single value:

         ```bash
         $CLI config get mode
         ```

         - Returns correct value?

      3. Set value:

         ```bash
         $CLI config set mode solo
         ```

         - Persists to file?

      4. List exporters:

         ```bash
         $CLI exporters
         ```

         - Shows all 50+ exporters?
         - Indicates which are enabled?

      5. Detect new agents:

         ```bash
         mkdir -p .aider/rules
         echo "test" > .aider/rules/test.md
         $CLI exporters detect
         ```

         - Detects new `.aider/` directory?

      6. Run doctor:

         ```bash
         $CLI doctor
         ```

         - Runs health checks?
         - Reports any issues?

      **Report findings:**


      - [ ] Config commands work

      - [ ] Exporters list accurate

      - [ ] Detection works

      - [ ] Doctor finds issues or clears status

      - [ ] Any errors?


      ---


      ### Area 6: Safety & Recovery


      **Goal:** Test backups, recovery, and onboarding.


      **Commands:** `backup`, `revert`, `doctor`, `onboard`


      **What to try:**


      1. Verify backups after sync:

         ```bash
         ls -la .aligntrue/.backups/
         ```

         - Backups created automatically?
         - Timestamps present?

      2. List backups:

         ```bash
         $CLI backup list
         ```

         - Shows all backups?
         - Timestamps readable?

      3. Create deliberate change and revert:

         ```bash
         echo "DELETED CONTENT" > .aligntrue/rules/test.md
         $CLI revert --latest --yes
         ```

         - Does revert restore the file?
         - Was backup used?

      4. Run onboard wizard:

         ```bash
         echo "n" | $CLI onboard  # Skip interactive
         ```

         - Does it provide checklist?

      **Report findings:**


      - [ ] Backups created on every sync

      - [ ] Backup list shows all

      - [ ] Revert restores correctly

      - [ ] Onboard runs without errors

      - [ ] Any issues?


      ---


      ### Area 7: Edge Cases & Privacy


      **Goal:** Test unusual scenarios, error handling, privacy.


      **Commands:** `privacy`, `migrate`


      **What to try:**


      1. Privacy audit:

         ```bash
         $CLI privacy audit
         ```

         - Shows consent status?

      2. Grant privacy consent:

         ```bash
         $CLI privacy grant git --yes
         ```

         - Updates consent state?

      3. Edge cases:
         - Empty rule file:

           ```bash
           touch .aligntrue/rules/empty.md
           $CLI sync
           ```

           - Error or skip gracefully?

         - Invalid YAML frontmatter:
           ```bash
           echo "---
           invalid: [yaml
           ```

         ***

         Content" > .aligntrue/rules/bad.md
         $CLI sync

         ````
         - Error message helpful?

         - Very large file (>100KB):
         ```bash
         python3 -c "print('## Large Rule\n\n' + 'x' * 150000)" > .aligntrue/rules/large.md
         $CLI sync
         ````

         - Handles large files?

      **Report findings:**


      - [ ] Privacy commands work

      - [ ] Edge cases handled gracefully

      - [ ] Error messages clear

      - [ ] No crashes on invalid input

      - [ ] Any issues?


      ---


      ## Recording findings


      After each area, summarize:


      ### Area [N] - [Name]


      **Tests completed:**


      - [ ] Feature 1

      - [ ] Feature 2

      - [ ] Feature 3


      **Issues found:**


      - (Describe any critical/medium/low severity issues)


      **Doc/behavior mismatches:**


      - (Note any where docs don't match actual behavior)


      **Confidence:** [Thorough / Partial / Skipped]


      ---


      ## Coverage matrix


      Mark each command as tested:


      | Command   | Tested | Notes |

      | --------- | ------ | ----- |

      | init      | [ ]    |       |

      | sync      | [ ]    |       |

      | check     | [ ]    |       |

      | status    | [ ]    |       |

      | add       | [ ]    |       |

      | remove    | [ ]    |       |

      | sources   | [ ]    |       |

      | rules     | [ ]    |       |

      | team      | [ ]    |       |

      | drift     | [ ]    |       |

      | scopes    | [ ]    |       |

      | plugs     | [ ]    |       |

      | override  | [ ]    |       |

      | config    | [ ]    |       |

      | exporters | [ ]    |       |

      | backup    | [ ]    |       |

      | revert    | [ ]    |       |

      | doctor    | [ ]    |       |

      | onboard   | [ ]    |       |

      | privacy   | [ ]    |       |

      | migrate   | [ ]    |       |


      ---


      ## Final report


      After completing all areas:


      1. **Commands test report:** X / 22

      2. **Issues found:** X critical, X medium, X low

      3. **Tests that failed:** (List any)

      4. **Doc mismatches:** (List any)

      5. **Overall confidence:** Single run **%, 3 runs **%, 5 runs \_\_%


      ---


      ## Cleanup


      When finished:


      ```bash

      cd /tmp

      rm -rf aligntrue-test-*

      ```


      All test data deleted. Original AlignTrue setup untouched.
    level: 2
    fingerprint: cli-testing-playbook
    source_file: .aligntrue/rules/cli_testing_playbook.md
    vendor:
      aligntrue:
        frontmatter:
          description:
            Focused AI-driven CLI testing playbook with 7 exploration areas
            covering all 24 commands
          enabled: false
          title: CLI Testing Playbook
  - heading: CLI Testing Playbook Comp
    content: >

      # CLI Testing Playbook


      **When to apply:** Use when running systematic CLI validation before
      releases or when explicitly asked to test the CLI. Not for routine
      development or debugging.


      **Goal:** Find distribution blockers and validate user workflows without
      maintaining a manual feature list that drifts.


      **⚠️ CRITICAL REQUIREMENT: COMPLETE ALL TESTS ⚠️**


      **ALL TESTS MUST BE COMPLETED - NO EXCEPTIONS**


      When executing the CLI testing playbook:


      - **Time constraints DO NOT matter** - Completeness is the ONLY priority

      - **ALL layers must be fully executed** - Every test scenario, every
      workflow, every command

      - **ALL git-based team collaboration tests must be run** - Section 3.1 A-F
      scenarios are REQUIRED

      - **Partial testing is NOT acceptable** - Complete the full test suite or
      clearly document why a specific test cannot be run

      - **Gaps must be explicitly documented** - If a test cannot be completed,
      explain why and provide a plan to complete it


      **Testing Priority:**


      1. Completeness (100% required)

      2. Thoroughness (test all scenarios)

      3. Accuracy (document all findings)


      **⚠️ CRITICAL WARNING: NEVER TEST IN WORKSPACE ROOT ⚠️**


      **ALWAYS create test directories in `/tmp/` and work from there. Running
      CLI commands from the workspace root will detect existing `.aligntrue/`
      configuration and risk corrupting the user's actual setup. See "During
      testing" section for details.**


      ---


      ## Quick start


      ### AI-Driven Testing (Recommended)


      Use these prompts to trigger automated test execution:


      **Run all layers comprehensively:**


      ```

      Execute all 8 layers from .aligntrue/rules/cli_testing_playbook_COMP.md
      sequentially.

      ```


      **Run specific layer:**


      ```

      Execute Layer 1 (Smoke Tests) from
      .aligntrue/rules/cli_testing_playbook_COMP.md.

      ```


      Replace "Layer 1 (Smoke Tests)" with:


      - Layer 2 (Solo Golden Paths)

      - Layer 3 (Team Golden Paths)

      - Layer 3.5 (Advanced Customization)

      - Layer 4 (Command Coverage)

      - Layer 5 (Statefulness)

      - Layer 6 (Environment Matrix)

      - Layer 7 (Error & UX)

      - Layer 8 (Exploratory)


      ### Manual execution (Recommended Approach)


      **Build first (required):**


      ```bash

      cd /path/to/aligntrue

      pnpm build

      ```


      **Run all layers:**


      ```bash

      cd packages/cli

      pnpm test:comprehensive

      ```


      This runs layers 2-8 using local workspace (fast, no network).


      **Run distribution testing (Layer 1):**


      ```bash

      cd packages/cli

      pnpm test:distribution

      ```


      Tests the packaged artifact independently.


      **Run specific layer:**


      ```bash

      cd packages/cli

      pnpm test:layer 2  # Replace 2 with layer number (1-8)

      ```


      **Generate report from logs:**


      ```bash

      cd packages/cli

      pnpm test:report .internal_docs

      ```


      ### Test infrastructure


      **Automated Architecture:**


      Test execution files located in `packages/cli/tests/comprehensive/`:


      - **Layer 1:** `layers/layer-1-smoke.ts` - Distribution package testing
        - Uses `scripts/test-distribution.sh` to test packaged artifact
        - Run: `pnpm test:distribution`

      - **Layers 2-8:** Feature testing via TypeScript implementations
        - Files: `layers/layer-2-solo.ts`, `layer-3-team.ts`, `layer-4-coverage.ts`, etc.
        - Uses local build (no cloning needed)
        - Runs in isolated `/tmp/` directories
        - Fast feedback (seconds to minutes)
        - Run all: `pnpm test:comprehensive`
        - Run specific: `tsx layers/layer-2-solo.ts`

      **Safety Guards:**


      All layer tests use `assertTestSafety()` to verify:


      - Current working directory is in `/tmp/` (isolated)

      - Test workspace is not in workspace root

      - Environment variables properly set (`TEST_WORKSPACE`, `ALIGNTRUE_CLI`,
      `LOG_FILE`)


      Tests fail immediately with clear error messages if safety checks fail.


      **Why This Approach Works:**


      1. **No dogfooding interference:** Tests use isolated `/tmp/` directories,
      your local AlignTrue config is untouched

      2. **Fast execution:** Local builds are already cached, no cloning or
      rebuilding

      3. **Easy debugging:** Test directories kept for inspection, clear paths

      4. **Reliable:** No network dependencies, simple execution model

      5. **Protected:** Explicit safety checks prevent workspace corruption


      ### Test results


      Results are saved to:


      - `.internal_docs/TEST_LOG.md` - Comprehensive test log

      - Test directories in `/tmp/aligntrue-test-*/` - Keep for inspection or
      delete manually


      ---


      ## Core principle


      **Derive specifics from the live repo each run.** Test systematically
      based on actual commands and docs, not a static checklist.


      ---


      ## Testing approach: Hybrid strategy for real user experience


      This playbook uses a hybrid testing strategy to accurately validate user
      experience while maintaining fast feedback:


      ### Layer 1: Distribution package testing


      - **Goal:** Test the actual packaged artifact users receive

      - **Method:** Create tarball with `pnpm pack`, install globally with `npm
      install -g`

      - **Why:** Catches packaging issues (missing files, wrong bin links),
      tests real installation flow, simulates user experience

      - **Reliability:** Works with AI terminal execution (no GitHub cloning
      failures)


      ### Layers 2-8: Feature testing


      - **Goal:** Validate CLI commands and workflows

      - **Method:** Use local workspace directly with `pnpm exec` or PATH
      modifications

      - **Why:** Fast, reliable, no installation overhead, tests CLI logic
      thoroughly

      - **Scope:** All commands, statefulness, error handling, golden paths


      ---


      ## Testing resources


      **Evergreen test repository:** https://github.com/AlignTrue/examples


      - Stable, versioned markdown files for integration testing

      - 11 curated example files live under the `aligns/` subdirectory:
      `aligns/global.md`, `aligns/testing.md`, `aligns/security.md`,
      `aligns/debugging.md`, `aligns/docs.md`, `aligns/nextjs_app_router.md`,
      `aligns/rule-authoring.md`, `aligns/tdd.md`, `aligns/typescript.md`,
      `aligns/vercel_deployments.md`, `aligns/web_quality.md`

      - Use for testing git source integration, caching, and bundle merging

      - Note: Files are in markdown format (`.md`), not YAML packs


      **Pack testing (catalog-only):**


      - Align packs are created and stored only in the catalog UI; there is no
      `.align.yaml` or local pack authoring path

      - When testing pack-related flows, create an ephemeral pack in
      https://aligntrue.ai/catalog and delete it after the run

      - Prefer the AlignTrue/examples repo for rule fixtures; avoid inventing
      repo/demo packs that would pollute the catalog


      - Example config:
        ```yaml
        sources:
          - type: git
            url: https://github.com/AlignTrue/examples
            path: aligns/testing.md
        ```

      **Git source troubleshooting:**


      - `Rules file not found` → Confirm the `path` includes `aligns/` and
      matches the repo file (case-sensitive).

      - `git clone failed` → Ensure you granted consent: `aligntrue privacy
      grant git` (team CI may require this).

      - Missing credentials → For private forks use SSH URLs
      (`git@github.com:...`) and load SSH keys in CI.

      - Slow tests → Set `INTEGRATION=1` only when running network-dependent
      suites (see Layer 1 instructions).

      - Cache cleanup → Delete `.aligntrue/.cache/git/` when changing refs or
      repo URLs between tests.


      ---


      ## Testing charter


      Execute in order. Each layer builds on previous validation.


      ### 1. Smoke / Install


      **What:** Test package creation and local CLI installation


      **Validate:**


      - Package creation succeeds (`pnpm pack`)

      - Tarball contents include all necessary files

      - Local installation succeeds (`pnpm link --global`)

      - `aligntrue --help` returns <1s with accurate usage

      - `aligntrue --version` shows correct version

      - First run with no config handles gracefully

      - Installed CLI is accessible from `$PATH`


      **Commands:**


      ```bash

      # Step 1: Build all workspace dependencies

      cd /path/to/workspace

      pnpm build  # Builds all packages (core, exporters, schema, cli, etc.)


      # Step 2: Run distribution simulation script

      cd packages/cli

      bash tests/scripts/test-distribution.sh


      # This script:

      # - Creates tarball with pnpm pack

      # - Extracts and rewrites workspace:* to concrete versions

      # - Sets up proper NODE_PATH for testing

      # - Runs smoke tests (--help, --version, init, status)

      # - Reports results

      # - Cleans up automatically


      # OR for manual testing:


      # Step 2a: Create tarball

      pnpm pack  # Creates aligntrue-cli-X.Y.Z.tgz


      # Step 2b: Verify tarball contents

      tar -tzf aligntrue-cli-*.tgz | grep -E "dist/|package.json" | head -20


      # Step 3: ⚠️ CRITICAL - Create test directory and work from there

      cd /tmp

      TEST_DIR="aligntrue-test-$(date +%s)"

      mkdir "$TEST_DIR" && cd "$TEST_DIR"

      # NOW we're in a clean test directory - safe to run CLI commands


      # Step 4: Use absolute path to CLI (NOT pnpm link --global)

      CLI_PATH="/path/to/workspace/packages/cli/dist/index.js"


      # Verify CLI works

      $CLI_PATH --version

      time $CLI_PATH --help  # Should be <1s


      # Test basic usage (from test directory)

      $CLI_PATH check  # Should handle missing config gracefully

      $CLI_PATH init --yes

      $CLI_PATH status


      # Cleanup

      cd /path/to/workspace/packages/cli && rm -f aligntrue-cli-*.tgz

      rm -rf /tmp/aligntrue-test-*

      ```


      **Why:** This properly tests distribution without relying on `pnpm link
      --global`, which doesn't work with `workspace:*` dependencies. The
      distribution script simulates what `pnpm publish` does.


      **Note:** Do NOT use `pnpm link --global` - it will fail with
      `ERR_PACKAGE_PATH_NOT_EXPORTED`. Use absolute paths or the distribution
      script instead.


      ### 2. Golden Paths (Solo)


      **What:** Core workflows a normal solo developer does


      **Identify 3-5 primary workflows from:**


      - `packages/cli/src/commands/*.ts` - available commands

      - `apps/docs/content/` - documented workflows

      - `README.md` - quickstart examples


      **Validate for each workflow:**


      - Exact commands match docs

      - Expected outputs appear

      - Resulting files are correct

      - Idempotency where expected (running twice produces same result)


      **Example workflows:**


      - Init new project → sync to agents

      - Add pack → validate → export

      - Override rule → check changes

      - Edit AGENTS.md → sync to agents

      - Edit Cursor scope file → sync → verify round-trip to IR and other agents

      - Personal rule in remote → modify → sync → verify git operations

      - Ignore file management (auto-detection of format conflicts)

      - Backup creation and restoration on destructive operations

      - **New file detection → auto-enable exporters → backups before
      overwrite**

      - **Multiple new files → auto-enable exporters → verify backups captured
      original content**

      - **Content deduplication (current behavior: overwrite with canonical
      rules; no extracted-rules.md)**


      #### Ignore file management workflow


      Test automatic ignore file handling and format conflict detection:


      ```bash

      cd /tmp/test-ignore-files

      aligntrue init --mode solo --yes --exporters cursor,agents


      # Verify init prompt/detection of format conflicts

      # Expected: Cursor exporter should auto-manage ignore files to prevent
      duplicate rules


      # Set manual ignore file priority (if needed)

      # aligntrue config set sync.ignore_file_priority native


      # Sync and verify ignore files are created/managed

      aligntrue sync


      # Check for auto-generated ignore files (only created when conflicts
      exist)

      # Note: Ignore files use standard agent names (.cursorignore,
      .aiderignore, etc.)

      # They are only created when multiple exporters target the same agent

      test -f .cursorignore && echo "PASS: .cursorignore created" || echo "INFO:
      No conflicts detected, ignore file not needed"


      # Manage ignore files automatically (current option)

      aligntrue config set sync.auto_manage_ignore_files true


      # Sync again and verify ignore files are managed

      aligntrue sync

      ```


      **Expected:**


      - Auto-detection of format conflicts during init (when multiple exporters
      target same agent)

      - Ignore files created using standard agent names (`.cursorignore`,
      `.aiderignore`, etc.)

      - Ignore files only created when conflicts exist between exporters

      - Priority settings respected during sync

      - No duplicate rules across formats


      #### Nested ignore file workflow


      Test that ignore files are created in nested directories when rules have
      `nested_location`:


      ```bash

      cd /tmp/test-nested-ignore

      aligntrue init --mode solo --yes --exporters cursor,agents


      # Create a rule with nested_location

      mkdir -p .aligntrue/rules

      cat > .aligntrue/rules/docs-rule.md <<'EOF'

      ---

      nested_location: apps/docs

      ---


      # Docs rule


      Content for docs.

      EOF


      # Sync to trigger nested ignore file creation

      aligntrue sync


      # Verify nested ignore file was created

      test -f apps/docs/.cursorignore && echo "PASS: nested ignore file created"
      || echo "FAIL: nested ignore file missing"


      # Verify it ignores AGENTS.md (conflict between cursor and agents
      exporters)

      grep "AGENTS.md" apps/docs/.cursorignore || echo "FAIL: AGENTS.md not
      ignored"

      ```


      **Expected:**


      - Nested ignore files created in directories specified by
      `nested_location`

      - Ignore files follow same format conflict rules as root ignore files

      - Multiple nested locations each get their own ignore file


      #### Backup testing workflow


      Test mandatory backup system and BackupManager behavior:


      ```bash

      cd /tmp/test-backups

      aligntrue init --mode solo --yes


      # Verify backups directory exists

      test -d .aligntrue/.backups || echo "FAIL: backups directory missing"


      # Make a change that should trigger backup

      echo "### New Rule" >> AGENTS.md

      aligntrue sync


      # Verify backup was created

      ls -la .aligntrue/.backups/ | head -5

      BACKUP_COUNT=$(ls .aligntrue/.backups/ | wc -l)

      test $BACKUP_COUNT -gt 0 || echo "FAIL: no backups created"


      # Test backup listing

      aligntrue backup list


      # Test restore (shows preview before confirmation)

      LATEST_BACKUP=$(ls -t .aligntrue/.backups/ | head -1)

      aligntrue revert --timestamp "$LATEST_BACKUP" --yes


      # Verify file was restored

      grep "### New Rule" AGENTS.md && echo "FAIL: restore didn't revert
      changes" || echo "PASS: changes reverted"


      # Test retention_days configuration

      aligntrue config set backup.retention_days 30

      # Should succeed (age-based retention)


      aligntrue config set backup.minimum_keep 3

      # Should succeed (safety floor of 3 backups)


      # Test that old backups are cleaned up

      # Create multiple backups

      for i in {1..5}; do
        aligntrue backup create --notes "Test backup $i"
        sleep 1
      done


      # Cleanup should respect retention_days

      aligntrue backup cleanup


      # Test concurrent operation uniqueness

      BACKUP1=$(ls -t .aligntrue/.backups/ | head -1)

      echo "First backup: $BACKUP1"

      # Should contain timestamp with process ID (e.g., 20251124-123456-12345-0)

      ```


      **Expected:**


      - Backups created in `.aligntrue/.backups/TIMESTAMP-PID-SEQ/` directory

      - Backup timestamps include process ID and sequence for uniqueness

      - Agent files backed up to `agent-files/` subdirectory within backup

      - `retention_days` configuration controls age-based cleanup (default: 30
      days)

      - `minimum_keep` configuration maintains safety floor of recent backups
      (default: 3)

      - Cleanup removes backups older than `retention_days` while respecting
      `minimum_keep`

      - Backups are mandatory for all destructive operations


      #### Remotes workflow (replaces legacy remote backup)


      **For comprehensive remotes testing scenarios, see Section 3.1.F "Remotes
      Testing".**


      That section covers:


      - Basic remotes configuration and status checking

      - Manual remote push operations

      - Auto-push during sync

      - Multiple remote destinations with file routing

      - Conflict detection between sources and remotes


      Quick summary for Layer 2:


      - Remotes configuration stores rules in remote git repositories

      - `aligntrue remotes status` shows configured remotes and file assignments

      - `aligntrue remotes push` manually pushes to all configured remotes

      - `auto: true` triggers remote push during sync

      - Multiple destinations supported with glob patterns


      #### Source/remote conflict detection


      Test warning when same URL is both source and remote:


      ```bash

      cd /tmp/test-source-backup-conflict

      aligntrue init --mode solo --yes


      git init --bare /tmp/conflicting-repo.git


      # Configure same URL as both source AND remote

      cat > .aligntrue/config.yaml <<'EOF'

      sources:
        - type: git
          url: /tmp/conflicting-repo.git

      remotes:
        personal: /tmp/conflicting-repo.git
      EOF


      # Test sync - should warn about conflict

      aligntrue sync

      # Expected: warning about URL being both source and remote, remote push
      skipped


      # Test remotes push - should also warn

      aligntrue remotes push

      # Expected: same warning, remote push skipped for conflicting URL

      ```


      **Expected:**


      - Warning emitted when same URL is source and backup

      - Backup operation skipped for conflicting URLs

      - Warning includes link to documentation (aligntrue.ai/backup)


      #### Personal source in team mode


      Test that personal sources skip team approval:


      ```bash

      cd /tmp/test-personal-source

      aligntrue init --mode team --yes


      # Configure a personal git source

      git init --bare /tmp/personal-rules.git

      cat > .aligntrue/config.yaml <<'EOF'

      mode: team

      sources:
        - type: git
          url: /tmp/personal-rules.git
          personal: true
      EOF


      # Personal sources should auto-pull without approval

      aligntrue sync

      # Expected: no UpdatesAvailableError, rules pulled automatically


      # Personal source rules should be gitignored

      cat .gitignore | grep -q ".aligntrue/rules/" && echo "PASS: personal rules
      gitignored" || echo "FAIL: personal rules not gitignored"

      ```


      **Expected:**


      - `personal: true` sources skip team approval workflow

      - Personal source rules are automatically gitignored

      - Team rules still require approval as before


      #### Gitignore flag for rules


      Test the gitignore flag (renamed from private):


      ```bash

      cd /tmp/test-gitignore-flag

      aligntrue init --mode solo --yes


      # Create a rule with gitignore flag

      cat > .aligntrue/rules/secret-prompts.md <<'EOF'

      ---

      description: My secret prompts

      gitignore: true

      ---

      # Secret prompts

      These should not be committed.

      EOF


      # Sync should add to gitignore

      aligntrue sync


      # Check gitignore was updated

      cat .gitignore | grep -q "secret-prompts.md" && echo "PASS: rule
      gitignored" || echo "FAIL: rule not gitignored"


      # Verify the managed section markers

      grep -q "# START AlignTrue Gitignore Rules" .gitignore && echo "PASS:
      section marker found" || echo "FAIL: section marker missing"

      ```


      **Expected:**


      - Rules with `gitignore: true` are added to `.gitignore`

      - Managed section uses "AlignTrue Gitignore Rules" markers

      - Works for both frontmatter and source-level gitignore settings


      #### New file detection workflow (current behavior)


      The CLI no longer creates `extracted-rules.md`. New agent files with
      content are detected, exporters are auto-enabled, and backups are taken
      before overwriting those files with the canonical rules.


      ```bash

      cd /tmp/test-new-file-detection

      aligntrue init --mode solo --yes


      # Add new agent files with content

      cat > CLAUDE.md <<'EOF'

      ## Claude-specific tips

      Use clear, structured prompts.

      EOF


      cat > GEMINI.md <<'EOF'

      ## Security

      Always use HTTPS for API calls.

      EOF


      # Sync detects new agent files and enables exporters

      aligntrue sync --yes


      # Verify backups were created (content is preserved here before overwrite)

      test -d .aligntrue/.backups || echo "FAIL: backups directory missing"


      # Verify exporters were auto-enabled for detected agents

      aligntrue config get exporters

      # Expected: includes agents, cursor, claude, gemini (order not guaranteed)


      # After sync, CLAUDE.md and GEMINI.md contain the exported rules (not
      original content)

      head -5 CLAUDE.md

      head -5 GEMINI.md


      # To inspect original content, check the latest backup under
      .aligntrue/.backups/

      ls .aligntrue/.backups/ | tail -1

      ```


      **Expected:**


      - New agent files are detected and corresponding exporters are
      auto-enabled

      - Original file content is preserved in `.aligntrue/.backups/` before
      overwrite

      - No `extracted-rules.md` is created

      - Exported agent files contain canonical rules after sync


      #### Rule import workflow


      Test importing rules from external sources:


      ```bash

      cd /tmp/test-rule-import

      aligntrue init --mode solo --yes


      # Test one-time import (default)

      aligntrue add https://github.com/org/rules/testing.md

      # Expected: Rule copied to .aligntrue/rules/testing.md with source
      metadata


      # Verify frontmatter

      grep "source:" .aligntrue/rules/testing.md || echo "FAIL: source field
      missing"

      grep "source_added:" .aligntrue/rules/testing.md || echo "FAIL:
      source_added field missing"


      # Test linked source

      aligntrue add link https://github.com/org/rules/security.md

      # Expected: Link added to config.yaml for continuous updates


      # Verify config

      grep "security.md" .aligntrue/config.yaml || echo "FAIL: source not in
      config"


      # Test conflict handling

      echo "## Existing" > .aligntrue/rules/testing.md

      aligntrue add https://github.com/org/rules/testing.md

      # Expected: Prompt for replace/keep-both, backup if replaced


      # Test init with source

      cd /tmp/test-init-source

      aligntrue init https://github.com/org/rules --yes

      # Expected: Rules imported, auto-detect skipped

      ```


      **Expected:**


      - One-time import copies rules to `.aligntrue/rules/`

      - `aligntrue add link <url>` adds link to config for continuous updates

      - Conflicts prompt for resolution with backup

      - `init --source` skips auto-detection


      #### Private rules workflow


      Test importing rules from private (SSH) sources:


      ```bash

      cd /tmp/test-private-rules

      aligntrue init --mode solo --yes


      # Test SSH source detection (requires valid SSH access)

      # Use a test private repo or mock with local path + manually set private

      aligntrue add git@github.com:user/private-rules

      # Expected:

      # - "Private source detected (SSH authentication)"

      # - "Rules added to .gitignore automatically"

      # - Auto-sync happens after import


      # Verify gitignore was updated

      grep "AlignTrue Gitignore Rules" .gitignore || echo "FAIL: gitignore rules
      section missing"

      grep ".aligntrue/rules" .gitignore || echo "FAIL: source rules not in
      gitignore"

      grep ".cursor/rules" .gitignore || echo "FAIL: exported rules not in
      gitignore"


      # Test --no-sync flag

      cd /tmp/test-private-no-sync

      aligntrue init --mode solo --yes

      aligntrue add git@github.com:user/private-rules --no-sync

      # Expected: Rules imported but sync skipped, tip shows "run 'aligntrue
      sync'"


      # Test linked private source

      cd /tmp/test-private-linked

      aligntrue init --mode solo --yes

      aligntrue add link git@github.com:user/private-rules

      # Expected:

      # - Source added to config with auto-gitignore

      # - "Run 'aligntrue sync' to pull rules" message


      # Verify config has gitignore flag or personal flag

      grep -E "gitignore: true|personal: true" .aligntrue/config.yaml || echo
      "FAIL: security flag not set"


      # Test per-rule gitignore override (frontmatter)

      cd /tmp/test-rule-gitignore-override

      aligntrue init --mode solo --yes

      echo '---

      gitignore: true

      ---

      # Gitignored rule' > .aligntrue/rules/secret.md

      aligntrue sync

      # Expected: Rule synced but marked for gitignore

      ```


      **Expected:**


      - SSH URLs (`git@`, `ssh://`) auto-detected as personal sources

      - Personal source rules are auto-added to .gitignore (both source and
      exports)

      - Auto-sync happens after import (unless `--no-sync`)

      - Links added with `aligntrue add link` get appropriate security flags

      - Frontmatter `gitignore: true` overrides source settings

      - Enhanced tips section shows security-aware guidance


      #### File size validation workflow


      Test automatic file size validation in the `check` command:


      ```bash

      cd /tmp/test-file-size

      aligntrue init --mode solo --yes


      # Create a large file that exceeds the urgent threshold (1,500 lines)

      for i in {1..1600}; do echo "## Section $i" >> AGENTS.md; done


      # Run check command - should warn about the large file

      aligntrue check 2>&1 | tee check-output.txt

      grep "very large" check-output.txt || echo "FAIL: no size warning"

      grep "sources split" check-output.txt || echo "FAIL: no split suggestion"


      # Test sources split command

      aligntrue sources split

      # Expected: Splits large file into multiple smaller files


      # Verify split worked

      ls -la *.md | wc -l

      # Expected: Multiple files created (more than 1)

      ```


      **Expected:**


      - `aligntrue check` warns about files exceeding the urgent threshold
      (~1,500 lines)

      - The warning cites the file path, line count, and suggests `aligntrue
      sources split`

      - `aligntrue sources split` divides large files into manageable segments

      - The resulting files are smaller and more maintainable


      **Note:** The `sources split` command is specifically designed for
      migrating from a single AGENTS.md to multi-file organization in
      `.aligntrue/rules/`. It does not split arbitrary large rule files. For
      large individual rule files in `.aligntrue/rules/`, manually split them
      into multiple files.


      #### Sources detect workflow


      Test detection of untracked agent files:


      ```bash

      cd /tmp/test-sources-detect

      aligntrue init --mode solo --yes


      # Create untracked agent files

      echo "## Untracked Rule" > CLAUDE.md

      mkdir -p .windsurf/rules

      echo "## Windsurf Rule" > .windsurf/rules/custom.md


      # Detect untracked files

      aligntrue sources detect

      # Expected: Lists CLAUDE.md and .windsurf/rules/custom.md


      # Import detected files

      aligntrue sources detect --import

      # Expected: Files imported to .aligntrue/rules/

      ```


      **Expected:**


      - Detects new agent files with content outside `.aligntrue/rules/`

      - Lists detected files with section counts

      - `--import` flag imports detected files

      - Imported files added to exporters list


      #### Formatting normalization workflow


      Test that common formatting issues are fixed during export:


      ```bash

      cd /tmp/test-formatting

      aligntrue init --mode solo --yes


      # Create file with formatting issues (horizontal rule + heading without
      newline)

      cat > AGENTS.md <<'EOF'

      ## First section


      Some content here.


      ---### Second Section


      More content.


      ---



      ### Third section


      Final content.

      EOF


      # Sync to export

      aligntrue sync


      # Verify formatting fixed in exports

      cat .aligntrue/rules/aligntrue.mdc


      # Should have proper spacing: ---\n\n###

      grep -A2 "^---$" .aligntrue/rules/aligntrue.mdc | grep "^$" || echo "FAIL:
      missing newline after horizontal rule"


      # Should NOT have concatenated: ---###

      grep "^---#" .aligntrue/rules/aligntrue.mdc && echo "FAIL: found malformed
      horizontal rule" || echo "PASS: formatting normalized"

      ```


      **Expected:**


      - Horizontal rules followed by proper newlines

      - No concatenated `---###` patterns

      - All sections properly spaced

      - Formatting issues fixed automatically


      #### Content mode testing workflow


      Test content mode configuration for single-file exports:


      ```bash

      cd /tmp/test-content-mode

      aligntrue init --mode solo --yes


      # Create multiple rules to test different modes

      cat > .aligntrue/rules/global.md <<'EOF'

      ---

      description: Global rules

      ---


      ## Global rule 1


      First global rule content here.


      ## Global rule 2


      Second global rule content here.

      EOF


      cat > .aligntrue/rules/security.md <<'EOF'

      ---

      description: Security rules

      ---


      ## Security rule


      Security rule content here.

      EOF


      # Test auto mode (default) - should use links for 2+ rules

      aligntrue sync

      grep -q "^\[" AGENTS.md && echo "PASS: auto mode uses links for 2+ rules"
      || echo "FAIL: links not found"


      # Test inline mode - should embed all content

      aligntrue sync --content-mode=inline

      grep -q "<!-- aligntrue:rule" AGENTS.md && echo "PASS: inline mode uses
      HTML comment separators" || echo "FAIL: separators missing"


      # Verify content is embedded not linked

      grep -q "^\[.*Global Rule" AGENTS.md && echo "FAIL: links found in inline
      mode" || echo "PASS: no links in inline mode"


      # Test links mode - should use markdown links

      aligntrue sync --content-mode=links

      grep -q "^\[.*Global Rule" AGENTS.md && echo "PASS: links mode uses
      markdown links" || echo "FAIL: links not found"


      # Test size warning with large inline content (>50KB)

      # Create rules with ~60KB of content

      for i in {1..30}; do
        echo "## Rule $i" >> .aligntrue/rules/large.md
        for j in {1..100}; do
          echo "Line $j with some content to bulk up the file."  >> .aligntrue/rules/large.md
        done
      done


      # Sync with inline mode - should warn about size

      aligntrue sync --content-mode=inline 2>&1 | tee size-warning.log

      grep -i "warning.*size\|warning.*50KB\|warning.*large" size-warning.log &&
      echo "PASS: size warning emitted" || echo "INFO: size warning not shown
      (file may be under 50KB)"

      ```


      **Expected:**


      - Auto mode uses inline for single rule, links for 2+ rules

      - Inline mode embeds full content with HTML comment separators

      - Links mode always uses markdown links to `.aligntrue/rules/` files

      - Size warning emitted for inline mode with combined content >50KB

      - `--content-mode` CLI flag overrides config setting

      - Content modes work consistently across multiple syncs


      #### MCP configuration propagation workflow


      Test that MCP server configurations are correctly propagated to
      agent-specific files:


      ```bash

      cd /tmp/test-mcp-propagation

      aligntrue init --mode solo --yes --exporters
      cursor-mcp,vscode-mcp,root-mcp


      # Add MCP server configuration to config

      #

      # Note: Configure MCP servers by editing YAML directly. The `config set`

      # command does not support nested array paths (e.g.,
      mcp.servers[0].command).

      cat >> .aligntrue/config.yaml <<'EOF'

      mcp:
        servers:
          - name: custom-tool
            command: python
            args: ["./tools/mcp-server.py"]
            env:
              API_KEY: "secret"
          - name: nodejs-server
            command: node
            args: ["./mcp.js"]
          - name: disabled-tool
            command: ruby
            disabled: true
      EOF


      # Sync to propagate MCP configs

      aligntrue sync


      # Verify MCP configs were written to agent-specific files

      test -f .cursor/mcp.json || echo "FAIL: Cursor MCP config missing"

      test -f .vscode/mcp.json || echo "FAIL: VS Code MCP config missing"

      test -f .mcp.json || echo "FAIL: Root MCP config missing"


      # Verify content in Cursor MCP config

      grep -q "custom-tool" .cursor/mcp.json || echo "FAIL: custom-tool not in
      Cursor config"

      grep -q "nodejs-server" .cursor/mcp.json || echo "FAIL: nodejs-server not
      in Cursor config"


      # Verify disabled tool is NOT included

      grep -q "disabled-tool" .cursor/mcp.json && echo "FAIL: disabled-tool
      should not be in config" || true


      # Verify environment variables are included

      grep -q "API_KEY" .cursor/mcp.json || echo "FAIL: environment variables
      not propagated"


      # Verify VS Code has different format (servers vs mcpServers)

      grep -q '"servers"' .vscode/mcp.json || echo "FAIL: VS Code format
      incorrect"

      grep -q '"mcpServers"' .cursor/mcp.json || echo "FAIL: Cursor format
      incorrect"


      # Verify root MCP has correct format

      grep -q '"mcpServers"' .mcp.json || echo "FAIL: Root MCP format incorrect"


      # Verify deterministic content hashes

      HASH1=$(grep -o '"content_hash":"[^"]*"' .cursor/mcp.json | head -1)

      HASH2=$(grep -o '"content_hash":"[^"]*"' .vscode/mcp.json | head -1)

      # Both should have valid SHA256 hashes (64 hex chars)

      echo "$HASH1" | grep -qE '[a-f0-9]{64}' || echo "FAIL: invalid content
      hash in cursor config"

      echo "$HASH2" | grep -qE '[a-f0-9]{64}' || echo "FAIL: invalid content
      hash in vscode config"

      ```


      **Expected:**


      - MCP configs written to all configured agent-specific paths

      - Server definitions propagated with correct format per agent

      - Disabled servers excluded from output

      - Environment variables included in output

      - Content hashes present and valid (SHA256)

      - VS Code gets `servers` format, Cursor/Root get `mcpServers` format


      #### Nested location import and export workflow


      Test that rules from nested directories are imported with
      `nested_location` frontmatter and exported back to the correct location:


      ```bash

      cd /tmp/test-nested-locations

      aligntrue init --mode solo --yes


      # Create a nested cursor rule at apps/docs/.aligntrue/rules/

      mkdir -p apps/docs/.cursor/rules

      cat > apps/docs/.aligntrue/rules/web_stack.mdc <<'EOF'

      ---

      description: Web stack guide for docs site

      ---


      # Web stack guide


      This rule is specific to the docs app.

      EOF


      # Run init to import the nested rule

      aligntrue init --yes --exporters cursor


      # Verify the imported rule has nested_location in frontmatter

      cat .aligntrue/rules/web_stack.md | grep "nested_location: apps/docs" ||
      echo "FAIL: nested_location missing"


      # Sync to export back

      aligntrue sync


      # Verify the rule was exported to the nested location (not root)

      test -f apps/docs/.aligntrue/rules/web_stack.mdc && echo "PASS: exported
      to nested location" || echo "FAIL: not exported to nested location"

      ```


      **Expected:**


      - Rules from nested directories get `nested_location` frontmatter during
      import

      - `original_path` frontmatter preserves the source location

      - Sync exports rules back to their nested locations

      - Root-level rules do NOT get `nested_location` frontmatter


      ### 3. Golden Paths (Team)


      **What:** Team mode workflows (lockfile, shared config, collaboration,
      personal rules)


      **Validate:**


      - Project init for team mode

      - Config sharing between developers

      - Lockfile generation and drift detection

      - Personal rules (local and remote)

      - Migration from solo to team mode

      - Joining existing team

      - Conflict behavior is clear

      - No hidden global state


      **Simulate:**


      - Two developers (user-a, user-b) in separate working directories

      - Real file operations, no mocks

      - Expected: explicit conflict messages, no silent overwrites


      **Key workflows to test:**


      1. **Solo → Team migration:**
         - `aligntrue team enable`
         - Creates `config.team.yaml` (team settings, committed)
         - Updates `config.yaml` (personal settings, gitignored)
         - Lockfile generation
         - Commit `config.team.yaml` (and lockfile) and push

      2. **Joining existing team:**
         - Clone team repository (has `config.team.yaml`)
         - `aligntrue init` (detects team mode from `config.team.yaml`)
         - Personal `config.yaml` created for local overrides
         - `aligntrue sync`

      3. **Personal remotes setup:**
         - Create private git repository for backup
         - Configure backup URL in config.yaml under `backup.default`
         - Push personal rules to remote with `aligntrue remotes push`
         - Verify git operations (push to remote)
         - Auto-backup during sync when `auto: true`

      4. **Team rule changes:**
         - Edit AGENTS.md (team sections)
         - `aligntrue sync`
         - Commit changes
         - PR approval workflow
         - Other team members pull and sync

      5. **Personal rule changes:**
         - Edit `.aligntrue/rules/` (personal rules)
         - `aligntrue sync`
         - Changes stay local or backup to remote if configured
         - No team approval needed for personal sources

      6. **Drift detection:**
         - Make unapproved changes
         - `aligntrue drift --gates` fails in CI
         - Team lead approves via PR or `aligntrue team approve`
         - CI passes

      **Drift detection testing is covered comprehensively in Section 3.1 and
      statefulness tests below. Key validations:**


      - Content hash-based comparison (deterministic, no timestamp issues)

      - Identical content with different timestamps does NOT trigger drift

      - Cross-platform reliability

      - No false positives from file copy operations


      7. **Multi-file agent editing:**
         - Edit Cursor scope files (e.g., `.aligntrue/rules/backend.mdc`, `.aligntrue/rules/frontend.mdc`)
         - Verify section routing and round-trip sync
         - Test conflict detection when same section edited in multiple files

      8. **Read-only file edit detection:**

         Test the system's ability to detect and backup manual edits to read-only files before overwriting:

         **Setup:**
         - Configure `edit_source: "AGENTS.md"` (makes Cursor files read-only)
         - Run `aligntrue sync` to establish baseline

         **Test steps:**
         - Edit `.aligntrue/rules/aligntrue.mdc` (a read-only file)
         - Run `aligntrue sync` (without --force)
         - Verify backup created in `.aligntrue/.backups/`
         - Verify file is overwritten with clean IR content

         **Expected behavior:**
         - Backup automatically created before overwriting
         - Backup location: `.aligntrue/.backups/TIMESTAMP-PID-SEQ/` (unified backup directory)
         - File overwritten with IR content (manual edit removed)
         - No --force flag needed for read-only files
         - Manual edit content preserved in backup

         **Test edit_source mode switching:**
         - Start with `edit_source: "AGENTS.md"`
         - Make edits to AGENTS.md, sync successfully
         - Change config to `edit_source: ".aligntrue/rules/*.mdc"`
         - Make edits to Cursor files, sync successfully
         - Verify both file types maintain their content correctly

      9. **Personal rules with remote backup:**
         - Configure backup in config.yaml
         - Modify personal rules and sync
         - Verify remote push operations

      ### Team testing patterns


      **Two approaches for testing team workflows:**


      #### Quick testing pattern (file copying)


      Use for fast, isolated tests that don't require git operations:


      ```bash

      # User A: Initialize team

      mkdir /tmp/team-user-a && cd /tmp/team-user-a

      aligntrue init --yes --mode team

      aligntrue sync  # Generates lockfile


      # User B: Join team (copy shared files)

      mkdir /tmp/team-user-b && cd /tmp/team-user-b

      cp -r /tmp/team-user-a/.aligntrue .

      cp /tmp/team-user-a/.aligntrue/config.team.yaml .aligntrue/

      cp /tmp/team-user-a/.aligntrue/lock.json .

      aligntrue team join --yes  # Creates personal config and gitignore entries

      aligntrue sync

      ```


      **When to use:**


      - Quick validation of basic team mode features

      - Testing lockfile generation and drift detection

      - Isolated tests that don't need git operations

      - Fast feedback during development


      **Limitations:**


      - Doesn't test actual git workflows

      - No merge conflict scenarios

      - No PR workflow validation

      - Git integration modes not tested


      #### Git-Based Testing Pattern (Comprehensive)


      **For realistic team collaboration scenarios with actual git operations,
      see Section 3.1 "Git-Based Team Collaboration" below.**


      That section provides comprehensive scenarios for:


      - Git repository setup and team initialization

      - All git integration modes (ignore, commit, branch)

      - Merge conflict handling

      - PR workflow testing

      - Git source update workflows

      - Remote backup testing


      **Note:** The file-copy pattern is useful for quick validation but doesn't
      test actual git workflows. Prefer Section 3.1 for comprehensive testing.


      #### Team backup and ignore file management


      Test backup and ignore file behavior in team mode:


      ```bash

      # Team user A: Enable team mode with backups

      cd /tmp/team-user-a

      aligntrue team enable


      # Verify backups created during team transition

      ls -la .aligntrue/.backups/

      test -f .aligntrue/lock.json || echo "FAIL: lockfile not created"


      # Verify ignore files managed correctly in team mode

      aligntrue sync

      test -f .cursorignore || echo "FAIL: ignore file missing in team mode"


      # Test that all sync operations create backups

      echo "### Team Rule" >> AGENTS.md

      aligntrue sync


      # Verify backup was created

      BACKUP_COUNT=$(ls -1 .aligntrue/.backups/ | wc -l)

      test $BACKUP_COUNT -gt 1 || echo "FAIL: backup not created for team sync"


      # Restore from backup (interactive preview shown automatically)

      LATEST_BACKUP=$(ls -t .aligntrue/.backups/ | head -1)

      aligntrue revert --timestamp "$LATEST_BACKUP" --yes


      # Verify restored state

      grep "### Team Rule" AGENTS.md && echo "FAIL: revert didn't work" || echo
      "PASS: state restored"


      # Team user B: Verify ignore files inherited from team

      cd /tmp/team-user-b

      cp -r /tmp/team-user-a/.aligntrue .

      cp /tmp/team-user-a/AGENTS.md .

      cp /tmp/team-user-a/.aligntrue/lock.json .


      # Init detects team mode

      aligntrue init --yes


      # Verify ignore files are present

      test -f .cursorignore || echo "FAIL: ignore file not inherited"


      # Sync should respect ignore file settings

      aligntrue sync

      ```


      **Expected:**


      - Backups created during team transitions

      - Ignore files properly configured in team mode

      - Backups inherited when cloning team repository

      - All sync operations create timestamped backups


      #### 3.1. Git-Based Team Collaboration


      **Implementation Status:** These scenarios should be implemented in
      `packages/cli/tests/comprehensive/layers/layer-3-team.ts`. Currently only
      basic team mode tests are implemented. The scenarios below define what the
      automated tests should cover.


      **Current coverage in layer-3-team.ts:**


      - [x] Enable team mode and generate lockfile

      - [x] Drift detection catches unapproved changes

      - [x] Personal rules stay local

      - [ ] A. Git Repository Setup and Team Initialization

      - [ ] B. Git Integration Modes Testing

      - [ ] C. Merge Conflict Scenarios

      - [ ] D. PR Workflow Testing

      - [ ] E. Git Source Update Workflows

      - [ ] F. Remotes Testing


      Test actual git operations for realistic team collaboration workflows.
      This section uses bare git repositories in `/tmp/` to simulate real team
      scenarios without network dependencies.


      **A. Git Repository Setup and Team Initialization:**


      ```bash

      # Setup bare repository (shared team repo)

      cd /tmp

      git init --bare team-repo.git

      # Set HEAD to main for clean clones

      git symbolic-ref HEAD refs/heads/main


      # Configure git user for test isolation

      export GIT_AUTHOR_NAME="Test User A"

      export GIT_AUTHOR_EMAIL="test-a@example.com"

      export GIT_COMMITTER_NAME="Test User A"

      export GIT_COMMITTER_EMAIL="test-a@example.com"


      # User A: Initialize team

      mkdir /tmp/team-user-a && cd /tmp/team-user-a

      git init

      git branch -M main

      git remote add origin /tmp/team-repo.git

      aligntrue init --yes --mode team

      aligntrue sync --yes  # Generates lockfile


      # Commit and push team configuration

      git add .aligntrue/ .aligntrue/lock.json

      git commit -m "Enable team mode"

      git branch -M main

      git push -u origin main


      # User B: Clone and join team

      cd /tmp

      export GIT_AUTHOR_NAME="Test User B"

      export GIT_AUTHOR_EMAIL="test-b@example.com"

      export GIT_COMMITTER_NAME="Test User B"

      export GIT_COMMITTER_EMAIL="test-b@example.com"


      git clone /tmp/team-repo.git team-user-b

      cd team-user-b

      aligntrue team join --yes  # Creates personal config and gitignore entries

      aligntrue sync


      # Verify lockfile and config are shared correctly

      test -f .aligntrue/lock.json || echo "FAIL: lockfile missing"

      test -f .aligntrue/config.team.yaml || echo "FAIL: team config missing"

      grep "mode: team" .aligntrue/config.team.yaml || echo "FAIL: team mode not
      detected"

      ```


      **Expected:**


      - Bare repository created successfully

      - User A can initialize team mode and push

      - User B can clone and detect team mode automatically

      - Lockfile and config are shared via git

      - Both users have identical team configuration


      **Automated test implementation:** Add this scenario to `layer-3-team.ts`
      using the `TeamScenario` interface with git commands executed via
      `execSync`. Create bare repo, set git users, and verify team
      initialization across two simulated users.


      **B. Git Integration Modes Testing:**


      Test the three git integration modes (ignore, commit, branch) and
      per-exporter overrides:


      ```bash

      # Setup test environment

      cd /tmp/test-git-modes

      git init

      git branch -M main

      aligntrue init --yes --mode team

      aligntrue exporters enable cursor


      # Branch mode requires at least one commit before it can create feature
      branches

      git add .

      git commit -m "Initial commit"


      # Test ignore mode (default for personal rules)

      aligntrue config set git.mode ignore

      aligntrue sync --yes

      grep "AGENTS.md" .gitignore || echo "FAIL: AGENTS.md not ignored"

      grep ".cursor/rules/*.mdc" .gitignore || echo "FAIL: .cursor/rules not
      ignored"


      # Test commit mode (for team shared rules)

      aligntrue config set git.mode commit

      aligntrue sync --yes

      git status --porcelain | grep "AGENTS.md" || echo "FAIL: AGENTS.md not
      staged for commit"

      # Note: commit mode ensures files are NOT in .gitignore


      # Test branch mode (for PR workflows)

      aligntrue config set git.mode branch

      aligntrue sync --yes

      git branch | grep "aligntrue/sync" || echo "FAIL: feature branch not
      created"

      BRANCH_NAME=$(git branch | grep "aligntrue/sync" | sed 's/^..//')

      test -n "$BRANCH_NAME" || echo "FAIL: branch name empty"

      git checkout "$BRANCH_NAME"

      git status --porcelain | grep "AGENTS.md" || echo "FAIL: files not staged
      on branch"


      # Test per-exporter override

      aligntrue config set git.mode ignore

      aligntrue config set git.per_exporter.cursor branch

      aligntrue sync --yes

      # Cursor files should be on branch, AGENTS.md should be ignored

      grep "AGENTS.md" .gitignore || echo "FAIL: AGENTS.md not ignored"

      git branch | grep "aligntrue/sync" || echo "FAIL: cursor branch not
      created"

      ```


      **Expected:**


      - Ignore mode adds files to `.gitignore`

      - Commit mode stages files for commit (not in `.gitignore`)

      - Branch mode creates feature branch and stages files

      - Per-exporter overrides work correctly

      - Multiple modes can coexist for different exporters


      **Automated test implementation:** Add this scenario to `layer-3-team.ts`
      using the `TeamScenario` interface. Test all three git modes and
      per-exporter overrides by modifying config and verifying git state
      changes.


      **C. Merge Conflict Scenarios:**


      Test git merge conflicts and resolution workflows:


      ```bash

      # Setup shared repository

      cd /tmp

      git init --bare team-repo.git

      git symbolic-ref HEAD refs/heads/main


      # User A: Make initial commit

      cd /tmp

      mkdir team-user-a && cd team-user-a

      git init

      git branch -M main

      git remote add origin /tmp/team-repo.git

      aligntrue init --yes --mode team

      echo "## Team Rule A" >> AGENTS.md

      aligntrue sync --yes

      git add . && git commit -m "Initial team rules"

      git push -u origin main


      # User B: Clone baseline

      cd /tmp

      git clone /tmp/team-repo.git team-user-b

      cd team-user-b

      echo "## Team Rule B" >> AGENTS.md

      aligntrue sync --yes

      git add . && git commit -m "Add rule B"


      # User A: Diverge and push

      cd /tmp/team-user-a

      echo "## Team Rule C" >> AGENTS.md

      aligntrue sync --yes

      git add . && git commit -m "Add rule C"

      git push origin main  # User A pushes first; user B will now diverge


      # User B: Create conflict, then pull

      cd /tmp/team-user-b

      git push origin main || echo "EXPECTED: push rejected (diverged)"

      git pull || echo "EXPECTED: merge conflict"

      test -f .aligntrue/lock.json || echo "FAIL: lockfile missing after merge"

      aligntrue drift --gates  # Validate lockfile integrity after resolving
      conflicts

      ```


      **Expected:**


      - Git merge conflicts are detected and reported

      - Lockfile conflicts are handled gracefully

      - `aligntrue drift --gates` validates lockfile after merge

      - Both users can resolve conflicts and continue working


      **Automated test implementation:** Add this scenario to `layer-3-team.ts`
      using the `TeamScenario` interface. Create conflicting commits from two
      users and verify both git merge conflicts and lockfile conflict handling.


      **D. PR Workflow Testing:**


      Test feature branch creation and PR simulation:


      ```bash

      # Setup with branch mode

      cd /tmp/test-pr-workflow

      git init

      git branch -M main

      aligntrue init --yes --mode team

      aligntrue config set git.mode branch


      # Make changes and sync (creates feature branch)

      # Edit rule sources (AGENTS.md is regenerated on sync)

      echo "## New Feature Rule" >> .aligntrue/rules/testing.md

      aligntrue sync --yes


      # Verify branch created

      BRANCH_NAME=$(git branch | grep "aligntrue/sync" | sed 's/^..//')

      test -n "$BRANCH_NAME" || echo "FAIL: branch not created"

      git checkout "$BRANCH_NAME"


      # Verify changes are on branch

      grep "New Feature Rule" .aligntrue/rules/testing.md || echo "FAIL: changes
      not on branch"


      # Simulate PR review: check drift before merge

      aligntrue drift --gates

      # Expected: Should pass if changes are approved


      # Simulate merge to main

      git checkout main

      git merge "$BRANCH_NAME" --no-ff -m "Merge feature branch"

      aligntrue sync --yes  # Should sync after merge


      # Test CI integration

      aligntrue drift --gates  # Should pass in CI after merge


      # Note: After merging a sync branch, set git.mode to commit or ignore if
      you want subsequent syncs to stay on main (branch mode will continue
      creating aligntrue/sync-* branches).

      ```


      **Expected:**


      - Branch mode creates feature branches automatically

      - Changes are isolated on feature branches

      - Drift detection works on feature branches

      - Merge workflows complete successfully

      - CI integration validates after merge


      **Automated test implementation:** Add this scenario to `layer-3-team.ts`
      using the `TeamScenario` interface. Test feature branch creation, drift
      validation on branches, and merge workflows with post-merge sync.


      **E. Git Source Update Workflows:**


      Test git source update checking workflows:


      **Note:** Local `file://` URLs are not supported for git sources. Use
      HTTPS URLs (e.g., `https://github.com/AlignTrue/examples`) or SSH URLs
      (e.g., `git@github.com:user/repo.git`) for testing.


      ```bash

      # Setup team mode with git source

      cd /tmp/test-git-updates

      aligntrue init --yes --mode team


      # Add git source using HTTPS URL (from AlignTrue examples repo)

      aligntrue add link https://github.com/AlignTrue/examples --personal

      aligntrue sync


      # Test update detection (branch reference checks daily)

      # Force update check

      aligntrue sync --force-refresh


      # Verify lockfile updated with source hash

      cat .aligntrue/lock.json | grep -i "hash"

      ```


      **Expected:**


      - Git source updates are detected in team mode

      - Lockfile reflects updated source hashes

      - Source changes pulled automatically on sync


      **Approval workflow in team mode:**


      Team mode uses PR-based approval via git, not a CLI command. When team
      rules change:


      1. Make changes to `.aligntrue/rules/` or update sources in
      `config.team.yaml`

      2. Run `aligntrue sync` to update lockfile

      3. Commit changes and create a PR

      4. Team reviews and approves the PR

      5. After merge, other team members run `aligntrue sync` to get updates


      Use `aligntrue drift --gates` in CI to enforce that lockfile matches the
      current rule state.


      **Note:** For testing update detection, you need an actual remote
      repository that changes over time. The AlignTrue/examples repo is stable,
      so update detection won't trigger unless the upstream repo is modified.


      **Automated test implementation:** Add this scenario to `layer-3-team.ts`
      using the `TeamScenario` interface. Configure a git source, test update
      detection with `--force-refresh`, and verify lockfile updates.


      **F. Remotes Testing (replaces remote backup):**


      **STATUS: IMPLEMENTED**


      This scenario tests the remotes feature that pushes local rules to remote
      git repositories. Remotes are for **push**; git sources are **pull**. Same
      URL cannot be both source AND remote (warning emitted).


      **Key concepts:**


      - **Source** = Pull (consume rules from remote)

      - **Remote** = Push (store your rules to remote)

      - Remote push happens automatically during `aligntrue sync` when `auto:
      true` is configured

      - `personal: true` on source = skip team approval + auto-gitignore

      - `gitignore: true` = don't commit rules (renamed from `private`)


      **IMPORTANT: Scope-based routing:**


      Files are routed to remotes based on `scope` frontmatter in rule files:


      - `scope: personal` → pushed to `remotes.personal`

      - `scope: shared` → pushed to `remotes.shared`

      - No scope or `scope: team` → stays in main repo (NOT pushed to any
      remote)


      To push all files regardless of scope, use `remotes.custom` with glob
      patterns.


      **For testing remotes (auto-push during sync):**


      ```bash

      # Create a test directory

      cd /tmp/test-remote-backup

      aligntrue init --mode solo --yes


      # Create rules WITH scope: personal frontmatter (required for personal
      remote)

      mkdir -p .aligntrue/rules/guides

      cat > .aligntrue/rules/typescript.md <<'EOF'

      ---

      scope: personal

      ---

      # TypeScript

      TypeScript coding standards.

      EOF


      cat > .aligntrue/rules/guides/react.md <<'EOF'

      ---

      scope: personal

      ---

      # React

      React development guide.

      EOF


      # Set up a local bare repo as remote target

      git init --bare /tmp/remote-repo.git


      # Configure remotes in config.yaml with auto: true

      cat >> .aligntrue/config.yaml <<'EOF'

      remotes:
        personal:
          url: /tmp/remote-repo.git
          branch: main
          auto: true
      EOF


      # Run sync - this automatically pushes to configured remotes when auto:
      true

      aligntrue sync

      # Should sync to agents AND push personal-scoped files to remote


      # Verify files were pushed

      git clone /tmp/remote-repo.git /tmp/verify

      ls /tmp/verify/

      # Should show: typescript.md, guides/react.md at repo root


      # (Optional) Preserve .aligntrue/rules layout by setting a path:

      # remotes:

      #   personal:

      #     url: /tmp/remote-repo.git

      #     branch: main

      #     path: .aligntrue/rules

      #     auto: true


      # Test that updates are pushed on subsequent syncs

      echo "Updated" >> .aligntrue/rules/typescript.md

      aligntrue sync

      # Should sync to agents AND push updated files to remote

      ```


      **Alternative: Push all files using custom patterns:**


      If you want to push ALL rule files regardless of scope, use
      `remotes.custom` with a glob pattern:


      ```bash

      # Configure custom remote with include pattern for all .md files

      cat >> .aligntrue/config.yaml <<'EOF'

      remotes:
        custom:
          - id: all-rules
            url: /tmp/remote-repo.git
            branch: main
            auto: true
            include:
              - "**/*.md"
      EOF

      ```


      **For testing multiple remote destinations:**


      ```bash

      # Configure additional remote with include patterns

      cat > .aligntrue/config.yaml <<'EOF'

      remotes:
        shared:
          url: /tmp/all-rules.git
          auto: true
        custom:
          - id: oss-only
            url: /tmp/oss-rules.git
            auto: true
            include:
              - typescript.md
              - "guides/*.md"
      EOF


      # Sync triggers auto-push to all configured remotes

      aligntrue sync

      # Files matching include go to oss-only (custom)

      # Remaining files go to shared

      ```


      **For testing source/remote conflict:**


      ```bash

      # Configure same URL as source AND remote (requires network)

      # Use a real git URL; local filesystem paths are not valid git sources.

      cat > .aligntrue/config.yaml <<'EOF'

      sources:
        - type: git
          url: https://github.com/AlignTrue/examples.git
      remotes:
        personal: https://github.com/AlignTrue/examples.git
      EOF


      aligntrue sync

      # Warning: URL configured as both source and remote. Skipping remote push.

      ```


      Notes:


      - Conflict detection only triggers for valid git URLs. Local filesystem
      paths (e.g., /tmp/\*.git) are rejected for sources.

      - If you need offline/local testing, use a reachable git URL in a local
      git server or mock; otherwise skip this scenario when offline.


      **Note:** Remote push can run automatically during `aligntrue sync` when
      `auto: true` is configured. You can also run `aligntrue remotes status`
      and `aligntrue remotes push` directly. To add a remote, use `aligntrue add
      remote <url>`.


      **Automated test implementation:** Add this scenario to `layer-3-team.ts`
      using the `TeamScenario` interface. Test auto-push during sync, multiple
      destinations with file assignments, and source/remote conflict detection.


      **Git Testing Best Practices:**


      - Always use bare repositories (`git init --bare`) for shared repos

      - Set git user config per test to avoid conflicts

      - Use file:// URLs for local repositories (no network needed)

      - Clean up test repositories after each test run

      - Verify git operations with `git status`, `git log`, `git branch`

      - Test both successful and conflict scenarios


      ### 3.5. Advanced Customization (Scopes, Plugs, Overlays)


      **What:** Test complex monorepo and customization scenarios


      **Scenario reference:** All scenarios are documented on the docs site with
      full configurations and explanations. Use these as reference when testing:


      - Scopes: https://aligntrue.ai/docs/02-customization/scopes#scenarios

      - Plugs: https://aligntrue.ai/docs/02-customization/plugs#scenarios

      - Overlays: https://aligntrue.ai/docs/02-customization/overlays#scenarios


      **Validate:**


      - Scopes: Path-based rule application in monorepos

      - Plugs: Template slot resolution with fills

      - Overlays: Fork-safe pack customization

      - Integration: All three features working together


      **Test scenarios:**


      #### Scopes workflows


      **1. Monorepo with 3 scopes (frontend, backend, worker):**


      ```bash

      cd /tmp/test-scopes-monorepo

      aligntrue init --mode solo --yes


      # Create monorepo structure

      mkdir -p apps/web/src packages/api/src services/worker


      # Create scope configuration

      cat > .aligntrue/config.yaml <<EOF

      mode: solo

      scopes:
        - path: "apps/web"
          include: ["**/*.ts", "**/*.tsx"]
          exclude: ["**/*.test.ts"]
          rulesets: ["base-rules", "nextjs-rules"]
        - path: "packages/api"
          include: ["**/*.ts"]
          exclude: ["**/*.test.ts"]
          rulesets: ["base-rules", "node-rules"]
        - path: "services/worker"
          include: ["**/*.py"]
          rulesets: ["base-rules", "python-rules"]
      merge:
        strategy: "deep"
        order: ["root", "path", "local"]
      exporters:
        - agents
        - cursor
      EOF


      # Sync and verify

      aligntrue sync

      aligntrue scopes  # Should show 3 scopes with correct paths


      # Verify scoped rules are applied (no scope-specific export files are
      created)

      # Scopes control applicability; use nested_location frontmatter for nested
      exports if needed

      aligntrue scopes | grep "apps/web" || echo "FAIL: web scope missing"

      aligntrue scopes | grep "packages/api" || echo "FAIL: api scope missing"

      aligntrue scopes | grep "services/worker" || echo "FAIL: worker scope
      missing"

      ```


      **Expected:**


      - 3 scopes configured and listed

      - Scopes control which paths rules apply to; exports stay under configured
      exporters

      - Hierarchical merge order applied


      **2. Include/exclude pattern validation:**


      ```bash

      # Test include patterns match correctly

      # Test exclude patterns filter correctly

      # Verify glob pattern validation errors

      ```


      **3. Scope conflicts and precedence:**


      ```bash

      # Create overlapping scopes

      # Verify last matching scope wins

      # Test default scope (path: ".")

      ```


      #### Plugs workflows


      **Note:** Plug slots are defined in rule files (`.aligntrue/rules/*.md`)
      using YAML frontmatter. Fills are config-only (`plugs.fills` in
      `.aligntrue/config.yaml`). Sync fails if required plugs are unresolved.


      **1. Slot declaration and fill resolution:**


      ```bash

      cd /tmp/test-plugs

      aligntrue init --mode solo --yes


      # Create a rule file with plug slots in YAML frontmatter

      cat > .aligntrue/rules/testing.md <<'EOF'

      ---

      description: Testing guidelines with configurable commands

      plugs:
        slots:
          test.cmd:
            description: "Command to run tests"
            format: command
            required: true
            example: "pytest -q"
          docs.url:
            description: "Documentation URL"
            format: url
            required: false
            example: "https://docs.example.com"
      ---


      # Testing guidelines


      Run tests with: [[plug:test.cmd]]


      Documentation: [[plug:docs.url]]

      EOF


      # Plugs status (shows unresolved required)

      aligntrue plugs

      # Should show: test.cmd (required, unresolved), docs.url (optional)


      # Set fill for required plug via CLI (saves to config.yaml under
      plugs.fills)

      aligntrue plugs set test.cmd "pnpm test"

      # Should validate format and update config.yaml


      # Verify fill was set

      aligntrue plugs

      # Should show: test.cmd filled (from config), docs.url optional


      # Test unset command

      aligntrue plugs unset test.cmd

      aligntrue plugs

      # Should show: test.cmd unresolved again


      # Set it back

      aligntrue plugs set test.cmd "pnpm test"


      # Test format validation (supported: command, text; file/url are
      deprecated and treated as text)

      aligntrue plugs set test.cmd "/absolute/path" || echo "Expected:
      validation error"

      aligntrue plugs set docs.url "not-a-url" || echo "Expected: validation
      error"

      aligntrue plugs set docs.url "https://docs.example.com"  # Should succeed


      # Status and verify resolution

      aligntrue plugs

      # Should show: test.cmd resolved to "pnpm test", docs.url resolved to URL


      # Sync and check output

      aligntrue sync

      grep "Run tests with: pnpm test" AGENTS.md || echo "FAIL: plug not
      resolved"

      ```


      **Expected:**


      - Slots defined in rule file frontmatter are detected

      - Fills stored in config.yaml under `plugs.fills`

      - Unresolved required plugs detected

      - Fill validation works (format checking)

      - Optional plugs resolve to empty string

      - Required plugs generate TODO blocks if unresolved


      **3. Comprehensive plugs testing (slots, fills, validation):**


      Test plugs configuration via config.yaml, fill precedence, and validation:


      ```bash

      cd /tmp/test-plugs-comprehensive

      aligntrue init --mode solo --yes


      # Create a rule file with plug slots in YAML frontmatter

      cat > .aligntrue/rules/testing.md <<'EOF'

      ---

      description: Testing guidelines with configurable values

      plugs:
        slots:
          test.cmd:
            description: "Command to run tests"
            format: command
            required: true
          docs.url:
            description: "Documentation URL"
            format: url
            required: false
          author.name:
            description: "Author name"
            format: text
            required: false
      ---


      # Testing guidelines


      Run tests with: [[plug:test.cmd]]


      Documentation: [[plug:docs.url]]


      Author: [[plug:author.name]]

      EOF


      # Set fills via CLI

      aligntrue plugs set test.cmd "pnpm test"

      aligntrue plugs set docs.url "https://docs.example.com"

      aligntrue plugs set author.name "Jane Smith"


      # Verify fills in config.yaml

      grep -A 5 "plugs:" .aligntrue/config.yaml | grep -q "test.cmd" || echo
      "FAIL: fills not in config"


      # Status and verify source (should show "from config")

      aligntrue plugs

      # Expected: All three slots filled with values from config


      # Status shows resolved values

      aligntrue plugs

      # Expected: All slots resolved to their fill values


      # Sync and verify fills are applied

      aligntrue sync


      # Check output has filled values

      grep "Run tests with: pnpm test" AGENTS.md || echo "FAIL: test.cmd not
      filled"

      grep "Documentation: https://docs.example.com" AGENTS.md || echo "FAIL:
      docs.url not filled"

      grep "Author: Jane Smith" AGENTS.md || echo "FAIL: author.name not filled"


      # Test unsetting a fill

      aligntrue plugs unset author.name


      # Verify it was removed

      grep "author.name" .aligntrue/config.yaml && echo "FAIL: unset didn't
      remove fill" || echo "PASS: fill removed"


      # Verify plugs status shows unset slot as unresolved

      aligntrue plugs | grep -q "author.name" || echo "FAIL: unset slot not
      shown"


      # Test invalid format values (file/url deprecated; treat as text)

      aligntrue plugs set test.cmd "/absolute/path" 2>&1 | grep -i "error" ||
      echo "FAIL: should reject absolute path"

      aligntrue plugs set docs.url "not-a-url" 2>&1 | grep -i "error" || echo
      "FAIL: should reject invalid URL"

      aligntrue plugs set docs.url "ftp://invalid" 2>&1 | grep -i "error" ||
      echo "FAIL: should reject invalid URL"


      # Test unresolved required plugs fail sync (strict by default)

      aligntrue plugs unset test.cmd

      aligntrue sync && echo "FAIL: sync should fail on unresolved required
      plug" || echo "PASS: sync failed as expected"

      ```


      **Expected:**


      - Fills stored in config.yaml under `plugs.fills`

      - Config fills take precedence over IR fills

      - Format validation works for all types (command, file, url, text)

      - Invalid formats rejected with clear error messages

      - `plugs set <slot> <value>` updates config

      - `plugs unset <slot>` removes config fill

      - `plugs list` shows fill source (config vs IR)

      - Unresolved required plugs generate TODO blocks in exports


      #### Overlays workflows


      **1. Override severity (warning → error):**


      ```bash

      cd /tmp/test-overlays

      aligntrue init --mode solo --yes


      # Create base pack

      cat > upstream-pack.yaml <<EOF

      id: upstream-pack

      version: "1.0.0"

      spec_version: "1"

      sections:
        - heading: "No console.log"
          content: "Avoid console.log in production"
          level: 2
          fingerprint: "no-console-log"
          severity: "warning"
      EOF


      # Configure with overlay

      cat > .aligntrue/config.yaml <<EOF

      mode: solo

      sources:
        - type: local
          path: upstream-pack.yaml
      overlays:
        overrides:
          - selector: "rule[id=no-console-log]"
            set:
              severity: "error"
      exporters:
        - agents
      EOF


      # Sync and verify overlay applied

      aligntrue sync

      aligntrue override         # Default shows status + diff


      # Check output has upgraded severity

      # (Implementation detail: verify in exported files)

      ```


      **2. Add check inputs (complexity threshold):**


      ```bash

      # Override with nested property

      aligntrue override add \
        --selector 'rule[id=max-complexity]' \
        --set check.inputs.threshold=15

      aligntrue override status  # Should show override

      ```


      **3. Remove autofix (use set null):**


      ```bash

      # Remove property from rule (remove is deprecated; use null)

      aligntrue override add \
        --selector 'rule[id=prefer-const]' \
        --set autofix=null

      aligntrue override diff  # Should show autofix removed

      ```


      **4. Multiple overlays and health checking:**


      ```bash

      # Add multiple overlays

      # Run aligntrue override (default status + diff)

      # Verify all show as "healthy"; conflicts fail unless allow flag is set


      # Simulate upstream change (rename rule ID)

      # Run aligntrue override status

      # Should show stale overlay warning

      ```


      #### Combined scenarios


      **1. Monorepo with scopes + plugs + overlays:**


      ```bash

      cd /tmp/test-combined

      aligntrue init --mode solo --yes


      # Configure all three features

      cat > .aligntrue/config.yaml <<EOF

      mode: solo

      scopes:
        - path: "apps/web"
          rulesets: ["nextjs-rules"]
        - path: "packages/api"
          rulesets: ["node-rules"]
      plugs:
        fills:
          test.cmd: "pnpm test"
          docs.url: "https://docs.example.com"
      overlays:
        overrides:
          - selector: "rule[id=no-console-log]"
            set:
              severity: "error"
      exporters:
        - agents
        - cursor
      EOF


      # Sync and verify all features work together

      aligntrue sync


      # Verify:

      # 1. Scopes applied (different rules per directory)

      # 2. Plugs resolved (test.cmd filled)

      # 3. Overlays applied (severity upgraded)

      ```


      **2. Scope-specific plug fills:**


      ```bash

      # Test that plugs can have different values per scope

      # Verify hierarchical merge order applies to plugs

      ```


      **3. End-to-end determinism:**


      ```bash

      # Run sync twice

      # Verify byte-identical outputs

      # Check content hashes match

      ```


      **Validation checklist:**


      - [ ] `aligntrue scopes` lists configured scopes correctly

      - [ ] `aligntrue plugs list` shows slots and fills

      - [ ] `aligntrue plugs resolve` previews resolution

      - [ ] `aligntrue override status` shows overlay health

      - [ ] `aligntrue override diff` shows changes

      - [ ] Combined features work without conflicts

      - [ ] Deterministic outputs (run sync twice, compare hashes)


      #### Multi-source merge scenarios


      **1. First-wins precedence:**


      Test that local rules always override external sources:


      ```bash

      cd /tmp/test-multi-source

      mkdir -p .aligntrue/rules


      # Local rule

      cat > .aligntrue/rules/security.md <<'EOF'

      ## No console


      Use console.log carefully (local version).

      EOF


      # Config with external source (would normally override in old system)

      cat > .aligntrue/config.yaml <<'EOF'

      mode: solo

      exporters:
        - agents
      EOF


      # Sync and verify local rule is used

      aligntrue sync


      # Expected: local rule content appears, not external

      grep "local version" AGENTS.md || echo "FAIL: local rule not used"

      ```


      **2. Source ordering in output:**


      Verify sync shows source precedence summary:


      ```bash

      cd /tmp/test-multi-source


      # Config with multiple sources

      cat > .aligntrue/config.yaml <<'EOF'

      mode: solo

      sources:
        - type: git
          include:
            - https://github.com/test/repo
      exporters:
        - agents
      EOF


      # Sync shows source precedence

      aligntrue sync 2>&1 | tee sync.log


      # Verify summary output

      grep "Sources.*priority" sync.log || echo "FAIL: no source summary"

      grep ".aligntrue/rules.*local" sync.log || echo "FAIL: local not listed
      first"

      ```


      **3. Include array syntax validation:**


      Test new `include` syntax accepts multiple URLs per source:


      ```bash

      cd /tmp/test-multi-source


      # Valid include array

      cat > .aligntrue/config.yaml <<'EOF'

      mode: solo

      sources:
        - type: git
          include:
            - https://github.com/company/rules
            - https://github.com/company/rules@v2.0.0/packs
            - https://github.com/other/rules/security.md
      exporters:
        - agents
      EOF


      # Config should be valid

      aligntrue check || echo "FAIL: config validation failed"

      ```


      **4. URL parsing with ref and path:**


      Test URL parsing for `https://github.com/org/repo@ref/path` format:


      ```bash

      cd /tmp/test-multi-source


      # Config with full URL format

      cat > .aligntrue/config.yaml <<'EOF'

      mode: solo

      sources:
        - type: git
          include:
            - https://github.com/company/rules                    # All .md in root
            - https://github.com/company/rules/packs              # All .md in directory
            - https://github.com/company/rules@v2.0.0             # Specific version
            - https://github.com/company/rules@v2.0.0/security.md # Version + file
      exporters:
        - agents
      EOF


      # Should validate without errors

      aligntrue check || echo "FAIL: URL parsing validation failed"

      ```


      **5. Add and remove sources workflow:**


      Test adding then removing a source works cleanly:


      ```bash

      mkdir -p /tmp/test-add-remove/.aligntrue/rules


      cd /tmp/test-add-remove


      # Initial config

      cat > .aligntrue/config.yaml <<'EOF'

      mode: solo

      exporters:
        - agents
      EOF


      echo "## Base" > .aligntrue/rules/base.md


      # Check initial status

      aligntrue status | grep "base.md" || echo "FAIL: base rule not found"


      # Add external source

      cat > .aligntrue/config.yaml <<'EOF'

      mode: solo

      sources:
        - type: git
          url: https://github.com/test/repo
          path: test.md
      exporters:
        - agents
      EOF


      # Verify config is valid

      aligntrue check || echo "FAIL: config with source is invalid"


      # Remove the source

      cat > .aligntrue/config.yaml <<'EOF'

      mode: solo

      exporters:
        - agents
      EOF


      # Verify config is still valid

      aligntrue check || echo "FAIL: config after removing source is invalid"

      ```


      **6. Conflict detection with first-wins:**


      Verify conflicts are reported showing which source wins:


      ```bash

      # Expected output shows:

      # - Rule exists in multiple sources

      # - Which source wins (highest priority)

      # - Why (precedence explanation)

      ```


      ### 4. Command Coverage


      **What:** Systematic breadth across all commands


      **For each command:**


      - Happy path with valid inputs

      - Required flags missing (should error clearly)

      - Invalid input (should error with fix suggestion)

      - Conflicting flags (should error or warn)

      - `--help` exists and matches actual behavior


      **Validate exit codes:**


      - 0 on success

      - Non-zero with clear message on failure


      **Deriving command list from codebase:**


      Command coverage should be derived from the current codebase to avoid
      drifting from reality. Use these authoritative sources:


      1. **Available commands:** `packages/cli/src/commands/index.ts` exports
      all available commands

      2. **Command implementations:** `packages/cli/src/commands/*.ts` files
      define each command's behavior and flags

      3. **CLI help text:** Run `aligntrue --help` to verify current available
      commands at test time


      **Test approach:**


      1. Scan `packages/cli/src/commands/index.ts` to get the complete list

      2. For each exported command, verify:
         - Happy path with valid inputs works
         - Required flags missing produces clear error
         - Invalid input produces helpful error with fix suggestion
         - Conflicting flags error or warn appropriately
         - `--help` exists and matches actual behavior

      3. Check exit codes:
         - 0 on success
         - Non-zero with clear message on failure

      **Common flag patterns to validate:**


      - `--force`, `--force-invalid-ir`, `--force-refresh`, `--dry-run` — `sync`
      only

      - `--yes`, `-y`, `--non-interactive` — `init`, `migrate`, `revert`

      - `--ci` — `check` only

      - `--gates` — `drift` only

      - `--content-mode` — `sync` only


      Tip: Run `aligntrue <command> --help` for full flag details.


      **Plugin contract validation:**


      Note: The `ExporterPlugin` interface in `@aligntrue/plugin-contracts`
      includes an optional `resetState()` method:


      - Allows exporters to clear internal state (like warning counters) between
      sync runs

      - Fully backward compatible (optional method)

      - Used to prevent state leakage across multiple sync operations

      - Not directly testable via CLI, but important for plugin developers


      **Coverage notes:**


      Some commands require special setup or are destructive and may have lower
      coverage in automated tests:


      - `backup cleanup` - Would delete actual backups

      - `plugs set/unset/resolve` - Requires plug definitions in rules

      - `exporters detect/enable/disable` - Requires specific agent files
      present

      - `migrate config` - Splits legacy single-file team configs into two-file
      system

      - `migrate personal/team/ruler` - Requires schema changes to exist

      - `sources split` - Requires large AGENTS.md file

      - `uninstall` - Destructive operation

      - `doctor` - Health check command (requires workspace setup)

      - `remove` - Removes sources (requires configured sources)

      - `rules list` - Lists rules by agent (requires rules to be defined)

      - `add link` / `add remote` - New subcommands (covered in golden path
      tests)


      Comprehensive coverage for these commands is provided by dedicated
      integration tests in `packages/cli/tests/integration/`. When adding or
      updating commands, verify related integration tests exist at
      `packages/cli/tests/` and that your command implementation is exported
      from `packages/cli/src/commands/index.ts`.


      ### 5. Statefulness


      **What:** Real-world persistence and state management scenarios


      **Test with:**


      - No config (first run)

      - Valid config

      - Corrupted config (malformed YAML)

      - Partial state (cache exists but config missing)

      - Backup recovery from various states


      **Validate:**


      - State is stored in documented locations (.aligntrue/,
      .aligntrue/lock.json, .aligntrue/.backups/)

      - Cache invalidation works correctly

      - Backup system maintains file integrity

      - Restore operations recover proper state

      - **Drift log persists across sessions**


      ### Drift log persistence (statefulness testing — team mode only)


      #### Drift log persistence


      **Note:** Drift log (`.aligntrue/.drift-log.json`) is only created in
      **team mode**. Solo mode intentionally does not write a drift log.


      Test that drift log persists across sessions and sync operations in team
      mode:


      ```bash

      cd /tmp/test-drift-persistence

      aligntrue init --mode team --yes  # team mode required


      # Add untracked files

      echo "## Rule 1" > FILE1.md

      echo "## Rule 2" > FILE2.md

      echo "## Rule 3" > FILE3.md


      # Run sync once - should detect all three

      aligntrue sync --yes


      # Verify drift log created

      test -f .aligntrue/.drift-log.json || echo "FAIL: drift log missing"

      DETECTION_COUNT=$(cat .aligntrue/.drift-log.json | grep -c '"file"')

      test $DETECTION_COUNT -eq 3 || echo "FAIL: expected 3 detections, got
      $DETECTION_COUNT"


      # Exit and restart (simulating session end/start)

      cd /

      cd /tmp/test-drift-persistence


      # Drift log should still exist

      test -f .aligntrue/.drift-log.json || echo "FAIL: drift log not persisted"


      # Run sync again - should remember previous state

      aligntrue sync --yes


      # Verify detections updated (not duplicated)

      DETECTION_COUNT=$(cat .aligntrue/.drift-log.json | grep -c '"file"')

      test $DETECTION_COUNT -eq 3 || echo "FAIL: detections duplicated, got
      $DETECTION_COUNT"


      # Verify timestamps updated

      cat .aligntrue/.drift-log.json | grep "timestamp"

      ```


      **Expected:**


      - Drift log persists across sessions

      - File system state preserved in `.aligntrue/.drift-log.json`

      - No duplication of detections on subsequent syncs

      - Timestamps update correctly


      ### 6. Environment Matrix


      **What:** Cross-platform and runtime validation


      **Reason about behavior on:**


      - macOS, Linux, Windows

      - Different shells (bash, zsh, fish, cmd, powershell)

      - Node versions (20 LTS, 22, latest)

      - CI environments (GitHub Actions, local scripts)


      **Node.js support:**


      - Minimum: Node 20 LTS (supported until April 2026)

      - Recommended: Node 20 or 22

      - CI validates both Node 20 and Node 22 compatibility


      **Validate:**


      - Commands are scriptable and deterministic

      - Paths use correct separators

      - No platform-specific assumptions leak


      ### 7. Error & UX


      **What:** User trust via helpful errors and predictable behavior


      **Validate:**


      - Error messages state what failed, why, and how to fix

      - Exit codes follow conventions (0=ok, 1=validation, 2=user error,
      3=system error)

      - Progress indicators only for operations >10s

      - No sensitive data in logs

      - Deterministic outputs (same inputs → same outputs)


      ### 8. Exploratory


      **What:** Find unknown unknowns after structured coverage


      **Behave as:**


      - A clever user who skimmed the docs

      - Goal: break the CLI or find confusing behavior using only supported
      commands


      **Propose 10-15 strange but plausible sequences:**


      - Rapid mode switches (solo → team → solo)

      - Conflicting config changes

      - Partial file deletions mid-operation

      - Race conditions (two terminals, same repo)

      - Edge cases from real usage patterns


      **Document:**


      - What bug or confusion you are probing for

      - Actual behavior vs expected behavior

      - Severity (blocks adoption vs polish)


      ---


      ## Execution protocol


      ### Before testing


      **0. Validate understanding:**


      - Read `/apps/docs/content/06-development/architecture.md` section on sync
      behavior


      **1. Scan the repo:**


      - `packages/cli/src/commands/*.ts` - list all commands

      - `packages/cli/README.md` - document CLI usage

      - `apps/docs/content/00-getting-started/00-quickstart.mdx` - quickstart
      flows

      - `CHANGELOG.md` - recent changes that need validation


      **2. Build command inventory in scratchpad:**


      Run `aligntrue --help` and scan `packages/cli/src/commands/*.ts` to build
      complete current inventory.


      **Verification:**

      Always cross-check with `aligntrue --help` output and
      `packages/cli/src/commands/index.ts` exports to ensure completeness.


      Use your derived inventory as ground truth for test design.


      **3. Check last test log:**


      - Read `.internal_docs/TEST_LOG.md` if exists

      - Identify gaps and untested areas

      - Plan this session to complement previous runs


      ### During testing


      **CRITICAL: Testing Only, No Fixes**


      **⚠️ ABSOLUTE REQUIREMENT: NEVER TEST IN REPO ROOT ⚠️**


      **NEVER run test commands from the workspace root directory
      (`/path/to/aligntrue` or any path containing `.aligntrue/`).**


      **ALWAYS:**


      - Create isolated test directories in `/tmp/` (e.g.,
      `/tmp/aligntrue-test-{timestamp}`)

      - Change directory INTO the test directory BEFORE running any CLI commands

      - Use absolute paths to the CLI binary if needed:
      `/path/to/workspace/packages/cli/dist/index.js`

      - OR use `pnpm link --global` first, then run `aligntrue` from the test
      directory


      **WHY:** The repo root contains the user's actual AlignTrue configuration.
      Running `init`, `sync`, or other commands there will:


      - Detect existing `.aligntrue/` directory and exit early

      - Potentially corrupt or modify the user's real configuration

      - Make validation impossible to test

      - Risk data loss or configuration damage


      **Example CORRECT workflow:**


      ```bash

      # ✅ CORRECT: Create test dir and work from there

      cd /tmp

      TEST_DIR="aligntrue-test-$(date +%s)"

      mkdir "$TEST_DIR" && cd "$TEST_DIR"

      # Now run CLI commands here, not from repo root

      /path/to/workspace/packages/cli/dist/index.js init --yes

      ```


      **Example WRONG workflow:**


      ```bash

      # ❌ WRONG: Running from repo root

      cd /path/to/workspace

      node packages/cli/dist/index.js init  # NO! This will detect existing
      .aligntrue/

      ```


      **Safety Guards (Automatic):**


      All test layers now include automatic safety checks:


      ```typescript

      // Every layer starts with:

      assertTestSafety();


      // This verifies:

      // 1. Current directory is in /tmp/ (isolated)

      // 2. TEST_WORKSPACE env var points to isolated directory

      // 3. ALIGNTRUE_CLI env var points to correct binary

      // 4. LOG_FILE env var is set for output

      ```


      If these checks fail, tests immediately exit with a clear error message
      explaining the problem.


      **AI must NOT:**


      - Modify any source code files (except test files created in the hermetic
      test environment)

      - Attempt to fix bugs or issues discovered during testing

      - Make changes to the main workspace or repository

      - Implement recommendations or solutions

      - **Run any CLI commands from the workspace root directory**


      **AI must ONLY:**


      - Execute test commands in the hermetic test environment
      (`/tmp/aligntrue-test-{timestamp}`)

      - **ALWAYS change directory into the test directory before running CLI
      commands**

      - Capture outputs, exit codes, and execution times

      - Document findings with severity (P0-P3)

      - Provide actionable recommendations for the user to review

      - Report all issues in `.internal_docs/TEST_LOG.md`


      **All fixes and code changes are the user's responsibility.** The AI's
      role is to discover and document issues, not to resolve them.


      ---


      **Work in hermetic sandbox:** AI must create test directories for Layer 1
      package testing, execute tests, capture outputs, and clean up
      automatically.


      **Create test environment:**


      ```bash

      # For layer 1 (distribution package testing)

      # Build and pack from workspace (this is safe - just creates a file)

      cd /path/to/workspace/packages/cli

      pnpm pack  # Creates aligntrue-cli-X.Y.Z.tgz in current directory


      # ⚠️ CRITICAL: Create test directory OUTSIDE workspace and work from there

      cd /tmp

      TEST_DIR="aligntrue-test-$(date +%s)"

      mkdir "$TEST_DIR" && cd "$TEST_DIR"

      # NOW we're in a clean test directory, safe to run CLI commands


      # Install from tarball (or use pnpm link --global)

      npm install -g /path/to/workspace/packages/cli/aligntrue-cli-*.tgz

      export TZ=UTC

      export NODE_ENV=test

      node --version

      npm --version

      which aligntrue

      ```


      **For Layers 2-8 (feature testing):**


      **Note:** Create isolated test directories in `/tmp` (see "During testing"
      section for critical safety requirements).


      ```bash

      # Create isolated test directory

      cd /tmp

      TEST_DIR="aligntrue-test-$(date +%s)"

      mkdir "$TEST_DIR" && cd "$TEST_DIR"

      # NOW we're in a clean test directory


      # Use CLI from workspace (absolute path) OR use pnpm link --global

      export TZ=UTC

      export NODE_ENV=test

      node --version

      pnpm --version


      # Option 1: Use absolute path to CLI

      /path/to/workspace/packages/cli/dist/index.js init --yes


      # Option 2: NOT RECOMMENDED - pnpm link --global does not work

      # DO NOT USE pnpm link --global - it fails with
      ERR_PACKAGE_PATH_NOT_EXPORTED

      # due to workspace:* protocol incompatibility with symlinks

      ```


      **Why this approach:**


      - Layer 1 tests the actual packaged artifact users receive, catching
      packaging issues (missing files, wrong bin links)

      - Tests real global installation experience via `npm install -g`, not
      monorepo `pnpm` commands

      - Layers 2-8 use local workspace for fast feature validation without
      installation overhead

      - Works reliably with AI terminal execution (no GitHub cloning failures)


      **Execute charter layers 1-8 in order.**


      **Important:** See "During testing" section above for critical workspace
      root safety requirements.


      **Record findings as you go:**


      - Command that failed

      - Expected vs actual behavior

      - Severity (P0=blocks adoption, P1=major friction, P2=polish,
      P3=nice-to-have)

      - Root cause if identifiable


      ---


      ### AI Execution Checklist


      **⚠️ MANDATORY: ALL TESTS MUST BE COMPLETED ⚠️**


      **Testing Completeness Requirements:**


      - Execute EVERY test scenario listed in the playbook

      - Complete ALL git-based team collaboration tests (Section 3.1 A-F)

      - Test all available commands systematically (derive list from codebase)

      - Cover ALL layers completely (1-8)

      - NO shortcuts, NO partial coverage, NO time-based limitations

      - If a test requires setup (git repos, multiple users), CREATE that setup
      - do not skip

      - Document completion status for every test scenario

      - Gaps are only acceptable if a test is fundamentally impossible to run
      (explain why)


      **Time is NOT a constraint** - Test completeness is the ONLY priority.


      When running automated tests, the AI must complete all steps:


      **Setup:**


      - [ ] **CRITICAL: Create test directory in /tmp and change into it BEFORE
      any CLI commands**

      - [ ] For Layer 1: Build all workspace packages with `cd
      /path/to/workspace && pnpm build`

      - [ ] For Layer 1: Create tarball with `cd packages/cli && pnpm pack`
      (safe - just creates file)

      - [ ] For Layer 1: Run distribution simulation script: `cd packages/cli &&
      bash tests/scripts/test-distribution.sh`

      - [ ] For Layers 2-8: Build workspace packages first, then use absolute
      path to CLI (NEVER use `pnpm link --global`)

      - [ ] Set environment variables: `TZ=UTC` and `NODE_ENV=test`

      - [ ] Verify Node and npm/pnpm versions

      - [ ] For Layer 1: Verify `which aligntrue` shows global install path


      **Execution:**


      - [ ] Run each test command from the layer definition

      - [ ] **Execute ALL scenarios in each layer - no shortcuts**

      - [ ] **For Layer 3: Complete ALL git-based team collaboration tests
      (A-F)**

      - [ ] **For Layer 3: Set up bare repos, multiple users, and all git
      workflows**

      - [ ] **For Layer 4: Test all available commands (derive from
      packages/cli/src/commands/index.ts)**

      - [ ] Capture stdout and stderr for all commands

      - [ ] Record exit codes (0=success, non-zero=failure)

      - [ ] Measure execution time for performance-sensitive commands

      - [ ] Take snapshots of file system state before and after operations

      - [ ] Save all outputs to log file for analysis

      - [ ] **Verify every test scenario was executed - check against playbook**


      **Analysis:**


      - [ ] Compare actual vs expected outputs for each test

      - [ ] Identify error patterns and failure modes

      - [ ] Assign severity to each issue (P0=blocker, P1=major, P2=polish,
      P3=nice-to-have)

      - [ ] Determine root cause when identifiable

      - [ ] Note any platform-specific behaviors

      - [ ] Flag non-deterministic outputs


      **Reporting:**


      - [ ] Write findings to `.internal_docs/TEST_LOG.md`

      - [ ] Include all commands run with their outputs

      - [ ] List all issues found with severity and root causes

      - [ ] Document gaps for next test run

      - [ ] Provide actionable recommendations

      - [ ] Include performance metrics where relevant


      **Cleanup:**


      - [ ] Remove test directory: `rm -rf /tmp/aligntrue-test-{timestamp}`

      - [ ] Remove package tarballs: `rm -f packages/cli/aligntrue-cli-*.tgz`

      - [ ] Verify no artifacts left in workspace

      - [ ] Confirm no background processes running

      - [ ] Automatic cleanup runs before and after tests (keeps last 3 runs or
      24 hours)


      **Cleanup Policy:**


      Test artifacts are automatically cleaned up by
      `packages/cli/tests/comprehensive/run-all-layers.ts`:


      - **Test directories:** `/tmp/aligntrue-test-*` (keeps last 3 runs OR
      directories newer than 24 hours)

      - **Package tarballs:** `packages/cli/aligntrue-cli-*.tgz` (removed after
      each Layer 1 test)

      - **Runs automatically:** Before and after comprehensive test runs via
      `cleanupOldTestDirs()`

      - **Manual cleanup:**
        - Test directories: `find /tmp -maxdepth 1 -name "aligntrue-test-*" -mtime +1 -exec rm -rf {} \;`
        - Package tarballs: `find packages/cli -name "aligntrue-cli-*.tgz" -exec rm {} \;`

      ---


      ### Automated output analysis


      **Exit Code Validation:**


      Capture and validate exit codes for every command:


      ```bash

      # Pattern for capturing exit codes

      aligntrue sync

      EXIT_CODE=$?

      if [ $EXIT_CODE -ne 0 ]; then
        echo "FAIL: Expected 0, got $EXIT_CODE"
        echo "Command: aligntrue sync"
        echo "Stderr: $(cat stderr.log)"
      fi

      ```


      **Expected exit codes:**


      - 0: Success

      - 1: Validation error

      - 2: User input error

      - 3: System error


      **Output Pattern Matching:**


      Look for these indicators in command output:


      **Success indicators:**


      - "✓" or "✔"

      - "Success"

      - "completed"

      - "done"


      **Error indicators:**


      - "Error:"

      - "Failed:"

      - "✗" or "✘"

      - Non-zero exit code


      **Warning indicators:**


      - "Warning:"

      - "⚠"

      - "Note:"


      **File Validation:**


      Verify expected files exist and contain correct content:


      ```bash

      # Check file existence

      test -f .aligntrue/config.yaml || echo "FAIL: config.yaml missing"

      test -d .aligntrue/rules || echo "FAIL: rules directory missing"

      test -f AGENTS.md || echo "FAIL: AGENTS.md missing"


      # Check directory structure

      test -d .cursor/rules || echo "FAIL: .cursor/rules directory missing"

      ```


      **Content Validation:**


      ```bash

      # Verify file contents contain expected patterns

      grep -q "profile:" .aligntrue/config.yaml || echo "FAIL: profile field
      missing in config"

      grep -q "sections:" .aligntrue/rules || echo "FAIL: sections missing in
      IR"


      # Verify JSON structure

      jq -e '.version' .aligntrue/lock.json || echo "FAIL: lockfile missing
      version"

      ```


      **Large Rule Set Testing:**


      Test CLI performance with realistic large rule sets:


      **Note:** The `examples/remote-test/large-rules/` directory contains
      markdown files with YAML frontmatter. These are proper markdown sources
      (not pure YAML IR files) and should be used as `type: local` sources in
      config.


      ```bash

      # Copy large rule fixtures (markdown files with YAML frontmatter)

      cp -r examples/remote-test/large-rules /tmp/test-project/rules


      # Configure all files as sources

      cat > .aligntrue/config.yaml <<EOF

      mode: solo

      sources:
        - type: local
          path: rules/backend-api.md
        - type: local
          path: rules/frontend-react.md
        - type: local
          path: rules/database.md
        - type: local
          path: rules/testing-integration.md
        - type: local
          path: rules/security-auth.md
        - type: local
          path: rules/devops-ci.md
        - type: local
          path: rules/code-review.md
        - type: local
          path: rules/documentation.md
        - type: local
          path: rules/performance.md
        - type: local
          path: rules/accessibility.md
      exporters:
        - agents
        - cursor
      EOF


      # Measure sync time

      time aligntrue sync


      # Expected: <60 seconds for 80-100 sections (10 files × 8-10 sections
      each)

      # Expected: <500MB memory usage

      # Expected: All files processed successfully

      # Expected: AGENTS.md and .aligntrue/rules/*.mdc contain merged content
      from all sources

      ```


      **Performance Validation:**


      ```bash

      # Time command execution

      START=$(date +%s%N)

      aligntrue --help

      END=$(date +%s%N)

      DURATION=$(( (END - START) / 1000000 ))  # Convert to milliseconds


      if [ $DURATION -gt 1000 ]; then
        echo "FAIL: --help took ${DURATION}ms (expected <1000ms)"
      fi


      # Performance thresholds for large rule sets

      # - Init: <10 seconds

      # - Sync (100-150 sections): <60 seconds (first run), <30 seconds
      (subsequent)

      # - Help: <5 seconds

      # - Memory: <500MB heap for large rule sets

      ```


      **Determinism Validation:**


      ```bash

      # Run command twice and compare outputs

      aligntrue sync --dry-run > output1.txt 2>&1

      aligntrue sync --dry-run > output2.txt 2>&1


      if ! diff -q output1.txt output2.txt; then
        echo "FAIL: Non-deterministic output detected"
        diff -u output1.txt output2.txt
      fi

      ```


      **Log Analysis:**


      Parse logs for common issues:


      - Sensitive data exposure (tokens, keys, passwords)

      - Stack traces in user-facing output

      - Unclear error messages

      - Missing "how to fix" guidance

      - Inconsistent formatting


      ---


      ### After testing


      **Log results to `.internal_docs/TEST_LOG.md`:**


      Append entry:


      ```markdown

      ## Test run YYYY-MM-DD


      **Commit:** abc123def

      **Scope:** Solo workflows, command coverage

      **Duration:** ~45 minutes


      **Scenarios Executed:**


      - ✅ Smoke tests (install, help, version)

      - ✅ Solo golden paths (init → sync → export)

      - ⚠️ Command coverage (3/15 commands tested)

      - ❌ Team workflows (deferred)


      **Notable Findings:**


      - P1: `aligntrue check` exits 0 on validation errors (should be non-zero)

      - P2: `aligntrue override add` unclear error when pack not found

      - P3: Help text for `--force` flag inconsistent across commands


      **Gaps for Next Run:**


      - Complete command coverage (12 commands remaining)

      - Team mode simulation (lockfile workflows)

      - Environment matrix (test on Linux CI)


      **Files Created:**


      - (none, logs only)

      ```


      **Format:**


      - Date, commit hash, scope, duration

      - Checklist of charter layers executed

      - Findings with severity

      - Gaps to test next time


      **Do NOT fabricate results.** If you cannot run commands, describe what
      SHOULD be tested instead.


      ---


      ## Steer vs Wander


      **When to steer (structured):**


      - Before releases

      - After major refactors

      - When validating new features

      - When fixing regressions


      Use charter layers 1-7 systematically.


      **When to wander (exploratory):**


      - After structured coverage is complete

      - When hunting for edge cases

      - When simulating creative user behavior


      Use charter layer 8 to find unknowns.


      **Never:**


      - Pure wandering without charter guidance (misses boring vital stuff)

      - Pure checklist execution without adaptation (tests rot)


      **Balance:**

      Rules define structure. AI derives specifics from live repo. Log what's
      tested for incremental coverage.


      ---


      ## Success criteria


      **Tests are effective when:**


      - Real blockers found before users hit them

      - Gaps explicitly documented for next run

      - Findings include severity and root cause

      - Test log shows incremental coverage over time


      **Tests are ineffective when:**


      - AI clusters around obvious paths only

      - Same scenarios repeated without learning

      - Findings are vague ("seems slow") without data

      - No logging of what was validated
    level: 2
    fingerprint: cli-testing-playbook-comp
    source_file: .aligntrue/rules/cli_testing_playbook_COMP.md
    vendor:
      aligntrue:
        frontmatter:
          description: Systematic CLI testing playbook for AI agents
          enabled: false
          title: CLI Testing Playbook Comp
  - heading: Debugging
    content: >

      # Debugging workflow


      **When to apply:** Investigating bugs, unexpected behavior, test failures,
      or non-deterministic outputs. Use this before making code changes.


      ## Core principle


      **Diagnose first, fix second.** Symptoms lie. Contracts and data flow do
      not.


      ---


      ## Top 5 time-wasters to avoid


      1. Pattern matching fixes that "look like last time"

      2. Fixing symptoms (exporter) when root cause is upstream
      (bundle/lock/schema)

      3. Assuming examples and quickstarts are correct

      4. Ignoring environment drift (TZ, Node, OS, CI)

      5. Trial and error edits without a hypothesis


      If you catch any of these: stop and read the error literally.


      ---


      ## Investigation framework


      ### 1. Read the error literally


      ```

      UndefinedError: 'object' has no property 'contentHash'

      ```


      Extract facts:


      - Type: object

      - Missing: contentHash

      - Suspect: shape/contract mismatch


      Ask: Why is the key missing? Not "How do I access it differently?"


      ### 2. Trace the data flow


      Map source → transforms → destination.


      ```

      load config → resolve packs → bundle → build context → exporter (error)

      ↑

      Likely fix lives here

      ```


      Answer:


      1. Where does the data originate?

      2. What transforms it?

      3. What does the consumer expect?

      4. Where do actual vs expected diverge?


      ### 3. Inspect actual state


      Do not guess. Log the real shape. Remove logs before commit.


      ```typescript

      const log = (o: unknown) => {
        console.debug("type:", Array.isArray(o) ? "array" : typeof o);
        try {
          console.debug("preview:", JSON.stringify(o, null, 2).slice(0, 2000));
        } catch {}
      };

      log(ctx);

      ```


      ### 4. Compare expected vs actual


      ```typescript

      // Expected

      const expected = { contentHash: "sha256:...", rules: [] };


      // Actual

      const actual = {
        hash: "sha256:...",
        rules: [],
        meta: { contentHash: "sha256:..." },
      };

      // Root cause: contentHash nested under meta instead of top level

      ```


      Fix the transformation or normalization, not templates or call sites that
      already match the contract.


      ### 5. Identify the root cause


      Keep asking "why" until you hit a contract boundary:


      - Symptom: exporter missing contentHash

      - Why: context builder never flattened metadata

      - Why: bundle layout changed, normalization not updated

      - Root cause: missing normalization step

      - Fix: add normalization in shared context builder


      ### 6. Fix at the right layer


      Use this matrix:


      | Situation                                | Fix location               |
      Reason                |

      | ---------------------------------------- | -------------------------- |
      --------------------- |

      | Nested vs flat mismatch across consumers | Normalization/shared layer |
      One source of truth   |

      | One consumer needs special format        | That consumer              |
      Localize special case |

      | Shared contract used by many             | Shared helpers             |
      Consistency and DRY   |


      ### 7. Verify the fix


      Prove the contract, do not just silence the error.


      ```typescript

      expect(ctx.contentHash).toMatch(/^sha256:/);

      expect(bytes(exportMdc(ctx))).toStrictEqual(bytes(exportMdc(ctx)));

      ```


      Checklist:


      - Error is gone

      - Root cause understood and documented

      - Correct layer changed

      - Contract test added to prevent regression


      ---


      ## Common anti-patterns


      - "Fix and see" loops

      - Copying old fixes based on similar messages

      - Only reproducing via full system runs (no minimal repro)

      - Treating docs/examples as ground truth without verifying

      - Token churning: repeated edits without fixing the underlying contract


      If you see this pattern, reset to the investigation framework above.


      ---


      ## CI Failures


      For troubleshooting CI issues, always follow the guidance in
      `.cursor/rules/ci_troubleshooting.mdc` to conserve API rate limits.


      Key command: `pnpm ci:errors`


      ---


      ## Git safety


      Always stash before destructive operations.


      ```bash

      git stash push -m "WIP: <desc>"

      git checkout <branch>   # or git switch/reset

      # ... investigate ...

      git stash pop

      ```


      Never:


      - Run git checkout or git reset with uncommitted changes without stashing

      - Assume uncommitted work is recoverable


      If you did it anyway:


      1. `git reflog`

      2. `git stash list`

      3. `git fsck --lost-found`

      4. If still lost, rebuild. Prevention is cheaper.


      ---


      ## Recognizing and stopping token churning


      Churning = burning tokens on repeated edits without fixing the underlying
      contract.


      Warning signs:


      1. Same type of tweak 3+ times in a row

      2. Bulk search/replace before proving pattern

      3. Editing tests to match outputs instead of fixing behavior

      4. Fighting mocks instead of understanding code under test

      5. Huge token use, small actual progress


      Reset with three questions:


      1. What pattern am I repeating?

      2. What is the actual contract or behavior?

      3. Which single layer is wrong?


      Then:


      1. Fix one representative case end to end

      2. Confirm with tests

      3. Apply the proven pattern once across the rest


      ---


      ## Environment checks


      Run these early:


      ```bash

      TZ=UTC pnpm test


      node -v

      pnpm -v


      # Canonical diff

      jq -S . out1.json > a && jq -S . out2.json > b && diff -u a b || true


      # Nondeterminism scan

      rg "Date\.now|Math\.random|performance\.now" packages/schema/src
      packages/cli/src packages/core/src

      ```


      ---


      ## OS-specific behavior


      Before touching code, check if the failure is platform specific.


      Common differences:


      | Area         | Unix           | Windows          |
      Strategy             |

      | ------------ | -------------- | ---------------- | --------------------
      |

      | Permissions  | chmod reliable | chmod unreliable | Skip or branch tests
      |

      | Spawn time   | Faster         | Slower           | Higher
      thresholds    |

      | Paths        | `/`            | `\`              | Use path.\*
      helpers  |

      | Line endings | `\n`           | `\r\n`           | Normalize in
      tests   |

      | Temp dirs    | `/tmp`         | `C:\...`         | Use
      os.tmpdir()      |


      If CI fails only on Windows:


      - Read error literally

      - Check for assumptions about paths, chmod, timing

      - Decide: real bug vs platform specific test

      - Fix once at correct layer


      ---


      ## Minimal repro pattern


      Use tight, focused tests.


      ```typescript

      test("context exposes contentHash at top level", () => {
        const merged = { rules: [], meta: { contentHash: "sha256:abc" } };
        const ctx = normalizeContext(merged);
        expect(ctx.contentHash).toBe("sha256:abc");
      });

      ```


      Run:


      ```bash

      pnpm --filter @aligntrue/schema vitest run
      packages/schema/tests/context.contract.test.ts -t contentHash -v

      ```


      ---


      ## Logging guidelines


      - Log what happened and how to fix it

      - Do not log secrets or token-like values

      - Prefer structured logs behind `--json` when helpful

      - Strip debug logs before merge


      ---


      ## AlignTrue quick reference


      | Error pattern                    | First check            | Likely
      cause        | Fix location                                      |

      | -------------------------------- | ---------------------- |
      ------------------- | ------------------------------------------------- |

      | Lockfile bytes differ            | canonicalizeJson usage | Missing JCS
      or sort | packages/schema/src/canonicalize.ts               |

      | Missing or wrong exporter footer | Context contentHash    | Not
      flattened       | packages/cli/src/commands/sync/context-builder.ts |

      | aligntrue --help slow            | Import graph           | Eager
      imports       | packages/cli/src/commands/\*.ts                   |

      | Pass local, fail CI              | TZ/Node drift          | Env
      mismatch        | Vitest setup, CI config                           |

      | Scope mismatch on Windows        | Path normalization     | Slash
      handling      | packages/core/src/scope.ts                        |

      | Ajv errors unreadable            | Error shaping          | Missing
      formatter   | packages/core/src/validation/\*.ts                |


      ---


      ## Determinism triage


      ```bash

      # 1. Canonical compare

      jq -S . bundle1.json > b1 && jq -S . bundle2.json > b2 && diff -u b1 b2 ||
      true


      # 2. Nondeterminism search

      rg "Date\.now|Math\.random|performance\.now" packages/schema/src
      packages/cli/src packages/core/src


      # 3. Stable sets

      # Ensure set-like arrays are sorted once in canonicalization

      ```


      ---


      ## Temp artifacts


      All temporary debug artifacts must start with `temp-`.

      Never commit temp files.


      ---


      ## Communicate the fix


      In PR or commit message:


      - Root cause in one sentence

      - What changed and where

      - How tests now enforce the contract

      - Any platform or determinism notes


      ---


      # Error lessons learned reference


      - For troubleshooting complex or recurring errors, consult
      `.cursor/rules/error_lessons_learned.mdc`—it contains past solutions and
      root causes.

      - When you solve a tricky or non-obvious error, summarize the problem,
      root cause, and successful fix in `error_lessons_learned.mdc`.

      - Write entries in a clear, concise, and structured way (e.g., Symptoms →
      Cause → Resolution) to help both humans and AI tools diagnose similar
      issues in the future.
    level: 2
    fingerprint: debugging
    source_file: .aligntrue/rules/debugging.md
    vendor:
      aligntrue:
        frontmatter:
          description: Systematic debugging workflow
          apply_to: alwaysOn
          content_hash: 481ce43a84eda84495d3b1096bcd14c264783a424a9838e1f6fd94f9985cfba5
          title: Debugging
  - heading: Documentation
    content: >

      # Documentation standards


      **When to apply:** Any time you create or update docs, complete features,
      or touch temporary files. This keeps docs useful and prevents cruft.


      ## Core principle


      **CHANGELOG + user docs are enough.**  

      Anything else is temporary. Delete it before merge.


      **Self-documenting.**

      The user docs should reflect and describe the codebase to users, the code
      is the authoritative source.


      **Optimize for user experience and understandability**


      - Keep docs usable and easy to navigate.

      - Don't unecessary duplicate things, instead link to the areas needed.

      - Use mermaid diagrams to help explain complex things

      - WHen it makes sense, organize things into guides or concepts, with other
      areas linking to them as needed.


      ---


      ## Strict rules


      ### Never create verbose summary docs


      Do **not** add:


      - `*_SUMMARY.md`

      - `*_STATUS.md`

      - `*_IMPROVEMENTS.md`

      - `*_REVIEW.md`

      - `docs/development/*-summary.md`

      - `docs/development/*-improvements.md`

      - Any file that just restates your response or PR description


      If it reads like a status, recap, or phase log, it is temporary.


      ### Only create


      1. **`CHANGELOG.md` entries**

      2. **User docs in `apps/docs/content/`**  
         Only when users need to understand how to use a feature.
      3. **Auto-generated repo files** - `README.md`, `CONTRIBUTING.md`,
      `DEVELOPMENT.md`, `SECURITY.md` are generated from docs site via `pnpm
      generate:repo-files` (see "Documentation architecture" for details).


      Internal working notes belong in `.internal_docs/` while work is active.
      They must not appear in public docs.


      ---


      ## CHANGELOG (required)


      `CHANGELOG.md` is the single source of truth for changes.


      ### Standards


      - Follow Keep a Changelog style.

      - Follow Semantic Versioning.

      - Use an `Unreleased` section.

      - Reverse chronological order.


      ### Valid categories


      - Added

      - Changed

      - Deprecated

      - Removed

      - Fixed

      - Security


      ### Entry format


      Keep it short, user facing, and factual.


      ```markdown

      ### Added


      - Cursor exporter with content hash footer

      - CLI command `aligntrue sync` to export to configured agents

      ```


      ### Forbidden in CHANGELOG


      Do not include:


      - Token or effort estimates

      - LOC counts

      - Full file path lists (config exceptions allowed)

      - Test counts or coverage metrics

      - Session or phase breakdowns

      - Internal refactor detail

      - Commit hashes or history dumps

      - Build or CI trivia with no user impact


      ### Allowed


      You may include:


      - Feature summaries

      - Behavior changes

      - CLI commands and flags

      - Breaking changes and migrations

      - Determinism, hashing, or lockfile behavior changes

      - Security fixes and CVE references

      - Performance improvements with user impact


      ### Writing style


      **Tone:**


      - Neutral, factual, concise

      - One idea per bullet

      - Sentences under 25 words

      - No emojis

      - No semicolons or em dashes


      **Use verbs like:**


      - added

      - changed

      - fixed

      - improved

      - removed

      - updated


      **Avoid:**


      - Hype and marketing language

      - Superlatives

      - Second person in technical notes


      **Good example:**


      ```markdown

      ### Added


      - Cursor exporter with fidelity notes footer

      ```


      **Bad example:**


      ```markdown

      ### Added


      - Amazing new exporter that unlocks next level productivity

      ```


      ---


      ## Commit messages


      ### Format


      ```

      type(scope): description

      ```


      ### Rules


      - Present tense

      - Lowercase after prefix

      - No trailing period


      ### Examples


      ```

      feat(exporter): add Cursor exporter with content hash footer

      fix(schema): handle missing profile id in config

      ```


      ---


      ## Documentation content


      Use documentation for real user workflows only.


      ### User guides


      - **Location:** `apps/docs/content/concepts/` or
      `apps/docs/content/reference/`

      - **Create only when:** a feature needs explanation

      - **Include:** Overview, Quick start, Configuration, Examples,
      Troubleshooting

      - **Keep examples:** runnable and minimal


      ### Tone


      - Explain what the feature does

      - Explain how to use it

      - No hype language


      ### Brand and naming


      - **AlignTrue** (no space)

      - **Align/Aligns** capitalized when referring to glossary-defined rule
      bundles

      - `.aligntrue/config.yaml` for config

      - `.aligntrue/rules` for internal IR

      - `.aligntrue/lock.json` and `.aligntrue/bundle.yaml` for team mode

      - `.cursor/*.mdc` for Cursor exports

      - `.aligntrue/rules/*.md` is the single source of truth (edit here, sync
      flows to agents)


      ### Emoji usage


      **NEVER use emojis in:**


      - AGENTS.md and agent-exported files

      - Rules directory (.aligntrue/rules/)

      - Config files (.aligntrue/config.yaml)

      - HTML comments and markers in exported files

      - Section headings or content that syncs across agents

      - Read-only file warnings

      - Error messages in synced content


      **Reason:** Emojis break parsing, render inconsistently across formats and
      terminals, cause encoding issues, and reduce clarity in technical content.


      **OK to use emojis in:**


      - Documentation website (apps/docs) for visual appeal

      - README files that are not synced

      - Commit messages (for personal preference)

      - Internal tools output (CLI help text, status messages)


      ---


      ## Documentation site layout


      Nextra docs live in `apps/docs/content/`. Browse the directory to see
      current sections and structure.


      ### Documentation architecture


      AlignTrue uses a **docs-first architecture** where the documentation site
      is the canonical source and repo root files are generated from it.


      **Data flow:**


      ```

      apps/docs/content/ (canonical source - edit here)
        ↓
      scripts/generate-repo-files.mjs (transformation)
        ↓
      README.md, CONTRIBUTING.md, DEVELOPMENT.md, SECURITY.md (generated - don't
      edit)

      ```


      **File mappings:**


      - `apps/docs/content/index.mdx` → `README.md`

      - `apps/docs/content/07-contributing/creating-packs.md` →
      `CONTRIBUTING.md`

      - `apps/docs/content/06-development/*.md` → `DEVELOPMENT.md`
      (concatenated)

      - `apps/docs/content/07-policies/security.md` → `SECURITY.md`


      **Workflow:**


      1. Edit docs source in `apps/docs/content/`

      2. Stage your changes (including any accidental edits to protected files)

      3. Commit—the pre-commit hook will auto-regenerate protected files from
      source


      **Protection:**

      The pre-commit hook automatically regenerates protected files when docs
      source changes. If regeneration fails, the hook explains how to debug.


      ### Frontmatter


      Each page must have:


      ```yaml

      ---

      description: One line description

      ---

      ```


      ### Guidelines


      - Use relative links

      - Use `bash`, `yaml`, `typescript` tags for code blocks

      - Keep navigation shallow and obvious

      - Use callouts and tabs only when they improve clarity

      - Avoid custom React components in content


      ### Markdown (.md) vs MDX (.mdx)


      **Use `.md` (default)**


      - Pure markdown content

      - No JSX components

      - Works fine with Nextra

      - Most docs should be `.md`


      **Use `.mdx` when adding JSX**


      - `<Callout>` components

      - `<Tabs>` components

      - `<Cards>` components

      - Any other React/JSX elements

      - **Critical:** Rename `.md` → `.mdx` BEFORE adding JSX, otherwise
      components won't render


      **Naming convention:**

      When you add a JSX component to an existing `.md` file, rename it to
      `.mdx` in the same edit. Example:


      ```bash

      git mv overlays.md overlays.mdx

      # Then add <Callout> components

      ```


      **Generation compatibility:**

      The `pnpm generate:repo-files` script handles both `.md` and `.mdx` files
      equally, so this doesn't affect README generation.


      ---


      ## Small vs big changes


      ### Small feature or fix


      **Scope:** one module or limited files.


      **Do:**


      - Add 1 to 3 bullets to `CHANGELOG.md`

      - Update existing docs only if behavior changed


      **Do not:**


      - Create new pages

      - Add status or summary docs


      ### Big feature or system


      **Scope:** new feature set or architecture.


      **Do:**


      - Add 3 to 5 bullets to `CHANGELOG.md`

      - Add one focused doc page in concepts or reference

      - Explain enablement, config, and key workflows


      **Do not:**


      - Add multi page status narratives

      - Keep phase or session logs


      ---


      ## Cleanup and completion


      ### Temporary files to delete


      Delete before merge:


      - `*_STATUS.md`, `*_CHECKLIST.md`, `*_SUMMARY.md`

      - `*_PHASE*.md`, `*_IMPLEMENTATION.md`, `*_COMPLETE.md`,
      `*_FILES_CREATED.txt`

      - Any `*.md` with `UPPERCASE_UNDERSCORES` used as working notes

      - Notes under `dev/` (keep `.internal_docs/*.md` for internal planning
      only)


      ### Permanent files to keep


      - `CHANGELOG.md`

      - `apps/docs/content/**/*.md`

      - `.internal_docs/*.md` (internal only, never linked from public docs)


      ### Before merge checklist


      1. Update `CHANGELOG.md`

      2. Create or update user docs if feature is user facing

      3. Delete all temporary files listed above

      4. Confirm git is clean (`git status`)


      ### Do not claim completion if


      - Temporary `*_*.md` files remain

      - Docs are missing for new user facing behavior


      ---


      ## Package exports documentation


      **Critical requirement:** All package exports must be documented BEFORE
      adding to `package.json`.


      ### Documentation location


      `apps/docs/content/06-development/package-exports.md`


      ### Required information


      For each export, document:


      - Export path (e.g., `./utils/section-parser`)

      - Purpose (one sentence description)

      - Example usage (import statement)


      ### Workflow


      1. **Document first** - Add entry to package exports documentation

      2. **Add export** - Update `exports` field in `package.json`

      3. **Build and test** - Verify: `pnpm build && pnpm test`

      4. **Update CHANGELOG** - Add entry describing the new export


      ### Export format


      ```json

      {
        "exports": {
          "./your-export": {
            "types": "./dist/your-export.d.ts",
            "default": "./dist/your-export.js"
          }
        }
      }

      ```


      ### Why this matters


      - Prevents accidental exposure of internal APIs

      - Ensures all exports are intentional and documented

      - Enables CI validation of exports

      - Provides clear guidance for package consumers


      ### Validation


      CI should validate that:


      - All exports in `package.json` are documented

      - All documented exports exist in `package.json`

      - All export files exist in `dist/` after build


      ---


      ## Documentation accuracy validation


      **Critical requirement:** Documentation must match implementation reality.
      Code and config are the source of truth, not docs.


      ### Automated validation


      CI and pre-commit hooks automatically validate:


      1. **Node.js version requirements**
         - Source of truth: `package.json` engines.node field
         - Validated in: All documentation files mentioning Node version
         - Update trigger: When changing `package.json` engines field

      2. **CLI command count**
         - Source of truth: `packages/cli/src/index.ts` command dispatch statements
         - Validated in: `apps/docs/content/04-reference/features.md`
         - Update trigger: When adding/removing CLI commands

      3. **Exporter count**
         - Source of truth: Directory count in `packages/exporters/src/`
         - Validated in: `apps/docs/content/index.mdx`, `apps/docs/content/04-reference/agent-support.md`
         - Update trigger: When adding/removing exporters

      4. **Performance threshold claims**
         - Source of truth: `packages/cli/tests/integration/performance.test.ts` threshold constants
         - Validated in: `apps/docs/content/04-reference/features.md`
         - Update trigger: When changing test thresholds

      ### Running validation manually


      ```bash

      pnpm validate:docs

      ```


      ### When validation fails


      1. Read the error message - it shows expected vs actual values

      2. Update documentation to match code/config (not the other way around)

      3. Re-run validation to confirm fix

      4. Commit both code and doc changes together


      ### What is NOT validated


      Validation only covers quantifiable claims. These still require manual
      updates:


      - Feature descriptions and explanations

      - Usage examples and tutorials

      - Troubleshooting guides

      - Conceptual documentation

      - Qualitative performance claims


      For these, follow the existing rules: update docs when behavior changes.
    level: 2
    fingerprint: documentation
    source_file: .aligntrue/rules/documentation.md
    vendor:
      aligntrue:
        frontmatter:
          description: Documentation standards and required workflows
          apply_to: alwaysOn
          content_hash: 21c5b2c0ab3214028f60e779abfccd4c52734bcd7b2664cd80df4fc20f961884
          title: Documentation
  - heading: Error Lessons Learned
    content: >

      # Error resolution lessons learned


      ## Build race condition & PowerShell quoting (November 12, 2025)


      **Symptoms:**


      - `Cannot find module '@aligntrue/core'` (Linux/macOS)

      - `No projects matched the filters` (Windows only)

      - `Failed to resolve entry for package "@aligntrue/schema"`


      **Root Causes:**


      - Parallel build race: packages building simultaneously despite
      dependencies

      - PowerShell treats single quotes literally (unlike bash)

      - Dependency chain not fully sequenced


      **Patterns to Recognize:**


      1. **Module not found but package exists:** Check build ordering in
      `build:packages` and `typecheck` commands

      2. **Works on Unix, fails on Windows:** Look for quoted package names in
      pnpm filters

      3. **Build passes, typecheck fails:** Ensure identical dependency ordering
      in both commands


      **Fix Applied:**


      Now using Turbo with explicit filters to handle ordering:


      ```json

      "build:packages": "turbo run build --filter='./packages/*'"

      ```


      Turbo automatically respects `package.json` dependencies and parallelizes
      work correctly without race conditions.


      **Key Insights:**


      - Use `&&` for explicit sequential stages

      - No quotes around package names in pnpm filters

      - Test cross-platform locally with `node scripts/pre-ci.mjs`

      - "No projects matched" = quoting issue on Windows


      **Prevention:**


      - Test `-r --filter` commands locally with real package names

      - Avoid single quotes in pnpm filter names

      - Mirror build stages exactly in typecheck command

      - Monitor changes to `package.json` build scripts and package dependencies


      ## Windows path separators & glob output (November 13, 2025)


      **Symptoms:**


      - `AssertionError: expected [ Array(2) ] to deeply equal [ Array(2) ]`
      (Windows CI)

      - Expected: `"rules/arch.md"` (forward slashes)

      - Actual: `"rules\\arch.md"` (backslashes)


      **Root Causes:**


      - `glob` library returns OS-native path separators (backslashes on
      Windows)

      - Code directly uses glob output without normalizing to forward slashes

      - Local pre-CI does not catch platform-specific path issues


      **Patterns to Recognize:**


      1. **Test fails only on Windows CI, not locally (macOS/Linux):** Look for
      path comparisons or manipulations that assume forward slashes.

      2. **Path string mismatch (`/` vs `\`):** Indicates a platform-specific
      path separator issue.

      3. **Glob returns unexpected paths:** Confirm whether glob is configured
      to return normalized paths or OS-native paths.


      **Fix Applied:**


      ```typescript

      // Normalize to forward slashes for cross-platform consistency

      matches = matches.map((p) => p.replace(/\\/g, "/"));

      ```


      **Key Insights:**


      - Always normalize paths from external libraries (like `glob`) to a
      consistent format (e.g., forward slashes) for cross-platform reliability.

      - Platform-specific issues (like path separators) require testing on
      target platforms (e.g., Windows CI) as local pre-CI may not detect them.

      - A small `setTimeout` delay can sometimes resolve race conditions with
      filesystem readiness in tests (e.g., before calling `glob`).


      **Prevention:**

          - Implement a custom path normalization utility in `packages/file-utils` for all path-sensitive operations.
          - Add specific unit tests for path handling with both Windows and Unix path formats, potentially using test data with mixed separators.
          - Document path normalization conventions in `documentation.mdc` and `testing.mdc` for all developers.
          - Consider adding a Windows environment to local development or more robust CI setup that emulates Windows filesystem behavior.

      ## Confusing "dual setting" configuration bug (November 23, 2025)


      **Symptoms:**


      - Spinner stuck on "Resolving sources" during interactive prompts
      (non-verbose mode only)

      - Configured multi-file rules (`edit_source: .cursor/rules/*.mdc`) not
      loaded into IR

      - Sync works but generates default rules instead of loading existing ones


      **Root Causes:**


      - **Two separate settings:** `edit_source` (watching) and `source_files`
      (loading) were distinct but related concepts.

      - **Documentation mismatch:** Docs claimed `source_files` was derived from
      `edit_source`, but no code implemented this logic.

      - **Spinner bug:** `spinner.stop()` was wrapped in `if (verbose)` block,
      causing infinite spinner during prompts in default mode.


      **Patterns to Recognize:**


      1. **Configuration drift:** Two settings controlling related behavior will
      eventually diverge or conflict.

      2. **Stuck spinner:** If a spinner persists during prompts, check if
      `stop()` is conditional on verbosity.

      3. **Silent failure:** If valid files are ignored without error, check if
      the loading logic is actually triggered by the config.


      **Fix Applied:**


      - **Unified Concepts:** Removed `source_files` entirely. Made
      `edit_source` the single source of truth for BOTH watching and loading.

      - **Logic Update:** `edit_source` with glob patterns now automatically
      triggers multi-file loading logic.

      - **Spinner Fix:** Moved `spinner.stop()` outside conditional block to
      ensure UI always cleans up before prompts.


      **Key Insights:**


      - **Single Source of Truth:** Avoid splitting related configuration into
      multiple fields. One setting is harder to mess up.

      - **Trust but Verify Docs:** Documentation claiming "automatic derivation"
      must be backed by code.

      - **UX State Management:** Spinners must always stop before handing
      control to the user (prompts), regardless of logging level.
    level: 2
    fingerprint: error-lessons-learned
    source_file: .aligntrue/rules/error_lessons_learned.md
    vendor:
      aligntrue:
        frontmatter:
          description: Lessons learned from resolving errors and issues
          enabled: false
          gitignore: true
          scope: personal
          content_hash: 4038c034f6eccd2e092bf58075c4d81f90f2f54a00e89b25093185c932a0715b
          title: Error Lessons Learned
    scope: personal
  - heading: Global
    content: >

      # Global rules


      ## Vision


      AlignTrue is an AI-native alignment platform to manage AI directives
      (rules, skills, MCP configs, etc.) across agents, repos & teams. It's
      starting as an open source CLI tool to sync rules and MCP configs, then
      continue to evolve as AI does in order to help users close the gap between
      AI hype and real output. Read more at https://aligntrue.ai/docs/about.


      - Repo boundaries: see `guardrails.mdc`

      - Architecture and determinism: see `/docs/06-development/architecture` on
      the docs site

      - Current capabilities: see
      https://aligntrue.ai/docs/04-reference/features


      ---


      ## Audience


      ### Solo developers


      - Want repeatable, explainable agent behavior across repos and machines

      - Expect setup under 60 seconds to first export

      - Default: lockfile off, bundle off, local rules only

      - Validation: `aligntrue check` validates internal consistency (schemas,
      lockfiles, etc.)

      - Export to multiple agents (Cursor, `AGENTS.md`, VS Code MCP)


      ### Teams (opt in)


      - Need versioned, reviewed rule sets enforced in CI

      - Enable team mode (`mode: team`) for lockfile, bundle, drift detection

      - CI validation via `aligntrue drift --gates`

      - Use git-native workflows (PR approval) without requiring cloud

      - Separate team and personal rules with flexible storage (local, repo,
      remote)

      - Use hierarchical scopes for monorepos

      - Migration wizards for smooth solo→team transitions


      ---


      ## Priorities


      1. Determinism first: identical inputs produce identical bundles, hashes,
      and exports

      2. Local first: all core workflows work offline and in CI; cloud is
      optional

      3. Agent parity: preserve semantics across exporters; where not possible,
      emit clear fidelity notes

      4. Simplicity over cleverness: explicit dispatch, shallow trees,
      consolidated modules

      5. 80/20: prioritize changes with clear impact on trust, reliability, or
      adoption

      6. One way doors: format and protocol changes require an ADR style note

      7. User impact over effort: optimize for end user value, not token burn

      8. Avoid premature optimization; small refactors that prevent debt are
      allowed

      9. Optimize for DX: minimal configuration, clear errors, fast feedback, no
      unnecessary complexity

      10. With user facing features always ask: Does this give us the best
      possible user experience?


      ---


      ## Technical approach


      - IR first: `.aligntrue/rules/*.md` compiles to a canonical IR (in-memory
      representation, no file output)

      - Natural markdown authoring:
        - `.aligntrue/rules/*.md` as the primary user-editable files
        - YAML frontmatter optional
        - Use headings and sections; no custom syntax required
      - Vendor bags:
        - Use `vendor.<agent>` for agent specific data
        - Exclude `vendor.*.volatile` from hashing
      - Unidirectional sync:
        - Edit `.aligntrue/rules/*.md` as the single source of truth
        - Sync flows from rules → IR → agent exports
        - Agent files (including `AGENTS.md`) are read-only exports
      - Hierarchical scopes: path based rules for monorepos

      - Bundles and lockfiles:
        - Team mode writes `.aligntrue/lock.json` with pinned hashes (`.aligntrue/bundle.yaml` is forward-compatible but not yet written)
      - Examples:
        - Small, deterministic
        - No network dependencies

      Detailed specifications: `implementation_specs.mdc`.


      ---


      ## AI maintainability doctrine


      All code is assumed AI edited. Design for safe, cheap future changes.


      - Prefer small modules with explicit contracts

      - Keep functions short and names predictable

      - Minimize side effects

      - Add targeted fixtures and tests near complex logic

      - Remove dead code and unnecessary indirection

      - Opt for the best long-term solution and best user experience, not effort

      - Only create an abstraction if it's actually needed


      ---


      ## AI assistance in Cursor


      When acting in this repo:


      - When making decisions and recommendations: Always optimize for the best
      long-term solution and best user experience. We should do the best thing
      for our users, always, no matter what.

      - Define minimal interfaces and contracts first

      - Add tests second

      - Update docs only when behavior changes

      - If rules conflict, raise it and propose a resolution

      - Tighten tests when behavior is ambiguous before heavy edits

      - If stuck or looping, pause and request reassessment

      - Always check if the server is running before trying to start it

      - The `gh` CLI is installed; use it for GitHub operations when requested,
      but **DO NOT make any GitHub API calls unless explicitly requested**.
      GitHub API has strict rate limits (5000/hr auth, 60/hr unauth). Even
      testing scripts counts. Always ask before running commands that hit GitHub
      API.

      - Never revert anything unless I explicitly approve.


      ### Read-only export enforcement (critical for dogfooding)


      **NEVER edit files with READ-ONLY markers in HTML comments.** These are
      auto-generated exports:


      Affected files (do not edit directly):


      - `.cursor/rules/*.mdc` - Cursor exporter output

      - `.cursor/*.mdc` files in nested directories (e.g.,
      `apps/docs/.cursor/rules/*.mdc`)

      - `AGENTS.md` at any level

      - `.clinerules/**` files

      - `.augment/rules/**` files


      **Workflow:**


      1. Identify which rule needs changing

      2. Edit the corresponding source file in `.aligntrue/rules/`
         - Find the rule by title/scope/globs match
         - Make your edits to the `.md` file
      3. Run `aligntrue sync` from the repo root

      4. The exported files will auto-update with your changes


      **Why this matters:** We dogfood our own product. If AI tools edit exports
      directly instead of sources, it breaks the entire sync system and teaches
      wrong patterns to users who copy this workflow.


      **Exception:** ONLY edit `.aligntrue/rules/*.md` files and nothing else in
      the `.cursor/`, `.augment/`, or `.clinerules/` directories.


      ### Git tracking of exports


      Export files can be either committed or ignored based on the `git.mode`
      setting in `.aligntrue/config.yaml`. Always check `git.mode` before
      flagging `.gitignore` changes as issues.


      - `git.mode: ignore` (default): Exports should be listed in `.gitignore`.

      - `git.mode: commit`: Exports should be tracked in git (the managed
      `.gitignore` block for exports will be removed).

      - `git.mode: branch`: Exports are staged on a generated feature branch.


      When `git.mode: commit` is set, it is correct for the `# START AlignTrue
      Generated Files` block to be absent from `.gitignore`; the sync system
      manages tracking automatically.


      Rules with `gitignore: true` in their frontmatter are always ignored
      regardless of global mode, creating a separate managed block in
      `.gitignore` for those rule exports only.


      ---


      ## Decisions and tradeoffs


      Before large or irreversible changes:


      - Ask clarifying questions if requirements are unclear

      - When asking questions propose at least two concrete options with:
        - Pros and cons
        - Risks
        - Why we'd choose it
      - Recommend one option with rationale based on:
        - Maintainability
        - Testability
        - Operability
        - User Experience
        - Best Long Term Solution
      - Flag one way door decisions explicitly


      Template:


      - Option A: pros, cons, effort, risks

      - Option B: pros, cons, effort, risks

      - Recommended: A or B

      - Why: short rationale


      ---


      ## Deferring features


      When deferring:


      - Add entry to `potential_future_features.mdc`

      - Include:
        - What is deferred
        - Why
        - Current approach
        - Objective triggers to revisit

      Review when triggers are met or during phase planning.


      ---


      ## Usability


      **Defaults must work. Failures must teach.**


      ### Error messages


      Each error must state:


      1. What failed (file, field, or operation)

      2. Why it failed

      3. How to fix it, with exact keys or commands


      **Bad**


      `Validation failed`


      **Good**


      `Error: missing 'profile.id' in .aligntrue/config.yaml. Add 'profile.id:
      "<org-or-user>"' or run 'aligntrue init'.`


      ### Defaults


      - Provide safe defaults for common setups

      - Document defaults in `--help` and schema docs

      - Tests must prove defaults yield deterministic outputs

      - NEVER user hostile


      ### CLI UX


      - `--help` must be fast

      - Exit codes:
        - 0 success
        - 1 validation error
        - 2 user error
        - 3 system error
      - Show progress only for long operations

      - Output should be professional and consistent


      ### Trust


      - Do not claim unsupported parity

      - Emit fidelity notes when exports are lossy

      - Document assumptions and limitations clearly


      ---


      ## Success metrics


      - Byte identical lockfiles and exports for identical inputs

      - Under 60 seconds from `aligntrue init` to first export

      - No required network calls in core OSS workflows


      ---


      ## Code policies


      - No full repo or large file rewrites

      - One configuration source of truth

      - Prefer clear module boundaries over cross module state


      ---


      ## Code style and quality


      - TypeScript 5 or newer, Node 20 or newer

      - Strict `tsconfig`

      - ESLint with typescript-eslint, Prettier, EditorConfig

      - Tests with Vitest or Jest

      - Test layout mirrors source layout


      See:


      - `typescript.mdc` for language rules

      - `testing.mdc` for test strategy


      ---


      ## Security and privacy


      - Assume on prem and offline by default

      - No outbound calls in core paths

      - Telemetry is opt in via `ALIGNTRUE_TELEMETRY=on` and documented

      - Do not log secrets or PII

      - Do not commit real keys or tokens
        See `security_linting_policy.mdc` for details.

      ---


      ## Docs and exports


      - Each major feature should have:
        - Example in `examples/` showing config to IR to export
      - Exporters:
        - Include footer with content hash
        - Include fidelity notes when behavior is partial or lossy

      See `documentation.mdc` for documentation rules.


      ---


      ## Communication style


      - Be direct and honest about limits, risks, and edge cases

      - Provide actionable details: exact flags, files, and snippets

      - State assumptions explicitly

      - Use sentence case for all titles

      - Use AlignTrue as a single word

      - Keep docs concise

      - No emojis


      ---


      ## File creation guardian


      Before creating a file:


      1. Decide if it is:
         - Test artifact
         - Config
         - Output
         - Temporary
      2. For temporary artifacts:
         - Prefix with `temp-`
      3. For permanent files:
         - Use correct locations:
           - `packages/cli/src/` for CLI
           - `packages/*/src/` for core, schema, exporters, etc.
           - `packages/*/tests/` for tests
           - `examples/` for examples
           - `apps/docs/content/` for docs
           - `artifacts/` if configured

      Do not create:


      - `test_*.md`, `export_*.md` in root

      - Random `*_config.yaml` in root


      Use `temp-` variants instead and clean them up.


      Before declaring completion:


      - Check for stray test or export files without `temp-`

      - Run cleanup targets where available


      ---


      ## Stub commands and documentation


      Never create stub commands or "coming soon" documentation for
      unimplemented features:


      - Stubs confuse AI assistants who report them as missing functionality

      - "Coming soon" documentation creates false expectations

      - If a feature isn't ready, don't document it or expose it in CLI


      Instead:


      - Implement fully or don't expose at all

      - If deferring, document in internal planning docs only
      (`.internal_docs/`)

      - Remove any existing stubs that create confusion


      **Why this matters:** AI-driven development relies on accurate
      documentation. Stubs and "coming soon" notes cause AI to incorrectly
      report working features as broken or missing, wasting time on false
      issues.


      ---


      ## Feature completion workflow


      For any user facing feature:


      - Update `apps/docs/content/reference/` or `apps/docs/content/concepts/`
      if needed

      - Add or update examples in `examples/` if applicable

      - Add determinism tests for artifact writers if applicable

      - Update `CHANGELOG.md`

      - Delete temporary files if applicable

      - Ensure global rules here are still accurate
    level: 2
    fingerprint: global
    source_file: .aligntrue/rules/global.md
    vendor:
      aligntrue:
        frontmatter:
          description: Global repo rules and priorities
          globs:
            - "**/*"
          apply_to: alwaysOn
          content_hash: 0f8b5db6d57a2033323324105843e99835475a26f9e9b1625df1d5c96714f4a5
          title: Global
  - heading: Guardrails
    content: >

      # OSS repo and content guardrails


      ## Keep future and commercial details private


      Do not generate, insert, or reference:


      - Future phases beyond the current OSS scope (cloud services, dashboards,
      org workflows, integrations)

      - Monetization details (pricing, revenue, paid tiers, consulting)

      - Competitive positioning (comparisons, market claims, investor angles)

      - Internal roadmap (timelines, gated milestones, GTM plans)

      - Speculative features not explicitly part of the current OSS release


      If unsure, omit.


      ---


      ## Public repo focus


      Keep all public content centered on:


      - Determinism, reproducibility, auditability, transparency

      - Current OSS features and direct user benefits

      - Example packs, schema validation, bundling, lockfiles

      - Exporters, CLI usage, MCP server basics

      - Local first workflows and offline usage


      Use neutral, factual language. Safe phrasing:


      > Future improvements may come via community contributions.


      ---


      ## Naming and scope


      - Project name: **AlignTrue** (no space)

      - Public repo: `AlignTrue/aligntrue` (MIT CLI, docs, examples)

      - Do not mention `AlignTrue/cloud` or any paid offering in OSS docs,
      comments, or examples


      ---


      ## Safe topics


      Allowed focus areas include:


      - Deterministic bundles and lockfiles

      - JSON canonicalization and hashing

      - Exporter fidelity notes and agent parity behavior

      - CI validation flows

      - Local, offline compatible usage


      ---


      ## Out of scope topics


      Do not include:


      - SSO, approvals, analytics, or multi tenant features

      - Team usage analytics, billing, or payment flows

      - Comparisons against vendors or tools

      - Investor materials, pitch framing, or narrative

      - Roadmaps or timelines framed as commitments


      ---


      ## Honesty rule


      - Do not make claims that are not currently true

      - If details are sensitive, undecided, or future oriented, omit rather
      than speculate


      ---


      ## Review checklist


      Before merging any OSS docs, README updates, or comments:


      - [ ] Mentions only current OSS features and behavior

      - [ ] No pricing, roadmap, or enterprise feature details

      - [ ] Neutral, factual tone with clear user value

      - [ ] AlignTrue naming and repo references are correct

      - [ ] Commands and examples run locally with no cloud dependency


      ---


      ## Allowed boilerplate


      **Positioning (safe)**


      > AlignTrue compiles rules into deterministic bundles and agent-ready
      exports. The CLI validates schemas, pins hashes, and writes stable outputs
      for CI.


      **Future note (safe)**


      > Additional improvements may arrive through community contributions. This
      repository documents the current OSS surface.


      ---


      ## Prohibited boilerplate


      Do not use phrases like:


      - "Enterprise roadmap includes..."

      - "Pricing starts at..."

      - "This will beat competitors because..."

      - "Planned Qx release will add..."


      ---


      ## Issue and PR hygiene


      - Scope issues and PRs to OSS features:
        - validate
        - bundle
        - export
        - schema
        - examples
      - Link to specs and tests instead of future plans

      - Keep discussion on current implementation and acceptance criteria only
    level: 2
    fingerprint: guardrails
    source_file: .aligntrue/rules/guardrails.md
    vendor:
      aligntrue:
        frontmatter:
          description: OSS repo/content guardrails (no leaking future phases or
            monetization details)
          apply_to: alwaysOn
          gitignore: true
          scope: personal
          content_hash: aa4661c9f76d6f574ac20182316c6a10f935db7ef121b87365ba14067941d275
          title: Guardrails
    scope: personal
  - heading: Implementation Specs
    content: >

      # Implementation specifications


      **When to apply:** When implementing or updating features that must be
      deterministic, reproducible, or compliance grade (IR, lockfiles, bundles,
      exports, hashing, canonicalization).


      These define **what** to build. The **how** is flexible as long as
      acceptance criteria are met.


      ---


      ## Applicability


      ### Solo mode (default)


      - Lockfile off, bundle off

      - IR is the single source of truth: `.aligntrue/rules`

      - Validation via `aligntrue check` (config and schema validation)


      ### Team mode (opt in)


      - `mode: team` in config

      - Enables lockfile, bundle, and drift detection

      - CI validation via `aligntrue drift --gates`


      ---


      ## 1) Canonical JSON (determinism foundation)


      ### Why


      Lockfiles and manifests must hash identically across machines.


      ### Requirements


      - Canonicalization uses JSON Canonicalization Scheme JCS (RFC 8785)

      - UTF-8 without BOM

      - No trailing spaces, exactly one trailing newline

      - Number serialization handled by JCS specification


      ### API


      File: `packages/schema/src/canonicalize.ts`


      - `canonicalizeJson(value: unknown, excludeVolatile?: boolean): string`

      - `computeHash(data: string): string` uses SHA-256

      - `computeAlignHash(alignInput: string | unknown): string` combines both
      for aligns


      ### Used by


      - `.aligntrue/lock.json`

      - `.aligntrue/bundle.yaml` normalized JSON views in tests

      - `manifest.json`

      - `versions.json`


      ### Acceptance


      - Same input yields identical `canonicalJson` on Linux, macOS, Windows

      - Non finite numbers throw with a clear field path

      - `0.123456789` canonicalizes as `0.123457`


      ---


      ## 2) Align merge, precedence, and conflicts (team mode)


      ### Why


      Teams need deterministic align composition.


      ### Requirements


      - Merging happens in memory; `.aligntrue/bundle.yaml` is a
      forward-compatible placeholder not yet persisted to disk

      - Dependency order from a topological sort of the align DAG

      - **Precedence (first-wins):**
        - Local project rules (`.aligntrue/rules/`) ALWAYS FIRST, ALWAYS WINS
        - First external source listed in config
        - Second external source listed in config
        - ... (in order)
      - `priority` field:
        - Higher numeric `priority` wins over default precedence
      - Tie break order:
        - `(priority desc, alignId asc, ruleId asc, sourcePath asc, lineNumber asc)`

      ### Merge semantics


      - Scalars: first wins (when source conflict)

      - Set like arrays: union, then stable sort by value

      - Maps: deep merge using the same precedence rules


      ### Outputs


      - `.aligntrue/bundle.yaml` merged rules

      - `.aligntrue/lock.json` pins:
        - align hashes
        - bundle hash
        - relevant tool versions

      ### Acceptance


      - Identical inputs produce identical bundle and lockfile bytes

      - Source rule order does not matter unless it changes defined precedence

      - No nondeterministic iteration in merges


      ---


      ## 3) Scope matching and glob semantics


      ### Why


      Stable file targeting across OS and tools.


      ### Requirements


      - Normalize paths to forward slashes

      - Base directory is repo root

      - POSIX style globs, case sensitive

      - Default excludes:
        - `node_modules/**`
        - `.git/**`
      - Most specific match wins

      - On equal specificity, apply Section 2 precedence


      ### Acceptance


      - Same repo yields identical scope resolution on Linux, macOS, Windows

      - Most specific scopes applied correctly for monorepo rule assignment


      ---


      ## 4) Telemetry (not currently implemented)


      ### Why


      Collect coarse usage signals without leaking data.


      ### Status


      This feature was removed in favor of a simpler approach. See CHANGELOG.md
      for details on removal.


      ---


      ## 5) Export formatting invariants


      ### Why


      Agent exports must be deterministic and readable.


      ### Markdown style exports


      Includes: `.mdc`, `AGENTS.md`, and other markdown based agent formats.


      **Requirements:**


      - Fixed, documented section order

      - `\n` line endings

      - Exactly one trailing newline

      - No timestamps or UUIDs

      - No content hash or fidelity footers in exported files (see note below)

      - Include the standard read-only marker so users edit `.aligntrue/rules/`


      ### AGENTS.md exporter


      - Follows the `AGENTS.md` spec

      - Uses read-only markers; no content hash or fidelity footers

      - Supports link-based or inline content (see content mode)


      ### Content mode for single-file exports


      Single-file exporters (AGENTS.md, CLAUDE.md, etc.) support content mode
      control:


      **Options:**


      - `auto` (default): Inline for 1 rule, links for 2+ rules

      - `inline`: Embed full rule content with HTML comment separators

      - `links`: Always use markdown links to `.aligntrue/rules/` files


      **Requirements:**


      - Size warning when inline content exceeds 50KB

      - Deterministic output regardless of mode

      - Links mode preserves relative paths to source files


      ### Content hash and fidelity handling


      **Important:** Content hashes and fidelity notes are NOT embedded in
      exported files.


      **Instead:**


      - Content hash is returned in `ExportResult.contentHash` for programmatic
      use

      - Fidelity notes are returned in `ExportResult.fidelityNotes` and
      displayed by CLI

      - Agent files contain only the read-only marker; no hashes or fidelity
      notes


      See `packages/exporters/src/base/EXPORTER_POLICY.md` for complete policy.


      ### MCP and config exporters


      - Write deterministic JSON or YAML

      - Stable key ordering

      - No volatile fields that change per run

      - Content hash returned in `ExportResult`, not embedded in file


      ### Acceptance


      - Same IR yields identical bytes across runs and OSes

      - When mapping is partial, fidelity notes are returned in
      `ExportResult.fidelityNotes`

      - Exported files include only the read-only marker as AlignTrue metadata;
      otherwise clean and user-editable


      ---


      ## 6) Schema validation


      ### Why


      Catch errors early.


      ### Requirements


      - Single JSON Schema: `packages/schema/schema/align.schema.json`

      - Ajv in strict mode with `allErrors: true`

      - Error shaping:
        - Includes JSON path
        - Includes expected vs actual types

      ### CLI


      - `aligntrue check` validates config and rules


      ### Acceptance


      - Invalid configs exit with code 1 and clear messages

      - Valid configs pass quietly or with structured output under `--json`


      ---


      ## 7) CLI exit codes and error shape


      ### Exit codes


      - `0` success

      - `1` validation error (validation failures, sync errors, etc.)

      - `2` user error (missing files, bad flags, config errors)

      - `3` system error (permissions, network, filesystem)


      ### Error format


      Each error must state:


      1. What failed

      2. Why it failed

      3. How to fix it, with a concrete action


      ### Acceptance


      - Contract tests cover `validate`, `bundle`, `export`, `align` exit codes
      and messages

      - Exit codes follow the four-tier system (0 success, 1 validation, 2 user
      error, 3 system error)


      ---


      ## 8) IR and vendor bags


      ### Why


      IR is canonical. Vendor bags enable lossless multi agent support.


      ### Requirements


      - Canonical source:
        - `aligntrue.yaml` or `.aligntrue/rules` for IR
      - Vendor bags:
        - Use `vendor.<agent>` namespaces
      - Volatile fields:
        - Stored in `vendor._meta.volatile` array (list of dot-notation paths to exclude from hashing)
        - Example: `vendor._meta.volatile: ["cursor.session_id", "claude.temp_token"]`
      - Round trip:
        - IR → agent → IR keeps semantics

      ### Hashing


      - Compute hash on IR with volatile fields removed (via
      `filterVolatileVendorFields`)

      - Use `canonicalJson` then `stableHash`


      ### Acceptance


      - IR → Cursor → IR preserves semantic and vendor data, except declared
      volatile fields

      - IR → AGENTS.md → IR preserves semantics and reports any loss

      - Volatile changes do not change hash

      - Semantic changes do


      ---


      ## 9) Unidirectional sync: rules → agents


      ### Why


      Single source of truth prevents conflicts and ensures predictable
      behavior.


      ### Requirements


      **Sync direction (only direction):**


      - `.aligntrue/rules/*.md` is the single source of truth

      - `aligntrue sync` reads from `.aligntrue/rules/`, writes to
      agent-specific exports

      - Agent files (`.cursor/rules/*.mdc`, `AGENTS.md`, etc.) are read-only
      exports

      - Never sync agent files back to IR


      **Edit workflow:**


      1. User edits `.aligntrue/rules/*.md`

      2. User runs `aligntrue sync`

      3. Changes flow: `.aligntrue/rules/` → IR → agent exports

      4. Agent files updated atomically

      5. No user interaction or prompts


      **Manual edits to agent files:**


      - Detected via SHA-256 checksum comparison

      - Backed up to `.aligntrue/overwritten-rules/` with timestamp

      - Overwritten without prompting on next sync

      - User should edit `.aligntrue/rules/` instead


      **Team mode governance:**


      - Use lockfile validation (`aligntrue drift --gates`) for approval
      workflows

      - Team lead manages via `aligntrue team approve`

      - CI validates against approved hashes

      - Lockfile pins IR hashes, not agent file hashes


      ### Atomicity


      - All or nothing writes

      - Use temp files and atomic rename

      - On failure, leave previous state untouched


      ### Dry run


      - `--dry-run` prints planned changes

      - Shows which files would be written

      - No files actually modified


      ### Acceptance


      - Plain `aligntrue sync` is deterministic and requires no user interaction

      - Same `.aligntrue/rules/` input produces identical agent exports across
      runs and machines

      - Manual edits to agent files are backed up and overwritten

      - Team governance via lockfile, not per-file conflicts

      - Agent files never contain unsaved user edits


      ---


      ## 10) Hierarchical scopes


      ### Why


      Monorepos need path aware rules.


      ### Requirements


      - Scope entries:
        - `path`
        - `include` / `exclude` globs
        - `rulesets`
      - Merge order:
        - `[root, path, local]`
      - Most specific scope wins

      - Ties resolved by merge order

      - Exporters support per scope outputs where relevant


      ### Acceptance


      - Scope resolution is deterministic across machines

      - Per scope exports match resolved rules

      - Conflicts produce actionable errors


      ---


      ## 11) Supply chain and releases


      ### Requirements


      - No floating ranges for release builds

      - Generate CycloneDX SBOM for tagged releases

      - Attach checksums

      - CI audits dependencies

      - High severity requires explicit waiver


      ### Acceptance


      - Release artifacts verifiable from SBOM and checksums


      ---


      ## 12) @aligntrue/ui constraints


      ### Why


      Zero build ESM package must work across apps without special loaders.


      ### Forbidden


      - Importing asset files (`.svg`, `.png`, `.jpg`, `.jpeg`, `.gif`, `.webp`,
      etc.)

      - Using `require()` for assets

      - Relying on Next.js loaders or bundler specific behavior


      ### Required


      - Inline SVGs as JSX

      - Images as data URIs if needed

      - Theming driven by CSS variables

      - TypeScript and React only


      ### Acceptance


      - No asset imports in `packages/ui/src/**`

      - Custom lint rule catches violations

      - Consumer apps build without extra config

      - Snapshot tests cover rendering


      ---


      ## Implementation guidelines


      - Read the relevant sections before coding

      - For JSON outputs, always use `canonicalJson` and `stableHash` where
      determinism is required

      - Write acceptance style tests linked to the specs above

      - Document discretionary choices inline

      - For UI changes, keep to the zero build and no asset import constraints


      ---


      ## Review checklist


      Before merging a feature that touches determinism, sync, or exports:


      - Uses `canonicalJson` and `stableHash` where required (Section 1)

      - IR first: IR remains the canonical source (Section 8)

      - Vendor bags used and volatile fields excluded correctly (Section 8)

      - Unidirectional sync follows precedence and atomicity rules (Section 9)

      - Merge order and precedence follow Section 2 in team mode

      - Scope behavior matches Sections 3 and 10

      - Export bytes are stable and do NOT include content hash or fidelity
      footers in files (Section 5)

      - CLI exit codes and messages follow Section 7

      - `@aligntrue/ui` obeys zero build rules if touched (Section 12)
    level: 2
    fingerprint: implementation-specs
    source_file: .aligntrue/rules/implementation_specs.md
    vendor:
      aligntrue:
        frontmatter:
          description: Deterministic implementation specifications for AlignTrue
          content_hash: dc41679516aef0e7c281dfaea2354106ab935595b531e621e406a948d4cd8983
          title: Implementation Specs
  - heading: Accessibility
    content: >

      # Accessibility Standards


      ## WCAG Compliance


      Follow WCAG 2.1 Level AA guidelines:


      - Provide text alternatives for non-text content

      - Provide captions for audio/video

      - Make content adaptable to different presentations

      - Use sufficient color contrast

      - Make all functionality keyboard accessible

      - Give users enough time to read content

      - Don't use content that causes seizures

      - Provide ways to navigate and find content

      - Make text readable and understandable

      - Make pages operate predictably

      - Help users avoid and correct mistakes

      - Maximize compatibility with assistive technologies


      ## Semantic HTML


      Use semantic HTML elements:


      - Use `<header>`, `<nav>`, `<main>`, `<footer>` for page structure

      - Use `<article>`, `<section>`, `<aside>` for content organization

      - Use `<button>` for buttons, not `<div>` with click handlers

      - Use `<a>` for links, not buttons

      - Use proper heading hierarchy (h1-h6)

      - Use `<label>` for form inputs

      - Use `<table>` for tabular data only

      - Use lists (`<ul>`, `<ol>`) for list content


      ## ARIA Labels


      Use ARIA appropriately:


      - Add `aria-label` when visible label isn't sufficient

      - Use `aria-labelledby` to reference existing labels

      - Use `aria-describedby` for additional context

      - Add `aria-live` for dynamic content updates

      - Use `aria-hidden` to hide decorative elements

      - Don't override native semantics unnecessarily

      - Test with screen readers

      - Follow ARIA authoring practices


      Examples:


      ```html

      <button aria-label="Close dialog">×</button>

      <div role="alert" aria-live="assertive">Error occurred</div>

      <nav aria-label="Main navigation">...</nav>

      ```


      ## Keyboard Navigation


      Ensure keyboard accessibility:


      - All interactive elements must be keyboard accessible

      - Provide visible focus indicators

      - Support Tab, Enter, Space, Arrow keys appropriately

      - Don't trap keyboard focus

      - Provide skip links for navigation

      - Use logical tab order

      - Support keyboard shortcuts

      - Test without mouse


      ## Color Contrast


      Maintain sufficient contrast:


      - Normal text: 4.5:1 minimum contrast ratio

      - Large text (18pt+): 3:1 minimum contrast ratio

      - UI components: 3:1 minimum contrast ratio

      - Don't rely on color alone to convey information

      - Test with color blindness simulators

      - Use contrast checking tools

      - Provide high contrast mode option


      ## Form Accessibility


      Make forms accessible:


      - Associate labels with inputs

      - Provide clear error messages

      - Indicate required fields

      - Group related fields with fieldset/legend

      - Provide helpful placeholder text

      - Show validation errors clearly

      - Support autocomplete attributes

      - Make error recovery easy


      Example:


      ```html

      <label for="email">Email address *</label>

      <input
        type="email"
        id="email"
        required
        aria-describedby="email-error"
        autocomplete="email"
      />

      <span id="email-error" role="alert"> Please enter a valid email address
      </span>

      ```


      ## Images and Media


      Provide alternatives:


      - Add alt text to all images

      - Use empty alt for decorative images

      - Provide captions for videos

      - Provide transcripts for audio

      - Don't use images of text

      - Describe complex images in detail

      - Use SVG with proper titles and descriptions


      ## Focus Management


      Manage focus properly:


      - Show clear focus indicators

      - Move focus to modals when opened

      - Return focus when modals close

      - Don't remove focus outlines

      - Use `:focus-visible` for keyboard-only focus

      - Trap focus in modals

      - Announce focus changes to screen readers


      ## Screen Reader Support


      Optimize for screen readers:


      - Use semantic HTML

      - Provide text alternatives

      - Use ARIA landmarks

      - Announce dynamic content changes

      - Provide skip links

      - Test with multiple screen readers (NVDA, JAWS, VoiceOver)

      - Use proper heading structure

      - Avoid screen reader-only text when possible


      ## Responsive Design


      Make responsive designs accessible:


      - Support text zoom up to 200%

      - Don't break layout when zoomed

      - Support mobile screen readers

      - Make touch targets at least 44x44 pixels

      - Support landscape and portrait orientations

      - Don't disable zoom

      - Test on mobile devices


      ## Testing Accessibility


      Test thoroughly:


      - Use automated tools (axe, Lighthouse, WAVE)

      - Test with keyboard only

      - Test with screen readers

      - Test with browser zoom

      - Test with high contrast mode

      - Get feedback from users with disabilities

      - Include accessibility in code reviews

      - Test on multiple devices and browsers
    level: 2
    fingerprint: large-rules-accessibility
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/accessibility.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/accessibility
          version: 1.0.0
          spec_version: "1"
          summary: Web accessibility standards and WCAG compliance
          title: Accessibility
    scope: personal
  - heading: Backend API
    content: >

      # Backend API Development


      ## RESTful API Design


      Follow REST principles for API endpoints:


      - Use nouns for resources, not verbs

      - HTTP methods map to CRUD: GET (read), POST (create), PUT/PATCH (update),
      DELETE (delete)

      - Use plural nouns for collections: `/users`, `/products`

      - Use path parameters for resource IDs: `/users/123`

      - Use query parameters for filtering and pagination:
      `/users?role=admin&page=2`


      ## Request Validation


      Validate all incoming requests:


      - Validate request body against schema (use Zod, Joi, or similar)

      - Check required fields are present

      - Validate data types and formats

      - Enforce length limits on strings

      - Sanitize inputs to prevent injection attacks

      - Return 400 Bad Request with detailed error messages for validation
      failures


      Example validation error response:


      ```json

      {
        "error": "Validation failed",
        "details": [
          { "field": "email", "message": "Must be a valid email address" },
          { "field": "age", "message": "Must be a number between 0 and 120" }
        ]
      }

      ```


      ## Error Handling


      Implement consistent error handling:


      - Use standard HTTP status codes appropriately

      - Return error responses in consistent format

      - Include error codes for client-side handling

      - Log errors with context (request ID, user ID, timestamp)

      - Never expose stack traces or internal details to clients

      - Use custom error classes for different error types


      Status code guidelines:


      - 200: Success

      - 201: Resource created

      - 204: Success with no content

      - 400: Client error (bad request)

      - 401: Unauthenticated

      - 403: Unauthorized (authenticated but no permission)

      - 404: Resource not found

      - 409: Conflict (e.g., duplicate resource)

      - 422: Unprocessable entity (semantic errors)

      - 500: Server error


      ## Response Formatting


      Use consistent response formats:


      - Wrap data in a `data` field for successful responses

      - Include metadata when relevant (pagination, timestamps)

      - Use camelCase for JSON keys

      - Return null for missing optional fields, omit undefined fields

      - Include resource links for HATEOAS when appropriate


      Success response example:


      ```json

      {
        "data": {
          "id": "123",
          "name": "John Doe",
          "email": "john@example.com"
        },
        "meta": {
          "timestamp": "2025-01-15T10:30:00Z"
        }
      }

      ```


      ## Pagination


      Implement pagination for list endpoints:


      - Use limit/offset or cursor-based pagination

      - Include pagination metadata in response

      - Default to reasonable page size (e.g., 20-50 items)

      - Allow clients to specify page size within limits

      - Return total count when feasible


      Pagination response:


      ```json

      {
        "data": [...],
        "pagination": {
          "page": 2,
          "perPage": 20,
          "total": 150,
          "totalPages": 8,
          "hasNext": true,
          "hasPrev": true
        }
      }

      ```


      ## Authentication


      Implement secure authentication:


      - Use JWT tokens or session-based auth

      - Store tokens securely (httpOnly cookies or secure storage)

      - Implement token refresh mechanism

      - Set appropriate token expiration times

      - Validate tokens on every protected endpoint

      - Use middleware for authentication checks


      ## Authorization


      Implement role-based access control:


      - Define clear roles and permissions

      - Check permissions at the route level

      - Use middleware for authorization checks

      - Return 403 Forbidden for unauthorized access

      - Log authorization failures for security monitoring

      - Implement least privilege principle


      ## Rate Limiting


      Protect APIs with rate limiting:


      - Implement per-user or per-IP rate limits

      - Use sliding window or token bucket algorithms

      - Return 429 Too Many Requests when limit exceeded

      - Include rate limit headers in responses (X-RateLimit-Limit,
      X-RateLimit-Remaining)

      - Allow different limits for different endpoints

      - Whitelist internal services from rate limits


      ## API Versioning


      Version your APIs for backward compatibility:


      - Use URL versioning: `/api/v1/users`, `/api/v2/users`

      - Maintain old versions during deprecation period

      - Document breaking changes clearly

      - Provide migration guides for version upgrades

      - Use semantic versioning for API versions

      - Announce deprecations well in advance


      ## Logging and Monitoring


      Implement comprehensive logging:


      - Log all requests with request ID, method, path, status, duration

      - Log errors with full context and stack traces

      - Use structured logging (JSON format)

      - Include correlation IDs for distributed tracing

      - Set up alerts for error rate spikes

      - Monitor API performance metrics (latency, throughput)


      ## Database Queries


      Optimize database interactions:


      - Use connection pooling

      - Implement query timeouts

      - Use indexes for frequently queried fields

      - Avoid N+1 queries (use eager loading)

      - Paginate large result sets

      - Use read replicas for read-heavy workloads

      - Cache frequently accessed data


      ## Async Operations


      Handle long-running operations properly:


      - Return 202 Accepted for async operations

      - Provide status endpoint to check operation progress

      - Use job queues for background processing

      - Implement idempotency for retry safety

      - Set reasonable timeouts

      - Provide webhooks or polling for completion notification


      ## Testing


      Test API endpoints thoroughly:


      - Write integration tests for all endpoints

      - Test happy paths and error cases

      - Test authentication and authorization

      - Test rate limiting behavior

      - Test with invalid inputs

      - Use test fixtures for consistent data

      - Mock external dependencies


      ## Documentation


      Document APIs comprehensively:


      - Use OpenAPI/Swagger specification

      - Document all endpoints, parameters, and responses

      - Provide example requests and responses

      - Document error codes and their meanings

      - Keep documentation in sync with code

      - Generate interactive API documentation
    level: 2
    fingerprint: large-rules-backend-api
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/backend-api.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/backend-api
          version: 1.0.0
          spec_version: "1"
          summary: Backend API development patterns and best practices
          title: Backend API
    scope: personal
  - heading: Code Review
    content: >

      # Code Review Standards


      ## Pull Request Guidelines


      Create good pull requests:


      - Keep PRs small and focused (< 400 lines)

      - Write clear PR description

      - Link related issues

      - Include screenshots for UI changes

      - Add tests for new functionality

      - Update documentation

      - Run tests locally before submitting

      - Respond to feedback promptly


      ## PR Description Template


      Use consistent PR template:


      ```markdown

      ## What


      Brief description of changes


      ## Why


      Reason for changes


      ## How


      Implementation approach


      ## Testing


      How to test the changes


      ## Screenshots


      (if applicable)


      ## Checklist


      - [ ] Tests added/updated

      - [ ] Documentation updated

      - [ ] No breaking changes

      - [ ] Reviewed own code

      ```


      ## Review Checklist


      Review systematically:


      - Does code solve the stated problem?

      - Is code readable and maintainable?

      - Are tests adequate?

      - Are there edge cases not handled?

      - Is error handling appropriate?

      - Are there performance concerns?

      - Is documentation updated?

      - Are there security issues?

      - Does it follow project conventions?


      ## Providing Feedback


      Give constructive feedback:


      - Be specific and actionable

      - Explain the "why" behind suggestions

      - Distinguish between must-fix and nice-to-have

      - Praise good solutions

      - Ask questions rather than demand changes

      - Focus on code, not the person

      - Provide examples when helpful

      - Be respectful and professional


      Feedback examples:


      - Good: "Consider extracting this logic into a separate function for
      better testability"

      - Bad: "This is wrong"


      ## Receiving Feedback


      Handle feedback professionally:


      - Don't take feedback personally

      - Ask for clarification if needed

      - Explain your reasoning when appropriate

      - Be open to different approaches

      - Thank reviewers for their time

      - Address all feedback (implement or explain why not)

      - Mark conversations as resolved


      ## Review Priorities


      Focus review on:


      1. Correctness: Does it work as intended?

      2. Security: Are there vulnerabilities?

      3. Performance: Are there obvious bottlenecks?

      4. Maintainability: Can others understand and modify it?

      5. Tests: Is it adequately tested?

      6. Style: Does it follow conventions? (lowest priority)


      ## Approval Process


      Follow approval workflow:


      - Require at least one approval

      - Require approvals from code owners

      - Address all blocking comments

      - Re-review after significant changes

      - Don't approve your own PRs

      - Don't merge without approval

      - Use "Request changes" for blocking issues


      ## Merge Strategy


      Choose merge strategy consistently:


      - Squash commits for clean history

      - Rebase for linear history

      - Merge commits for preserving context

      - Delete branch after merge

      - Update branch before merging

      - Resolve conflicts carefully


      ## Automated Checks


      Require automated checks to pass:


      - Linting and formatting

      - Unit tests

      - Integration tests

      - Build success

      - Security scans

      - Code coverage thresholds

      - No merge conflicts


      ## Review Turnaround


      Respond to reviews promptly:


      - Review within 24 hours when possible

      - Set status to "In Review" when ready

      - Notify reviewers of updates

      - Don't let PRs go stale

      - Escalate blocked PRs

      - Communicate delays


      ## Self-Review


      Review own code first:


      - Read through all changes

      - Check for debugging code

      - Verify tests pass

      - Run linter and formatter

      - Check for commented code

      - Verify documentation

      - Test manually if needed
    level: 2
    fingerprint: large-rules-code-review
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/code-review.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/code-review
          version: 1.0.0
          spec_version: "1"
          summary: Code review standards and pull request guidelines
          title: Code Review
    scope: personal
  - heading: Database
    content: |

      # Database Best Practices

      ## Schema Design

      Design database schemas carefully:

      - Normalize to reduce redundancy (usually to 3NF)
      - Denormalize strategically for performance
      - Use appropriate data types for columns
      - Define primary keys for all tables
      - Use foreign keys to enforce referential integrity
      - Add NOT NULL constraints where appropriate
      - Use UNIQUE constraints for natural keys
      - Document schema decisions

      ## Migrations

      Manage schema changes with migrations:

      - Use migration tools (Prisma, TypeORM, Knex, etc.)
      - Make migrations reversible when possible
      - Test migrations on staging before production
      - Run migrations in transactions
      - Keep migrations small and focused
      - Never edit existing migrations
      - Version control all migrations
      - Document breaking changes

      ## Indexing

      Create indexes strategically:

      - Index foreign keys
      - Index columns used in WHERE clauses
      - Index columns used in ORDER BY
      - Create composite indexes for multi-column queries
      - Avoid over-indexing (impacts write performance)
      - Monitor index usage and remove unused indexes
      - Use EXPLAIN to analyze query plans
      - Consider covering indexes for read-heavy queries

      ## Query Optimization

      Write efficient queries:

      - Select only needed columns (avoid SELECT \*)
      - Use WHERE clauses to filter early
      - Avoid N+1 queries with joins or eager loading
      - Use LIMIT for pagination
      - Avoid complex calculations in WHERE clauses
      - Use prepared statements to prevent SQL injection
      - Profile slow queries and optimize
      - Consider query caching for expensive queries

      ## Transactions

      Use transactions appropriately:

      - Wrap related operations in transactions
      - Keep transactions short to avoid locks
      - Use appropriate isolation levels
      - Handle transaction rollbacks
      - Avoid nested transactions
      - Be aware of deadlock possibilities
      - Use optimistic locking for concurrent updates
      - Test transaction behavior under load

      ## Connection Pooling

      Manage database connections:

      - Use connection pooling
      - Configure pool size appropriately
      - Set connection timeouts
      - Handle connection errors gracefully
      - Monitor connection pool metrics
      - Close connections properly
      - Avoid connection leaks

      ## Data Integrity

      Maintain data integrity:

      - Use foreign key constraints
      - Use check constraints for validation
      - Use triggers sparingly and document them
      - Implement soft deletes when needed
      - Use database-level defaults
      - Validate data at application level too
      - Handle constraint violations gracefully

      ## Backup and Recovery

      Implement backup strategy:

      - Schedule regular automated backups
      - Test backup restoration regularly
      - Store backups securely and redundantly
      - Document recovery procedures
      - Use point-in-time recovery when available
      - Monitor backup success/failure
      - Retain backups according to policy

      ## Security

      Secure database access:

      - Use least privilege principle for database users
      - Never use root/admin accounts in application
      - Rotate database credentials regularly
      - Use SSL/TLS for database connections
      - Encrypt sensitive data at rest
      - Audit database access logs
      - Prevent SQL injection with parameterized queries
      - Sanitize user inputs

      ## Performance Monitoring

      Monitor database performance:

      - Track query execution times
      - Monitor connection pool usage
      - Watch for slow queries
      - Monitor disk I/O and CPU usage
      - Set up alerts for anomalies
      - Use database profiling tools
      - Analyze query patterns
      - Optimize based on real usage data
    level: 2
    fingerprint: large-rules-database
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/database.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/database
          version: 1.0.0
          spec_version: "1"
          summary: Database design, migrations, and query optimization
          title: Database
    scope: personal
  - heading: Devops CI
    content: |

      # DevOps and CI/CD

      ## CI Pipeline

      Structure CI pipelines effectively:

      - Run on every pull request
      - Run linting and formatting checks
      - Run all tests (unit, integration, e2e)
      - Build application
      - Run security scans
      - Generate test coverage reports
      - Fail fast on errors
      - Cache dependencies for speed
      - Run jobs in parallel when possible

      ## Deployment Strategy

      Choose appropriate deployment strategy:

      - Blue-green deployment for zero downtime
      - Canary deployments for gradual rollout
      - Rolling deployments for incremental updates
      - Feature flags for controlled releases
      - Automate deployment process
      - Test deployments in staging first
      - Have rollback plan ready
      - Document deployment procedures

      ## Environment Management

      Manage environments properly:

      - Maintain separate dev, staging, production environments
      - Use infrastructure as code (Terraform, CloudFormation)
      - Keep environments in sync
      - Use environment-specific configurations
      - Never test in production
      - Limit production access
      - Document environment differences

      ## Container Best Practices

      Use containers effectively:

      - Use official base images
      - Keep images small (multi-stage builds)
      - Don't run as root user
      - Pin image versions
      - Scan images for vulnerabilities
      - Use .dockerignore
      - Cache layers appropriately
      - Document Dockerfile

      Example Dockerfile:

      ```dockerfile
      FROM node:20-alpine AS builder
      WORKDIR /app
      COPY package*.json ./
      RUN npm ci
      COPY . .
      RUN npm run build

      FROM node:20-alpine
      WORKDIR /app
      COPY --from=builder /app/dist ./dist
      COPY --from=builder /app/node_modules ./node_modules
      USER node
      CMD ["node", "dist/index.js"]
      ```

      ## Infrastructure as Code

      Manage infrastructure with code:

      - Version control all infrastructure code
      - Use declarative configuration
      - Test infrastructure changes
      - Review infrastructure changes like code
      - Use modules for reusability
      - Document infrastructure decisions
      - Implement least privilege access
      - Tag resources appropriately

      ## Monitoring

      Implement comprehensive monitoring:

      - Monitor application metrics (latency, throughput, errors)
      - Monitor infrastructure metrics (CPU, memory, disk, network)
      - Set up alerts for anomalies
      - Use distributed tracing
      - Log aggregation and analysis
      - Monitor business metrics
      - Create dashboards for visibility
      - Test alerting system

      ## Logging

      Implement structured logging:

      - Use JSON format for logs
      - Include context (request ID, user ID, timestamp)
      - Log at appropriate levels (debug, info, warn, error)
      - Don't log sensitive data
      - Centralize logs (ELK, CloudWatch, Datadog)
      - Set up log retention policies
      - Make logs searchable
      - Use correlation IDs for tracing

      ## Secrets Management

      Handle secrets in CI/CD:

      - Use CI/CD secret management (GitHub Secrets, GitLab CI/CD variables)
      - Never commit secrets to git
      - Rotate secrets regularly
      - Use different secrets per environment
      - Limit access to secrets
      - Audit secret usage
      - Encrypt secrets at rest

      ## Performance Testing

      Test performance regularly:

      - Run load tests before releases
      - Test under realistic conditions
      - Identify bottlenecks
      - Set performance budgets
      - Monitor performance trends
      - Test scalability
      - Document performance requirements

      ## Disaster Recovery

      Plan for disasters:

      - Document recovery procedures
      - Test backup restoration regularly
      - Maintain runbooks for incidents
      - Have rollback procedures ready
      - Practice incident response
      - Keep contact list updated
      - Post-mortem after incidents
      - Learn from failures

      ## Security Scanning

      Scan for vulnerabilities:

      - Scan dependencies (npm audit, Snyk)
      - Scan container images
      - Run SAST tools
      - Run DAST tools
      - Scan for secrets in code
      - Monitor for CVEs
      - Have patching process
      - Track security metrics
    level: 2
    fingerprint: large-rules-devops-ci
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/devops-ci.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/devops-ci
          version: 1.0.0
          spec_version: "1"
          summary: CI/CD pipelines, deployment, and monitoring
          title: Devops CI
    scope: personal
  - heading: Documentation
    content: |

      # Documentation Standards

      ## README Requirements

      Every project needs a good README:

      - Project name and description
      - Prerequisites and requirements
      - Installation instructions
      - Quick start guide
      - Configuration options
      - Usage examples
      - API documentation link
      - Contributing guidelines
      - License information
      - Contact/support information

      ## API Documentation

      Document APIs comprehensively:

      - Use OpenAPI/Swagger specification
      - Document all endpoints
      - Include request/response examples
      - Document authentication requirements
      - List all parameters and their types
      - Document error codes and messages
      - Provide example API calls
      - Keep documentation in sync with code
      - Generate interactive documentation

      Example endpoint documentation:

      ```yaml
      /api/users/{id}:
        get:
          summary: Get user by ID
          parameters:
            - name: id
              in: path
              required: true
              schema:
                type: string
          responses:
            200:
              description: User found
              content:
                application/json:
                  schema:
                    $ref: "#/components/schemas/User"
            404:
              description: User not found
      ```

      ## Code Comments

      Write helpful code comments:

      - Explain "why" not "what"
      - Document complex algorithms
      - Explain non-obvious decisions
      - Add TODOs with context
      - Use JSDoc for functions
      - Keep comments up to date
      - Remove obsolete comments
      - Don't comment obvious code

      Good comment:

      ```typescript
      // Use exponential backoff to avoid overwhelming the API
      // during temporary outages
      const delay = Math.min(1000 * Math.pow(2, retryCount), 30000);
      ```

      ## Architecture Documentation

      Document system architecture:

      - Create architecture diagrams
      - Document key design decisions
      - Explain system components
      - Document data flow
      - Describe integration points
      - Document deployment architecture
      - Explain technology choices
      - Keep diagrams up to date

      ## ADRs (Architecture Decision Records)

      Record important decisions:

      - Use ADR template
      - Document context and problem
      - List considered options
      - Explain chosen solution
      - Note consequences
      - Date and author decisions
      - Store in version control
      - Reference in code when relevant

      ADR template:

      ```markdown
      # ADR-001: Use PostgreSQL for primary database

      ## Status

      Accepted

      ## Context

      Need to choose database for user data storage

      ## Decision

      Use PostgreSQL

      ## Consequences

      - Pros: ACID compliance, rich query features
      - Cons: Requires more ops expertise than NoSQL
      ```

      ## Inline Documentation

      Document code inline:

      - Use JSDoc for TypeScript/JavaScript
      - Document function parameters and return types
      - Explain complex type definitions
      - Document class properties
      - Add examples for complex APIs
      - Generate documentation from code
      - Keep inline docs synchronized

      Example:

      ```typescript
      /**
       * Calculates compound interest
       * @param principal - Initial investment amount
       * @param rate - Annual interest rate (as decimal, e.g., 0.05 for 5%)
       * @param years - Number of years
       * @returns Final amount after compound interest
       * @example
       * calculateCompoundInterest(1000, 0.05, 10) // Returns 1628.89
       */
      function calculateCompoundInterest(
        principal: number,
        rate: number,
        years: number,
      ): number {
        return principal * Math.pow(1 + rate, years);
      }
      ```

      ## Changelog

      Maintain a changelog:

      - Follow Keep a Changelog format
      - Document all notable changes
      - Group by version
      - Include date of release
      - Categorize changes (Added, Changed, Fixed, etc.)
      - Link to issues/PRs
      - Write for users, not developers

      ## Runbooks

      Create operational runbooks:

      - Document common operations
      - Include troubleshooting steps
      - List required access/permissions
      - Provide example commands
      - Document rollback procedures
      - Include contact information
      - Test runbooks regularly
      - Keep updated

      ## Migration Guides

      Document breaking changes:

      - Explain what changed and why
      - Provide before/after examples
      - List migration steps
      - Estimate migration effort
      - Provide migration scripts when possible
      - Announce well in advance
      - Support old version during transition

      ## Troubleshooting Guide

      Help users solve problems:

      - List common issues
      - Provide solutions
      - Include error messages
      - Add diagnostic steps
      - Link to related documentation
      - Provide contact for help
      - Update based on support tickets

      ## Contributing Guide

      Help contributors:

      - Explain how to set up development environment
      - Document coding standards
      - Explain PR process
      - List testing requirements
      - Provide code of conduct
      - Explain commit message format
      - Link to issue tracker
    level: 2
    fingerprint: large-rules-documentation
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/documentation.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/documentation
          version: 1.0.0
          spec_version: "1"
          summary: Documentation standards for APIs, code, and architecture
          title: Documentation
    scope: personal
  - heading: Frontend React
    content: |

      # Frontend React Development

      ## Component Structure

      Organize components with clear structure:

      - One component per file
      - Use functional components with hooks
      - Keep components small and focused (< 200 lines)
      - Extract complex logic into custom hooks
      - Co-locate styles with components
      - Use index files for clean imports

      Directory structure:

      ```
      components/
        Button/
          Button.tsx
          Button.test.tsx
          Button.module.css
          index.ts
      ```

      ## State Management

      Choose appropriate state management:

      - Use useState for local component state
      - Use useReducer for complex state logic
      - Use Context API for app-wide state
      - Consider Zustand or Redux for large apps
      - Keep state as local as possible
      - Lift state only when necessary

      ## Hooks Best Practices

      Follow hooks rules and patterns:

      - Only call hooks at the top level
      - Only call hooks in React functions
      - Use useEffect for side effects only
      - Clean up effects with return functions
      - Use dependency arrays correctly
      - Extract reusable logic into custom hooks
      - Memoize expensive computations with useMemo
      - Memoize callbacks with useCallback

      ## Props and TypeScript

      Type props properly:

      - Define explicit prop types with TypeScript interfaces
      - Use optional props with `?` notation
      - Provide default values with destructuring
      - Use children prop type for composition
      - Avoid prop drilling (use composition or context)
      - Document complex props with JSDoc comments

      Example:

      ```typescript
      interface ButtonProps {
        variant?: "primary" | "secondary";
        size?: "small" | "medium" | "large";
        onClick: () => void;
        disabled?: boolean;
        children: React.ReactNode;
      }

      export function Button({
        variant = "primary",
        size = "medium",
        ...props
      }: ButtonProps) {
        // Component implementation
      }
      ```

      ## Component Composition

      Use composition over inheritance:

      - Build complex UIs from simple components
      - Use children prop for flexible composition
      - Create compound components for related UI elements
      - Use render props or custom hooks for logic sharing
      - Avoid deep prop drilling with composition
      - Keep components decoupled and reusable

      ## Performance Optimization

      Optimize React performance:

      - Use React.memo for expensive components
      - Memoize callbacks with useCallback
      - Memoize computed values with useMemo
      - Use lazy loading for code splitting
      - Virtualize long lists with react-window
      - Avoid inline object/array creation in JSX
      - Profile with React DevTools before optimizing

      ## Forms and Validation

      Handle forms properly:

      - Use controlled components for form inputs
      - Consider react-hook-form for complex forms
      - Validate on blur and submit
      - Show validation errors clearly
      - Disable submit during submission
      - Handle loading and error states
      - Provide clear success feedback

      ## Error Boundaries

      Implement error boundaries:

      - Wrap components with error boundaries
      - Show fallback UI for errors
      - Log errors to monitoring service
      - Provide recovery actions when possible
      - Don't catch errors in event handlers (use try-catch)
      - Test error boundary behavior

      ## Accessibility

      Make components accessible:

      - Use semantic HTML elements
      - Add ARIA labels when needed
      - Ensure keyboard navigation works
      - Provide focus indicators
      - Use sufficient color contrast
      - Test with screen readers
      - Support reduced motion preferences

      ## Testing Components

      Test React components thoroughly:

      - Use React Testing Library
      - Test user interactions, not implementation
      - Query by accessible roles and labels
      - Mock external dependencies
      - Test loading and error states
      - Test keyboard interactions
      - Aim for high coverage of critical paths

      ## Styling Approaches

      Choose appropriate styling:

      - CSS Modules for component-scoped styles
      - Tailwind for utility-first approach
      - Styled-components for CSS-in-JS
      - Keep styles close to components
      - Use CSS variables for theming
      - Avoid inline styles except for dynamic values
      - Follow consistent naming conventions

      ## Data Fetching

      Handle data fetching properly:

      - Use React Query or SWR for server state
      - Show loading states during fetches
      - Handle errors gracefully
      - Implement retry logic
      - Cache responses appropriately
      - Prefetch data when possible
      - Use suspense for data loading (when stable)

      ## Code Splitting

      Implement code splitting:

      - Use React.lazy for route-based splitting
      - Split large components and libraries
      - Use dynamic imports for conditional features
      - Preload critical routes
      - Monitor bundle sizes
      - Use webpack bundle analyzer

      ## Routing

      Implement routing properly:

      - Use React Router for client-side routing
      - Define routes declaratively
      - Use nested routes for layouts
      - Implement route guards for auth
      - Handle 404 pages
      - Use route parameters and query strings
      - Implement breadcrumbs for navigation

      ## Environment Variables

      Manage environment variables:

      - Use REACT*APP* prefix for Create React App
      - Use VITE\_ prefix for Vite
      - Never commit secrets to git
      - Use different .env files per environment
      - Document required environment variables
      - Validate env vars at startup
    level: 2
    fingerprint: large-rules-frontend-react
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/frontend-react.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/frontend-react
          version: 1.0.0
          spec_version: "1"
          summary: React component patterns and frontend best practices
          title: Frontend React
    scope: personal
  - heading: Performance
    content: |

      # Performance Optimization

      ## Profiling First

      Always profile before optimizing:

      - Use profiling tools to identify bottlenecks
      - Measure before and after changes
      - Focus on hot paths
      - Don't optimize prematurely
      - Profile in production-like environment
      - Use real data for profiling
      - Document performance improvements
      - Set performance budgets

      ## Algorithm Complexity

      Choose efficient algorithms:

      - Understand Big O notation
      - Prefer O(1) and O(log n) over O(n²)
      - Use appropriate data structures
      - Consider space-time tradeoffs
      - Optimize critical paths first
      - Use binary search over linear search
      - Cache computed results
      - Avoid nested loops when possible

      ## Database Performance

      Optimize database queries:

      - Use indexes strategically
      - Avoid N+1 queries
      - Use connection pooling
      - Implement query caching
      - Paginate large result sets
      - Use EXPLAIN to analyze queries
      - Denormalize when necessary
      - Use read replicas for read-heavy loads

      ## Caching Strategies

      Implement effective caching:

      - Cache at multiple levels (CDN, application, database)
      - Use appropriate cache invalidation strategy
      - Set reasonable TTLs
      - Cache expensive computations
      - Use cache-aside pattern
      - Monitor cache hit rates
      - Handle cache failures gracefully
      - Warm up caches proactively

      Cache levels:

      1. CDN: Static assets, API responses
      2. Application: Computed values, database queries
      3. Database: Query results
      4. Browser: Static resources

      ## API Performance

      Optimize API responses:

      - Implement response compression (gzip, brotli)
      - Use pagination for large datasets
      - Implement field filtering (GraphQL, sparse fieldsets)
      - Cache responses with appropriate headers
      - Use HTTP/2 or HTTP/3
      - Minimize response payload size
      - Implement rate limiting
      - Use connection keep-alive

      ## Frontend Performance

      Optimize frontend loading:

      - Minimize bundle size
      - Code split by route
      - Lazy load components
      - Optimize images (WebP, compression, responsive)
      - Use CDN for static assets
      - Implement service workers
      - Preload critical resources
      - Defer non-critical scripts

      ## Memory Management

      Manage memory efficiently:

      - Avoid memory leaks
      - Clean up event listeners
      - Close database connections
      - Clear intervals and timeouts
      - Use weak references when appropriate
      - Stream large files instead of loading into memory
      - Monitor memory usage
      - Profile memory allocation

      ## Concurrency

      Handle concurrent operations:

      - Use async/await for I/O operations
      - Implement connection pooling
      - Use worker threads for CPU-intensive tasks
      - Avoid blocking the event loop
      - Use queues for background jobs
      - Implement backpressure
      - Set appropriate timeouts
      - Handle race conditions

      ## Asset Optimization

      Optimize static assets:

      - Minify JavaScript and CSS
      - Compress images
      - Use modern image formats (WebP, AVIF)
      - Implement responsive images
      - Use SVG for icons
      - Bundle and tree-shake dependencies
      - Remove unused code
      - Use content hashing for cache busting

      ## Monitoring Performance

      Track performance metrics:

      - Monitor response times
      - Track error rates
      - Measure throughput
      - Monitor resource usage (CPU, memory, disk)
      - Set up performance alerts
      - Use APM tools (New Relic, Datadog)
      - Track Core Web Vitals for frontend
      - Create performance dashboards

      ## Load Testing

      Test under load:

      - Simulate realistic traffic patterns
      - Test with production-like data volumes
      - Identify breaking points
      - Test autoscaling behavior
      - Measure latency percentiles (p50, p95, p99)
      - Test sustained load and spike scenarios
      - Document performance benchmarks
      - Test before major releases
    level: 2
    fingerprint: large-rules-performance
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/performance.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/performance
          version: 1.0.0
          spec_version: "1"
          summary: Performance optimization, profiling, and caching strategies
          title: Performance
    scope: personal
  - heading: Security Auth
    content: |

      # Security and Authentication

      ## Password Security

      Handle passwords securely:

      - Never store passwords in plain text
      - Use bcrypt, scrypt, or Argon2 for hashing
      - Use appropriate cost factor (10-12 for bcrypt)
      - Implement password strength requirements
      - Prevent password reuse
      - Support password reset securely
      - Rate limit password attempts
      - Never log passwords

      ## JWT Tokens

      Implement JWT securely:

      - Sign tokens with strong secret
      - Set appropriate expiration times (15-30 min for access tokens)
      - Use refresh tokens for long-lived sessions
      - Store tokens securely (httpOnly cookies)
      - Validate token signature and expiration
      - Include minimal claims in tokens
      - Implement token revocation if needed
      - Rotate signing keys periodically

      ## Session Management

      Manage sessions securely:

      - Generate cryptographically random session IDs
      - Set secure and httpOnly flags on cookies
      - Implement session timeout
      - Regenerate session ID after login
      - Clear sessions on logout
      - Store sessions securely (Redis, database)
      - Implement concurrent session limits

      ## OAuth and Social Login

      Implement OAuth securely:

      - Validate redirect URIs
      - Use state parameter to prevent CSRF
      - Validate OAuth tokens
      - Store OAuth tokens securely
      - Handle token refresh
      - Implement proper scopes
      - Validate user data from providers

      ## Authorization

      Implement role-based access control:

      - Define clear roles and permissions
      - Check permissions at every protected endpoint
      - Use middleware for authorization
      - Implement least privilege principle
      - Log authorization failures
      - Test authorization logic thoroughly
      - Document permission requirements

      ## Input Validation

      Validate all inputs:

      - Validate on server side (never trust client)
      - Use schema validation (Zod, Joi, etc.)
      - Sanitize inputs to prevent injection
      - Validate file uploads (type, size, content)
      - Implement rate limiting
      - Reject unexpected fields
      - Return clear validation errors

      ## SQL Injection Prevention

      Prevent SQL injection:

      - Use parameterized queries always
      - Never concatenate user input into SQL
      - Use ORM with proper escaping
      - Validate and sanitize inputs
      - Use least privilege database accounts
      - Log suspicious query patterns

      ## XSS Prevention

      Prevent cross-site scripting:

      - Escape output in templates
      - Use Content Security Policy headers
      - Sanitize HTML input
      - Use framework's built-in escaping
      - Validate URLs before redirects
      - Set X-XSS-Protection header

      ## CSRF Protection

      Prevent cross-site request forgery:

      - Use CSRF tokens for state-changing operations
      - Validate CSRF tokens on server
      - Use SameSite cookie attribute
      - Validate Origin/Referer headers
      - Don't use GET for state changes

      ## API Security

      Secure API endpoints:

      - Use HTTPS everywhere
      - Implement rate limiting
      - Validate API keys/tokens
      - Use API versioning
      - Implement request signing for sensitive operations
      - Log API access
      - Monitor for abuse patterns
      - Implement IP whitelisting when appropriate

      ## Secrets Management

      Handle secrets securely:

      - Never commit secrets to git
      - Use environment variables
      - Use secret management services (AWS Secrets Manager, Vault)
      - Rotate secrets regularly
      - Encrypt secrets at rest
      - Limit access to secrets
      - Audit secret access
      - Use different secrets per environment

      ## Security Headers

      Set security headers:

      - Content-Security-Policy
      - X-Frame-Options: DENY
      - X-Content-Type-Options: nosniff
      - Strict-Transport-Security
      - Referrer-Policy
      - Permissions-Policy

      ## Dependency Security

      Manage dependencies securely:

      - Keep dependencies up to date
      - Run security audits regularly (npm audit, snyk)
      - Review dependency licenses
      - Pin dependency versions
      - Use lock files
      - Monitor for vulnerabilities
      - Have a patching process
    level: 2
    fingerprint: large-rules-security-auth
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/security-auth.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/security-auth
          version: 1.0.0
          spec_version: "1"
          summary: Authentication, authorization, and security best practices
          title: Security Auth
    scope: personal
  - heading: Testing Integration
    content: |

      # Integration Testing

      ## Test Structure

      Organize integration tests:

      - Place in `tests/integration/` directory
      - Name files descriptively: `user-registration.test.ts`
      - Group related tests with describe blocks
      - Use beforeEach/afterEach for setup/teardown
      - Keep tests independent and isolated
      - Run tests in parallel when possible

      ## Test Database

      Manage test database properly:

      - Use separate database for testing
      - Reset database between tests
      - Use transactions that rollback
      - Seed test data consistently
      - Use factories for test data creation
      - Clean up after tests complete
      - Never run tests against production database

      ## API Testing

      Test API endpoints thoroughly:

      - Test happy paths and error cases
      - Test authentication and authorization
      - Test input validation
      - Test rate limiting
      - Test with various content types
      - Verify response status codes and bodies
      - Test pagination and filtering
      - Use supertest or similar for HTTP testing

      Example:

      ```typescript
      describe("POST /api/users", () => {
        it("creates user with valid data", async () => {
          const response = await request(app)
            .post("/api/users")
            .send({ email: "test@example.com", name: "Test User" })
            .expect(201);

          expect(response.body.data).toHaveProperty("id");
          expect(response.body.data.email).toBe("test@example.com");
        });

        it("returns 400 with invalid email", async () => {
          await request(app)
            .post("/api/users")
            .send({ email: "invalid", name: "Test User" })
            .expect(400);
        });
      });
      ```

      ## Mocking External Services

      Mock external dependencies:

      - Mock HTTP clients for external APIs
      - Use nock or msw for HTTP mocking
      - Mock email/SMS services
      - Mock payment gateways
      - Mock file storage services
      - Keep mocks realistic
      - Update mocks when external APIs change
      - Document mock behavior

      ## Test Fixtures

      Create reusable test fixtures:

      - Use factory functions for test data
      - Keep fixtures minimal and focused
      - Use realistic data
      - Avoid hardcoded IDs
      - Make fixtures composable
      - Store fixtures near tests that use them

      Example factory:

      ```typescript
      export function createUser(overrides = {}) {
        return {
          email: "test@example.com",
          name: "Test User",
          role: "user",
          ...overrides,
        };
      }
      ```

      ## Async Testing

      Handle async operations properly:

      - Use async/await in tests
      - Set appropriate timeouts
      - Wait for operations to complete
      - Don't use arbitrary delays
      - Test timeout scenarios
      - Handle promise rejections

      ## Error Testing

      Test error scenarios:

      - Test validation errors
      - Test database errors
      - Test network failures
      - Test timeout scenarios
      - Test concurrent operations
      - Test edge cases
      - Verify error messages and codes

      ## Test Coverage

      Maintain good test coverage:

      - Aim for 70-80% coverage
      - Focus on critical paths
      - Test business logic thoroughly
      - Don't test framework code
      - Use coverage reports to find gaps
      - Don't chase 100% coverage blindly

      ## CI Integration

      Run tests in CI pipeline:

      - Run on every pull request
      - Fail build on test failures
      - Run tests in parallel for speed
      - Use test containers for dependencies
      - Cache dependencies
      - Report test results
      - Track test execution time
    level: 2
    fingerprint: large-rules-testing-integration
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/large-rules/testing-integration.md
    vendor:
      aligntrue:
        frontmatter:
          id: large-rules/testing-integration
          version: 1.0.0
          spec_version: "1"
          summary: Integration testing patterns and best practices
          title: Testing Integration
    scope: personal
  - heading: Personal Rules
    content: |

      # Personal Coding Preferences

      These are my personal coding preferences that complement team standards.

      ## Editor Configuration

      Use VSCode with these extensions:

      - Prettier for code formatting
      - ESLint for linting
      - GitLens for git history
      - Error Lens for inline diagnostics

      Configure auto-save on focus change and format on save.

      ## Code Style Preferences

      I prefer functional programming patterns when appropriate:

      - Use `const` by default, `let` only when reassignment is needed
      - Prefer arrow functions for callbacks and short functions
      - Use array methods (map, filter, reduce) over loops
      - Favor immutability and pure functions

      ## Import Organization

      Organize imports in this order:

      1. Node built-ins
      2. External packages
      3. Internal absolute imports
      4. Internal relative imports

      Add blank lines between groups for clarity.

      ## Comment Style

      Write comments that explain "why" not "what":

      - Document business logic and non-obvious decisions
      - Add TODO comments with your initials and date
      - Use JSDoc for public APIs and exported functions
      - Keep comments concise and up-to-date

      ## Testing Preferences

      I prefer test-driven development:

      - Write tests before implementation
      - Use descriptive test names that read like sentences
      - Arrange-Act-Assert pattern for test structure
      - Mock external dependencies, not internal modules

      ## Git Workflow

      My git workflow preferences:

      - Commit early and often with atomic commits
      - Write commit messages in present tense
      - Use conventional commits format (feat:, fix:, docs:, etc.)
      - Rebase feature branches before merging
      - Squash commits for cleaner history

      ## Local Development Tools

      I use these tools for local development:

      - `nvm` for Node version management
      - `pnpm` for package management
      - `tmux` for terminal multiplexing
      - `ripgrep` for fast code search
      - `jq` for JSON processing

      ## Debugging Approach

      My debugging workflow:

      - Start with reading error messages literally
      - Use debugger breakpoints over console.log
      - Reproduce issues with minimal test cases
      - Document findings in issue comments
      - Add tests to prevent regressions

      ## Performance Mindset

      I prioritize performance where it matters:

      - Profile before optimizing
      - Focus on algorithmic complexity first
      - Cache expensive computations
      - Lazy load when possible
      - Measure impact with benchmarks

      ## Documentation Habits

      I maintain documentation as I code:

      - Update README when adding features
      - Document API changes in CHANGELOG
      - Add inline comments for complex logic
      - Create diagrams for architecture decisions
      - Keep examples up-to-date
    level: 2
    fingerprint: personal-coding-preferences
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/personal-rules.md
    vendor:
      aligntrue:
        frontmatter:
          id: personal/coding-preferences
          version: 1.0.0
          spec_version: "1"
          summary: Personal coding preferences and local tooling configuration
          title: Personal Rules
    scope: personal
  - heading: Potential Future Features
    content: >

      # Potential future features


      This document tracks features that were considered but explicitly
      deferred. Each entry includes:


      - What was deferred and why

      - Current approach or workaround

      - Clear trigger(s) that indicate when to reconsider implementation

      - Estimated effort and implementation notes


      **When to use this:** Reference when users request features or when
      triggers are met.


      ---


      ## Permanently removed features


      ### Catalog as Remote Service


      **Status:** Permanently removed - not planned for future


      **What was removed:**


      - Remote catalog API for rule discovery

      - Catalog publishing commands (`aligntrue publish`)

      - Catalog-based source resolution

      - Centralized catalog website with search/discovery UI


      **Why removed:**


      - Added unnecessary complexity for solo and team workflows

      - Git-based sharing provides sufficient collaboration without central
      registry

      - Local example packs serve documentation needs adequately

      - Users prefer direct git URLs over catalog abstraction


      **Current approach:**


      - Users share rules via git repositories (GitHub, GitLab, self-hosted)

      - Example packs in `examples/packs/` provide seed data for documentation

      - Direct git URL imports via `aligntrue pull` command


      **Not planned:** Remote catalog service will not be reconsidered. All
      references removed from codebase.


      # Growth flywheel and community ignition


      - Align discovery: Should there be a way to browse/search aligns?

      - Starter packs deliver instant value in common stacks

      - Golden repos with public dashboards showing before and after metrics

      - Monthly public stats: Top Aligns, new packs, top exporters, drift trends

      - RFC process in `/rfcs` with template and voting in GitHub Discussions

      - Trust metric: verified authors, adoption count by hash, testkit
      conformance signal

      - Community rituals: weekly “Align Friday” releases; monthly “Top Aligns”
      blog; `good-first-align` bounties

      - Golden repos maintenance: locked by lockfile; weekly bot PR bumps deps
      and regenerates exports; alert if wow-metrics regress by more than 5%


      ---


      ## ☁️ Cloud Strategy and Monetization (Future)


      **Status:** Explicitly deferred until adoption demonstrates demand.


      **Adoption Trigger:** 100+ active repos OR 25+ organizations actively
      using AlignTrue + clear demand signal.


      **Note:** Cloud is optional. All core workflows (init, sync, check, team
      mode, CI gates) stay free and OSS forever.


      **Objective:** Monetize operational convenience (sync dashboard, approvals
      UI, org analytics) while keeping policy enforcement and determinism
      tooling free forever.


      ### Free vs Paid (Tentative Vision)


      | Feature                           | Free (OSS) | Paid (Cloud) |

      | --------------------------------- | ---------- | ------------ |

      | init, sync, check, export         | ✔         |              |

      | Unidirectional sync, watch mode   | ✔         |              |

      | Team mode, lockfiles, drift gates | ✔         |              |

      | CI validation and SARIF output    | ✔         |              |

      | Org sync dashboard                |            | ✔           |

      | Scheduled multi-repo PRs          |            | ✔           |

      | Approval workflows UI             |            | ✔           |

      | Drift analytics and trends        |            | ✔           |

      | SSO / RBAC (multi-org)            |            | ✔           |


      ### Cloud design principles (if built)


      - **Zero data at rest** — Cloud never stores private rules or config. Only
      hashes and minimal metadata.

      - **Git is source of truth** — Each org keeps rules in private repos.
      Cloud coordinates and verifies.

      - **Local enforcement** — All policy checks run in CI/CLI. Cloud provides
      visibility, not gatekeeping.

      - **Federated trust** — No org crawl without explicit scope. Repo-scoped
      tokens. Privacy by default.

      - **Open standards** — Use Sigstore, SLSA, SBOM. No proprietary lockdown.


      ### Implementation (Deferred)


      - Stack: Next.js, Vercel, minimal postgres for metadata

      - Data retention: 90 days default

      - Privacy: transparent, no data sales

      - Pricing: per-org or team tier (TBD post-launch)


      ### Acceptance criteria


      - Clear demand from 25+ organizations using AlignTrue

      - Pilot program with 3 users showing measurable adoption (drift down,
      onboarding faster)

      - Community feedback supports the vision


      ---


      # Implementing skills


      Updated deets:
      https://chatgpt.com/share/69098bdd-8a90-8001-a52d-89553d13381c


      You are Sonnet 4.5 with full repo context. Implement “Skills” as a
      first-class primitive in AlignTrue, separate from Rules,
      Claude-compatible, deterministic, and agent-agnostic.


      ## Objectives


      - Add a top-level `skills` config to AlignTrue (declarative).

      - Implement a lockfile with commit + hash pinning for reproducible
      installs.

      - Create CLI lifecycle: `install`, `lock`, `read`, `bundle`.

      - Update exporters to surface skills in `AGENTS.md` and sync to
      `.claude/skills/` or `.agent/skills/`.

      - Enforce spec validation for `SKILL.md` frontmatter. Note:
      `allowed-tools` is only enforced by Claude; treat it as advisory
      elsewhere.


      ## Guardrails


      - Node LTS 20, TypeScript strict, pnpm workspace.

      - Don’t touch unrelated code. Keep PR small, cohesive, and fully tested.

      - Idempotent file writes with clear markers. No duplicate skill listings.

      - Deterministic hashing (JCS where applicable) and stable sort orders.

      - Prefer commit SHAs over branches. Fail installs if ref is floating
      unless `--force`.


      ## High-level plan


      1. **Schema**
         - Edit `packages/schema/schema/align.schema.json` to add a top-level `skills` array referencing a new `$defs.skill_source`.
         - Create `packages/schema/schema/align.skills.lock.schema.json` for `.aligntrue.skills.lock.json`.

         **Targeted addition (trimmed) — align.schema.json**

         ```json
         {
           "properties": {
             "skills": {
               "type": "array",
               "description": "Declarative list of skill sources to install.",
               "items": { "$ref": "#/$defs/skill_source" }
             }
           },
           "$defs": {
             "skill_source": {
               "type": "object",
               "required": ["id", "source"],
               "properties": {
                 "id": { "type": "string", "pattern": "^[a-z0-9-]{1,64}$" },
                 "source": { "type": "string", "format": "uri" },
                 "ref": {
                   "type": "string",
                   "description": "Tag, branch, or commit; prefer commit SHA."
                 },
                 "install": {
                   "type": "string",
                   "enum": ["project", "global", "universal"],
                   "default": "project"
                 },
                 "include": { "type": "array", "items": { "type": "string" } }
               }
             }
           }
         }
         ```

      Lockfile sketch — .aligntrue.skills.lock.json


      {

      "lock_schema_version": 1,

      "resolved": [

      {

      "id": "core-skills",

      "source": "https://github.com/anthropics/skills.git",

      "commit": "abcdef1234…",

      "install": "project",

      "skills": [

      { "name": "pdf", "path": ".claude/skills/pdf", "sha256_dir": "…" },

      { "name": "xlsx", "path": ".claude/skills/xlsx", "sha256_dir": "…" }

      ]

      }

      ]

      }

          2.	Core utilities
          •	Add packages/utils/src/hashDir.ts to SHA-256 hash a directory deterministically (stable file order, exclude vcs dirs).
          •	Add packages/core/src/skills/validate.ts to validate SKILL.md frontmatter: name and description required, allowed-tools optional; length and charset checks.
          •	Add packages/core/src/skills/discovery.ts to scan skills using this precedence and dedupe by name:
          1.	./.agent/skills/
          2.	~/.agent/skills/
          3.	./.claude/skills/
          4.	~/.claude/skills/

      Highest-priority location wins. 3. CLI

      Create new commands under packages/cli/src/commands/skills/:

      • install.ts

      • Read .aligntrue/config.yaml → skills[].

      • Resolve ref to commit (prefer SHA). If branch/tag, resolve to SHA and
      warn; with --force allow floating.

      • Clone/checkout into target:

      • project → .claude/skills/ (default)

      • global → ~/.claude/skills/

      • universal → .agent/skills/ (or ~/.agent/skills/ if global)

      • Validate each SKILL.md. Compute sha256_dir. Update lockfile.

      • lock.ts

      • Resolve and pin refs to SHAs without cloning content changes. Write
      .aligntrue.skills.lock.json.

      • read.ts

      • Output normalized SKILL.md to stdout with a header indicating base
      directory for references/ or scripts/. Mirrors openskills read <name>.

      • bundle.ts

      • Create deterministic tarball of installed skills + index.json with file
      hashes for CI distribution.

      • Add shared helpers for git checkout, hashing, frontmatter parse.

      CLI usage examples


      pnpm aligntrue skills lock

      pnpm aligntrue skills install

      pnpm aligntrue skills read pdf

      pnpm aligntrue skills bundle --out dist/skills.tgz

          4.	Exporters
          •	Update packages/exporters/src/agents-md/index.ts to inject an idempotent skills section between markers.
          •	Implement discovery + dedupe. Generate XML block with usage guidance and <available_skills>.

      Exact block to write into AGENTS.md


      <skills_system priority="1">


      ## Available skills


      <!-- SKILLS_TABLE_START -->

      <usage>

      When users ask you to perform tasks, check if any of the available skills
      below can help.

      How to use skills (non-Claude agents):

      - Invoke: Bash("aligntrue skills read &lt;skill-name&gt;")

      - The skill content will load with detailed instructions

      - The base directory will be printed for resolving bundled resources

      Notes:

      - Only Claude enforces `allowed-tools` at runtime. For others, treat it as
      advisory policy.

      </usage>

      <available_skills>
        <!-- one line per deduped skill -->
        <!-- <skill><name>pdf</name><description>PDF toolkit…</description><location>project</location></skill> -->
      </available_skills>

      <!-- SKILLS_TABLE_END -->

      </skills_system>

          •	Add/confirm a Claude exporter (e.g., packages/exporters/src/claude/index.ts):
          •	Copy installed skills to .claude/skills/ for the chosen scope.
          •	Optionally support --universal to prefer .agent/skills/.

          5.	Docs
          •	apps/nextra: Add “Skills” page with:
          •	What is a Skill vs Rule.
          •	Authoring SKILL.md frontmatter reference.
          •	Install modes: project/global/universal and precedence.
          •	Lockfile semantics and reproducibility expectations.
          •	Security note about allowed-tools.
          6.	Tests
          •	Unit: validate.ts, hashDir.ts, lockfile writer, dedupe logic.
          •	Integration: fixture repo with 2 demo skills; run skills lock → install → read → export.
          •	Golden test: AGENTS.md injection idempotency and dedupe across .agent/ and .claude/.
          •	E2E: pin to SHAs, assert identical hashes on re-install.

      Acceptance criteria

      • Adding skills to .aligntrue/config.yaml and running pnpm aligntrue
      skills install installs skills deterministically, writes a lockfile, and
      pnpm aligntrue sync exports to agents-md with the XML section and no
      dupes.

      • Re-running install/sync is idempotent. No spurious diffs.

      • pnpm aligntrue skills read <name> returns normalized SKILL.md and a base
      dir hint.

      • Lockfile pins commit SHAs and per-skill directory hashes; CI re-install
      reproduces identical hashes.

      • Claude exporter syncs to .claude/skills/ or .agent/skills/ based on
      mode.

      • All new code has unit + integration tests and passes lint/typecheck.


      Implementation notes

      • Use fast-glob with explicit allowlist for hashing; ignore .git,
      node_modules, editor temp files.

      • Normalize frontmatter via a single parser; serialize normalized markdown
      for read.

      • For AGENTS.md, wrap writes with <!-- SKILLS_TABLE_START --> and <!--
      SKILLS_TABLE_END -->. On update, replace only the interior.

      • Sort skills by name ascending for stable output. In dedupe,
      highest-priority location wins; lower ones are ignored.

      • Make advisory policy text about allowed-tools explicit in non-Claude
      exporters.

      • Keep PR under ~600 LOC net change. Separate commits: schema, utils, CLI,
      exporters, docs, tests.


      Deliverables

      • Schema update + new lockfile schema.

      • CLI commands: skills lock, skills install, skills read, skills bundle.

      • Exporters updated for skills.

      • Docs page + examples.

      • Full test coverage for new surfaces.


      If you want a lighter “start here” prompt later, say the word and I’ll
      compress this into a one-screen checklist.


      # White collar wedge


      Target Eng/Dev Managers who want better alignment with the product teams
      by codifying strategy/goals/priorities in rules as a priorities.mdc.


      Make this feature 100% free as part of the corp team version.


      ⸻


      1. Conceptually viable


      Yes — alignment beyond code will become a big theme. Most white-collar
      work is already rule-based (strategy docs, playbooks, OKRs, compliance
      checklists). Turning those into deterministic, versioned “Aligns” is
      plausible because:

      • Writing and reasoning about rules is native to LLMs.

      • Every org struggles with drift between strategy and execution.

      • AI introduces compounding misalignment (each agent amplifies gaps).


      So the macro thesis — “alignment infrastructure for organizations” — is
      sound.


      ⸻


      2. But adoption will be nonlinear


      Stage Likelihood Why

      Dev & AI-ops alignment 90% Verifiable, measurable, direct productivity
      gain.

      Cross-team (PM, design, docs) 60% Feels useful if integrated into existing
      workflows (GitHub, Notion, Google Docs). Needs low-friction adapters.

      Org-wide cultural alignment 25–30% Most companies resist anything that
      smells like “process policing.” You’ll need strong framing: insight, not
      surveillance.


      Realistically: devs → tech teams → ops → maybe exec layers over ~5 years.


      ⸻


      3. What makes it viable outside dev


      You’d need to translate your “rule + lock + drift” model into something
      that feels natural in business contexts:


      Concept Developer version Business version

      .aligntrue.yaml aligns for code agents playbooks / policy snippets

      drift check CI test quarterly strategy review or live dashboard

      lock hash deterministic proof "this doc aligns with Strategy v1.3"

      SARIF findings lint results deltas between doc language and declared
      priorities


      If you hide the YAML and surface “alignment scores” or “drift trends,” it
      could click.


      ⸻


      4. Why it could fail


      1. No visible pain at human scale.
         Misalignment hurts slowly, so few teams will install “alignment tools.”
         You’ll need to piggyback on existing motions (PR checks, doc reviews, goal-tracking).

      1. Over-surveillance optics.
         Anything that “reads Slack” or “scores alignment” risks backlash.
         Position it as assistive clarity, not compliance monitoring.

      1. Context ambiguity.
         Natural language strategy is fuzzy. You can’t measure drift without structured context.
         The model has to enforce structure first (like Asana or Notion databases) before AI can quantify it.

      ⸻


      5. How to make it real 1. Pick a single white-collar wedge.
         e.g. product requirements and engineering roadmaps alignment.
         Build a “strategy lint” that scans docs and flags contradictions with declared goals. 2. Use the same primitives.
         Rules (.aligntrue.yaml), checks (regex, manifest_policy), drift scoring (hash mismatches).
         It’s the same engine, different data adapters. 3. Integrate into daily tools.
         • PR comments → GitHub
         • Doc checks → Google Workspace or Notion API
         • Meeting notes → summary drift check 4. Sell visibility, not control.
         Dashboards showing how teams interpret goals are easier to adopt than enforcement tools.

      ⸻


      6. Viability snapshot


      Dimension Outlook

      Technical feasibility ✅ Solid (reuses AlignTrue engine)

      Market readiness ⚠️ Low near-term, rising as orgs drown in AI chaos

      Adoption friction 🔴 High — cultural resistance

      Monetization potential 🟢 Strong if you own “alignment analytics” data

      5-year TAM realism ~$1–3B if generalized as “alignment observability”


      ⸻


      TL;DR brutal version

      • The dev use-case is a lock.

      • The org-wide “AI alignment for people + policy” angle is visionary but
      3–5 years early.

      • You’ll fail if you lead with it; you’ll win if you grow into it via
      developer traction.

      • Success depends on reframing it as clarity tooling, not compliance
      tooling.


      If you can make “alignment” feel like a spell check for decisions, you’ll
      own that category.


      ⸻


      1. Determinism in coding


      In software, determinism is literal — same inputs → same outputs, byte for
      byte.


      Layer Example How AlignTrue enforces it

      Config .aligntrue.yaml YAML → JSON (JCS RFC 8785) → SHA-256 hash. Anchors,
      timestamps, and NaN are forbidden.

      Execution Running aln bundle or export cursor Uses stable merge order,
      sorted arrays, canonical JSON, UTC timestamps, and consistent newlines.

      Verification .aligntrue.lock.json and export footer Recomputing hash
      proves that bundle == lock. Drift = any mismatch.

      Measurement SARIF findings or lint results Each check emits deterministic
      IDs and fingerprints so results are comparable across runs.


      → This makes AlignTrue deterministic by design.

      It’s mechanical, measurable, and repeatable — ideal for software because
      the system’s state space is discrete and bounded.


      Why it works:

      Source code, configs, and outputs are structured text. You can hash them,
      diff them, and verify them across time and machines.


      ⸻


      2. Determinism in white-collar work


      Outside code, determinism becomes semantic — same intent should produce
      the same interpretation or decision, even when expressed differently.


      Context Deterministic equivalent Practical signal

      Product strategy A stable set of priorities and trade-offs Consistent
      language and weighting in docs, roadmaps, and goals

      Policy / compliance Versioned rulebook + proofs Documents and actions
      referencing the same rule IDs or hashes

      Org communication Message alignment Consistent phrasing and emphasis
      across Slack, decks, and briefs


      But here, “outputs” are words, decisions, and judgments — not code.

      You can’t hash a meeting. So determinism can’t be absolute; it becomes
      probabilistic or linguistic determinism:


      Given the same rules and context, independent agents (people or AIs)
      should reach similar conclusions.


      That’s the white-collar version of “same inputs → same outputs.”


      ⸻


      3. How AlignTrue could bridge them


      Mechanism In code In white-collar adaptation

      Rule packs (Aligns) YAML rules for code agents YAML or markdown rules
      describing company values, decision frameworks, OKRs

      Lockfiles .aligntrue.lock.json (hash proof) “Strategy lock” — a signed
      snapshot of agreed-upon priorities or principles

      Drift checks Compare exports to lock Compare new docs or AI-generated text
      to locked priorities or guidelines

      SARIF-style findings Lint errors, autofixes “Strategy lints” — soft
      warnings like “mentions revenue but omits customer impact (priority #2)”

      Fidelity notes “Approximation in exporter” Transparency note: “AI summary
      diverges 20% from strategic weightings.”


      Essentially, AlignTrue’s determinism becomes semantic reproducibility:

      you measure how closely actions or text align to a declared rule set.


      The math shifts from:


      hash(A) == hash(B)


      to:


      similarity(A, rule_set) ≥ threshold


      Same idea — a verifiable measure of alignment — but fuzzier inputs.


      ⸻


      4. The key distinction


      Property Coding determinism White-collar determinism

      Nature Binary, exact Probabilistic, contextual

      Measurement Hash / diff NLP similarity / rule coverage

      Error meaning Bug or misconfig Drift or misunderstanding

      Proof Cryptographic hash Statistical or linguistic confidence

      Tool role Enforcer Advisor / mirror


      In software, AlignTrue can enforce determinism.

      In org work, it can only approximate and visualize it.


      ⸻


      5. What this means strategically
         • Short term (coding) → Determinism is a product feature. You sell trust and reproducibility.
         • Long term (orgs) → Determinism is a metaphor. You sell insight: “Here’s where we drifted from what we said we value.”

      You’re not building a compiler; you’re building an alignment observatory.


      ⸻


      TL;DR

      • Coding determinism = cryptographic reproducibility.

      • White-collar determinism = semantic consistency.

      • Both share the same goal: make alignment visible, measurable, and
      improvable.


      The more structured an org’s knowledge becomes, the closer it gets to the
      same kind of determinism that AlignTrue already guarantees for code.


      1. What “determinism” would mean outside code


      In org life, there’s no compiler. You can’t hash a meeting or unit-test a
      decision.

      So determinism stops meaning byte identical and starts meaning
      interpretation identical:


      Given the same strategy, information, and rules, two competent humans (or
      AIs) should make the same call most of the time.


      That’s the white-collar analog of same input → same output.


      It’s about predictable reasoning, not identical bytes.


      ⸻


      2. What’s actually deterministic in this context


      Layer Analogue to coding What could be deterministic How AlignTrue could
      enforce it

      Strategy rules .aligntrue.yaml Versioned YAML or doc that encodes values,
      priorities, tradeoffs Hashable strategy align; signed by leadership

      Lockfile .aligntrue.lock.json A frozen snapshot of what "aligned
      decisions" mean at a moment in time "Strategy lock" with checksums +
      signatures

      Drift checks aln check / SARIF Comparing new docs, plans, or decisions to
      that lock NLP or embedding similarity: score % alignment

      Findings Lint results Specific deltas like "mentions growth but not
      customer impact (priority #2)" Machine check with align ID and evidence

      Exports .cursor/rules AI directives derived from strategy ("when
      summarizing, weigh security>speed") Same YAML → same AI behavior in
      Slack/Notion bots


      So you could think of AlignTrue for orgs as a compiler for intent:

      it takes messy language (memos, decks, goals) and checks whether they
      compile to the declared align.


      ⸻


      3. How it would feel as a knowledge worker


      Imagine your company defines a short “Strategy Align”:


      id: org/2025-priorities

      priorities:


      - name: "Customer trust first" # weight 0.5

      - name: "Speed of delivery" # weight 0.3

      - name: "Efficiency" # weight 0.2
        aligns:
      - id: mention-customer
        severity: MUST
        check:
        type: regex
        pattern: "(customer|user|client)"
        scope: "docs/\*_/_.md"
      - id: avoid-internal-jargon
        severity: SHOULD
        check:
        type: regex
        pattern: "\\bsynergy\\b|\\bparadigm\\b"
        negate: true

      Now every doc, roadmap, or slide you write is checked by an AlignTrue bot.


      You'd experience:

      • Inline hints: "You mentioned speed but not customer trust — add one
      example."

      • "Alignment score: 0.82 vs last quarter's 0.74."

      • A dashboard showing which teams' plans drift most from strategy.

      • PR-style suggestions for doc updates ("add customer example per align
      org/2025-priorities#mention-customer").


      It doesn't block you; it mirrors drift — making misalignment visible the
      same way ESLint makes bad patterns visible.


      ⸻


      4. How it would feel as a manager or exec


      You’d see determinism as consistency and traceability across people and AI
      tools:


      Benefit Example

      Stable decisions Two teams faced with similar trade-offs make similar
      calls because they share the same align pack.

      Explainable reasoning When something diverges, you can point to "Align X"
      instead of gut feelings.

      Drift metrics Dashboards show which projects are 20% off-strategy
      (quantified via align coverage).

      Version control for intent You can see that this quarter's "lock" changed
      priorities and who approved it.


      So you’d manage by alignment deltas, not opinions.


      ⸻


      5. What’s truly deterministic vs approximate


      Dimension Coding determinism White-collar determinism

      Data type Code / config Language / decisions

      State space Finite Infinite, fuzzy

      Verification Hash comparison NLP similarity score

      Tolerance 0% difference allowed 10–20% drift tolerated

      Failure Bug Misalignment

      Proof Cryptographic Statistical


      In coding, determinism is absolute.

      In white-collar, it’s statistical but trackable — like saying “this doc
      aligns 87% with declared goals.”


      ⸻


      6. How AlignTrue could make that usable 1. Rule normalization
         Translate values, strategies, OKRs into small, testable rules (regex, embeddings, keyword coverage). 2. Semantic drift scoring
         Each new artifact (doc, email, summary) gets a numeric drift score vs lock. 3. Versioned intent
         Every strategy pack has a hash; any change is explicit and reviewable. 4. Feedback loops
         The system highlights where human behavior diverges from declared priorities.
         (“Team A keeps trading quality for speed despite policy.”) 5. AI-agent alignment
         The same rules feed into AI assistants so their writing and recommendations mirror org intent automatically.

      ⸻


      7. The lived experience of determinism here


      Role How it feels day-to-day

      Individual You get a "spell check for alignment." It nudges, not nags. You
      understand what's expected without meetings.

      Manager You get objective drift metrics and versioned rationale for
      changes.

      Org Culture becomes codified in small, auditable align pieces. Updates to
      strategy are propagated like code updates.


      It's not "AI policing language."

      It's AI linting reasoning — a reproducibility layer for judgment calls.


      ⸻


      8. Limits and truths
         • You'll never get byte-level determinism for human work. The goal is bounded variance, not identical behavior.
         • The metric is confidence: "80% chance this doc follows align pack X."
         • The danger is surveillance optics — must stay opt-in, advisory, transparent.
         • The payoff is massive when applied internally first (product, marketing, compliance) where drift costs real money.

      ⸻


      TL;DR


      In code: determinism = same bits.

      In business: determinism = same reasoning.


      AlignTrue's role outside coding is to give organizations:

      • A versioned, testable definition of "how we decide" via aligns.

      • A measurable way to see when real life drifts from that intent.

      • A feedback loop that keeps both humans and AIs interpreting strategy the
      same way.


      That's what "determinism" would feel like for white-collar work —

      not mechanical repetition, but predictable alignment of judgment.


      # mem0 Integration


      Here’s a backlog-ready cut you can drop in as a future feature.


      Feature: Optional Memory Provider (Mem0-compatible)


      Goal


      Let users opt into persistence for agents without touching AlignTrue’s
      deterministic path. Memory is a pluggable capability, not a requirement.


      Why

      • Agents work better when they remember repo norms and workflows.

      • Teams still need reproducible CI. Memory must be off by default and
      never run during validate unless explicitly requested.


      Scope

      • Add a provider-neutral capabilities.memory block to the Align spec.

      • Ship a thin client and CLI to test, seed, and search memory.

      • Export configs for MCP and Skills so Cursor or Claude can call memory
      tools.

      • Include advisory checks and a redaction layer.


      Non-Goals

      • No default activation.

      • No writes in CI unless --online is passed.

      • No provider lock-in.


      Spec change (non-breaking)


      capabilities:

      memory:

      provider: mem0 # future-proof. could be others later

      mode: openmemory*local # managed | self_hosted | openmemory_local

      endpoint: http://localhost:8765

      api_key_env: MEM0_API_KEY

      namespace: ${repo.name}

      default_ops: [store, search]

      policies:

      allow: ["non_sensitive_repo_facts"]

      deny_patterns: - "(?i)(password|secret|api[*-]?key)"


      Deliverables


      Area Deliverable Notes

      Schema capabilities.memory with enums and formats Backward compatible

      CLI aligntrue memory test Connectivity and auth check. Only with --online.

      aligntrue memory seed --from <globs> --namespace <ns> Extracts repo facts
      after redaction and stores them.

      aligntrue memory search --q "<query>" --top-k 5 Quick local debugging.

      Thin client packages/memory Minimal REST wrapper used by CLI and
      exporters.

      Exporters MCP client config Points to local OpenMemory or hosted Mem0
      server.

      Skills tools memory.store, memory.search, memory.delete wrappers.

      Configs .env.example and memory.config.json Endpoint, namespace, redaction
      regexes.

      Checks memory_policy, memory_connectivity, memory_dryrun Advisory only.
      Gate behind --online.

      Docs “Memory is optional” guide Local-first defaults, security notes,
      troubleshooting.


      Security and governance

      • Deny by default. Redact PII and secrets before any store.

      • Namespaces scoped per repo or org.

      • Clear guidance for local OpenMemory first. Hosted API is optional.


      Rollout plan 1. Add schema and feature flag. 2. Implement client and CLI.
      3. MCP exporter for local OpenMemory. 4. Skills exporter and config
      templates. 5. Advisory checks and docs.


      Risks and mitigations

      • Data leakage from careless seeding → ship deny patterns and require
      --online.

      • State divergence from non-determinism → default off and never in CI by
      default.

      • Vendor drift → provider-neutral interface and small wrapper layer.


      Acceptance criteria

      • Align file with capabilities.memory validates.

      • aligntrue memory test returns provider info when endpoint and key are
      set.

      • seed command shows a redaction preview and only writes with --confirm.

      • MCP export produces a working config that agents can use to add and
      search memory locally.

      • CI runs remain unchanged unless --online is set.

      • Docs include a one-page “turn it on” guide and a security checklist.


      Effort


      Band M. Roughly 60 to 90k tokens of implementation and docs.


      Open questions

      • Default namespace convention. Repo name only or org plus repo.

      • Retention policy and max item size.

      • Should we support read-only mode for CI smoke tests.


      # Deferred features


      ## Sigstore cryptographic signing


      **Deferred from:** Phase 1 verified authorship (Stage 1.4)


      **Current approach:** GitHub org validation (packs in `AlignTrue/aligns`
      are automatically verified)


      **Why deferred:** GitHub org validation provides sufficient trust for
      Phase 1. Sigstore adds complexity without clear demand signal.


      **Implementation trigger:**


      - External contributors explicitly request cryptographic verification, OR

      - 3+ incidents of disputed authorship occur, OR

      - Community consensus emerges that GitHub validation is insufficient


      **Implementation notes:**


      - Every Align would ship with `signatures/sha256-<hash>.sig` (Sigstore
      keyless)

      - CLI `aln verify-signature` would check signature → hash → content

      - Backward compatible: unsigned packs remain valid with warning

      - See Phase 1 spec in long_term.mdc for full design


      ---


      ## Full registry governance (disputes and SLAs)


      **Deferred from:** POLICY.md governance (Stage 1.4)


      **Current approach:** Minimal viable governance with namespacing,
      contribution requirements, and yanking process


      **Why deferred:** No external disputes yet. Premature process creates
      friction without value.


      **Implementation trigger:**


      - First external dispute arises that minimal governance cannot resolve, OR

      - 10+ active external contributors participate in the registry, OR

      - Community explicitly requests formal dispute resolution process


      **Implementation notes:**


      - Add dispute resolution process with clear escalation path

      - Define maintainer response SLAs (e.g., 48h for CRITICAL, 7d for normal)

      - Establish emergency yank procedure with notification requirements

      - Consider governance working group or steering committee

      - See Phase 1 spec in long_term.mdc for CVE-style advisory system


      ---


      ## MCP Server Declarations


      **Deferred from:** Phase 2 consideration


      **Current approach:** AlignTrue generates MCP config files
      (`.cursor/mcp.json`, `.vscode/mcp.json`, `.mcp.json`, etc.) but does not
      declare or manage MCP servers.


      **Why deferred:**


      - Focus on rule management and validation first (core value prop)

      - Server lifecycle management is orthogonal to alignment enforcement

      - Security concerns (server configs often contain API keys, internal URLs)

      - Users can combine tools: Ruler for server declarations + AlignTrue for
      rules

      - Zero users yet - no validation that this feature is needed


      **Implementation trigger:**


      - 10+ user requests for MCP server declarations, OR

      - Clear use case where server + rules must be atomically synced, OR

      - Phase 3 team mode adoption shows need for server standardization


      **Implementation notes:**


      - Add `mcp.servers` section to config schema

      - Support command/args for local servers, url/headers for remote

      - Env var interpolation with safety guardrails (`${MCP_TOKEN}`)

      - Never store secrets in config files (env vars only)

      - No lifecycle management (don't start/stop servers)

      - Optional merge strategies (merge vs overwrite existing configs)

      - See `docs/mcp-scope.md` for detailed rationale


      **Complementary tools:**


      - **Ruler:** MCP server infrastructure and declarations

      - **AlignTrue:** Rule content, validation, and team alignment

      - Both can coexist without conflict


      ---


      ## Additional exporter targets


      **Deferred from:** Phase 4


      **Current approach:** 48 exporters supporting 28+ AI coding agents


      **Why deferred:** Prove "one Align to many agents" with multiple
      exporters. Prioritize based on demand signals.


      **Implementation trigger:**


      - Clear demand signal for specific agent (e.g., 10+ requests for new
      agent), OR

      - Agent vendor requests integration partnership, OR

      - Community contribution meets exporter quality standards


      **Implementation notes:**


      - Choose exporters based on adoption and request volume

      - Capability matrix per exporter as machine-readable JSON

      - Loss catalog required for all exporters

      - Target <5% loss delta across exporters on golden repos


      ---


      ## AI-Assisted Rule Organization


      **Deferred from:** Coverage assessment (November 2025)


      **Current approach:** Manual categories and tags in catalog. Users
      organize rules themselves.


      **Why deferred:**


      - Core authoring workflow works well without AI assistance

      - No demand signal yet from users struggling with taxonomy

      - Build foundation first, add AI polish when pain is clear

      - Zero users yet - no validation that this feature is needed


      **Implementation trigger:**


      - 10+ user requests for auto-categorization, OR

      - Users report taxonomy fatigue or inconsistency, OR

      - Phase 4.5 polish iteration prioritizes this feature


      **Implementation notes (~45k tokens):**


      - Add `aligntrue organize` command with LLM-powered analysis

      - Analyze existing rules and suggest categories, tags, and rule IDs

      - Interactive mode: present suggestions, user accepts/rejects

      - Auto-generate rule IDs following dot-notation conventions

      - Batch operations: organize entire rule sets at once

      - Integration with markdown authoring for seamless workflow

      - Consider local LLM option for privacy (ollama, llamafile)


      **User experience:**


      ```bash

      # Analyze existing rules and suggest organization

      aligntrue organize --suggest


      # Apply suggestions interactively

      aligntrue organize --interactive


      # Auto-organize with defaults

      aligntrue organize --auto

      ```


      **Quality guardrails:**


      - Always show diffs before applying

      - Require explicit confirmation for structural changes

      - Preserve user overrides and customizations

      - Log decisions for future reference


      ---


      ## Enhanced agent-specific configuration


      **Deferred from:** Coverage assessment (November 2025)


      **Current status:** Basic export options exist (`export.mode_hints`,
      `performance` config)


      **Current approach:** Global configuration with minimal per-agent
      customization


      **Why deferred:**


      - Foundation exists and covers 80% of use cases

      - No demand signal for advanced per-agent settings

      - Better to document existing capabilities first


      **Implementation trigger:**


      - 10+ user requests for per-agent customization, OR

      - Specific agent requires unique configuration (timeouts, paths, formats),
      OR

      - Phase 4.5 polish iteration identifies this as high-impact


      **Implementation notes (~15k tokens):**


      - Document existing `export.mode_hints.overrides` and `performance`
      options

      - Extend config schema with per-agent sections:

        ```yaml
        exporters:
          - cursor
          - agents-md

        exporter_config:
          cursor:
            timeout_ms: 5000
            token_limit: 8000
            output_path: .cursor/rules/custom.mdc
          agents-md:
            format: extended
            include_metadata: true
        ```

      - Add validation for agent-specific settings

      - Update documentation with examples

      - Consider agent capability matrix for smart defaults


      **Documentation priority:**


      - README section highlighting current customization options

      - Config reference with all available settings

      - Examples for common use cases


      ---


      ## Homebrew installation


      **Deferred from:** Coverage assessment (November 2025)


      **Current approach:** npm/pnpm only (Node ecosystem)


      **Why deferred:**


      - npm covers majority of target users (TypeScript/JavaScript developers)

      - No demand signal from non-Node users

      - Can ship quickly when needed


      **Implementation trigger:**


      - 10+ requests from Python/Ruby/Go developers, OR

      - Adoption metrics show friction from npm-only install, OR

      - Community contributor offers to maintain Homebrew tap


      **Implementation notes (~20k tokens):**


      - Create Homebrew tap repository: `AlignTrue/homebrew-tap`

      - Formula for `aligntrue` CLI pointing to npm package

      - Standard Homebrew formula structure:

        ```ruby
        class Aligntrue < Formula
          desc "AI-native rules and alignment platform"
          homepage "https://aligntrue.ai"
          url "https://registry.npmjs.org/@aligntrue/cli/-/cli-X.Y.Z.tgz"
          sha256 "..."

          depends_on "node"

          def install
            system "npm", "install", *std_npm_args
            bin.install_symlink Dir["#{libexec}/bin/*"]
          end
        end
        ```

      - CI automation for formula updates on npm releases

      - Installation docs: `brew install aligntrue/tap/aligntrue`

      - Consider official Homebrew core submission after validation


      **Alternative:** Simple shell script installer as interim solution


      ---


      ## Tool-Specific Migration Converters


      **Deferred from:** Coverage assessment (November 2025)


      **Current approach:** Users manually copy/paste from existing agent files
      into AGENTS.md, then sync


      **Why deferred:**


      - Import functionality was removed (users author AGENTS.md directly)

      - No clear demand for automated migration converters

      - Manual copy/paste covers most migration needs

      - Focus on natural markdown authoring instead


      **Implementation trigger:**


      - 10+ requests for specific tool migration (e.g., "migrate from Ruler"),
      OR

      - Clear user pain with manual migration process, OR

      - Partnership with tool vendor for migration path


      **Implementation notes (~60k tokens):**


      - Add `aligntrue migrate --from=<tool>` command

      - Tool-specific adapters in `packages/cli/src/migrations/`

      - Supported tools by priority:
        1. Ruler (.rulerrc, ruler.yaml)
        2. Legacy .cursorrules files
        3. Custom .airc or similar formats
        4. IDE-specific settings (VS Code, IntelliJ)
      - Migration report showing coverage and manual steps

      - Preserve original files with `.backup` suffix

      - Interactive mode for ambiguous conversions


      **Quality requirements:**


      - 90%+ automated conversion rate for common patterns

      - Clear documentation of manual steps for remaining 10%

      - Validation of migrated rules before applying

      - Rollback capability if migration fails


      ---


      ## Additional package manager support


      **Deferred from:** Coverage assessment (November 2025)


      **Current approach:** npm/pnpm (and potentially Homebrew)


      **Why deferred:**


      - npm + Homebrew covers 90%+ of target users

      - Diminishing returns for additional package managers

      - Maintenance burden increases with each manager


      **Implementation trigger:**


      - Specific user base requests it (e.g., Python community wants pip), OR

      - Adoption metrics show significant friction from missing package manager,
      OR

      - Community contributor offers to maintain package


      **Implementation notes (80k tokens total):**


      **pip wrapper (~25k tokens):**


      - Simple Python wrapper around npm package

      - Published to PyPI as `aligntrue`

      - Handles Node.js dependency installation

      - Alternative: npx-based launcher


      **apt PPA (~30k tokens):**


      - Debian/Ubuntu package repository

      - `.deb` package with bundled Node.js binary

      - Automatic updates via apt

      - Requires signing key and repository hosting


      **Docker image (~15k tokens):**


      - Official Docker Hub image

      - Pre-installed with Node.js and CLI

      - Useful for CI environments

      - Volume mounts for workspace access


      **asdf plugin (~10k tokens):**


      - Version management integration

      - Community-maintained alternative

      - Lower maintenance burden


      **Priority order:** Homebrew → pip wrapper → Docker → asdf → apt PPA


      ---


      # Deferred technical improvements


      This section tracks technical refactoring and infrastructure improvements
      deferred to Phase 4.5 or later. Items here require a stabilized codebase
      and should be reviewed when triggers occur.


      ## Atomic writing abstraction


      **Deferred from:** Foundation cleanup review


      **Current approach:** AtomicFileWriter used directly in 46 files with
      slight variations


      **Why deferred:** Current pattern is safe and works well. Premature
      abstraction without usage pain.


      **Implementation trigger:**


      - Pattern becomes problematic (errors, inconsistencies), OR

      - Phase 4.5 stabilization review prioritizes this, OR

      - Adding 20+ new file write sites with different patterns


      **Implementation notes (~3k tokens):**


      - Create `packages/file-utils/src/safe-writer.ts`

      - Function: `writeFileSafe(path: string, content: string, options:
      WriteOptions): Promise<void>`

      - Built-in dry-run support, standardized error messages

      - Gradually migrate 46 call sites


      ---


      ## Validation logic centralization


      **Deferred from:** Foundation cleanup review


      **Current approach:** Schema validation fairly centralized in
      packages/schema


      **Why deferred:** Already well-organized. Low ROI for further
      consolidation.


      **Implementation trigger:**


      - Validation logic becomes scattered across 5+ packages, OR

      - Duplicate validation rules found in multiple locations, OR

      - Phase 4.5 review identifies validation inconsistencies


      **Implementation notes (~5k tokens):**


      - Create `packages/core/src/validation/` directory

      - Consolidate: `validateRules()`, `validateConfig()`, `validateLockfile()`

      - Single source of truth for business rules


      ---


      ## Build/CI Optimization


      **Deferred from:** Foundation cleanup review


      **Current approach:** Simple pnpm recursive scripts, sequential builds


      **Why deferred:** No performance issues yet. Build times acceptable.


      **Implementation trigger:**


      - Build times exceed 5 minutes, OR

      - 15+ packages in workspace, OR

      - CI costs become significant


      **Implementation notes (~5k tokens):**


      - Evaluate Turborepo for build caching

      - Parallelize package builds where dependencies allow

      - Add build-time dependency analysis

      - Incremental TypeScript compilation


      ---


      ## Mode hints optional enhancements


      **Deferred from:** Phase 2 Stage 1 (Step 9a)


      **Status:** Core mode hints functionality complete. Optional polish
      deferred.


      **Deferred items:**


      - Step 9d: Enhanced import parser with marker pairing (~1.5k tokens)

      - Step 9e: Validate command with 9 checks (~2.5k tokens)

      - Step 9f: Documentation updates (~0.5k tokens)

      - Step 9g: Integration testing (~1k tokens)


      **Why deferred:** Core mode hints experiment complete and
      production-ready. Optional features await user feedback.


      **Implementation trigger:**


      - 10+ user requests for enhanced mode validation, OR

      - Import from AGENTS.md with mode markers shows parser issues, OR

      - Phase 4.5 review prioritizes mode hints polish


      **Total effort if implemented:** ~5.5k tokens


      ---


      ## Execution modes and conditional rules


      **Deferred from:** Phase 2 planning discussion (execution modes feedback)


      **Current approach:** Static rule exports with hierarchical scopes and
      applies_to patterns for basic file-based filtering. Phase 2 includes a
      lightweight mode hints experiment (~6k tokens) to validate demand before
      considering any investment in execution modes infrastructure.


      **Why deferred:** Architecturally sound concept but operationally heavy
      for current phase. Requires significant infrastructure (conditions engine,
      loader integration, agent cooperation) without clear user demand yet.


      **Implementation trigger:**


      - 10+ user requests specifically for conditional rule execution (not just
      file-based filtering), OR

      - Phase 2 adoption reaches 50+ repos showing need for conversation-aware
      rule injection, OR

      - Agent vendors (Cursor, VS Code, etc.) expose APIs for runtime rule
      injection


      **Implementation notes:**


      **Schema Extensions (~20k tokens):**


      - Add `mode` field: `"always" | "manual" | "intelligent"` with intelligent
      as default

      - Add `conditions` DSL for deterministic triggers:
        ```yaml
        conditions:
          all:
            - language_any: ["typescript", "javascript"]
            - not:
                any:
                  - path_glob_any: ["**/*.test.*", "**/__tests__/**"]
                  - text_matches_any:
                      - pattern: "console\\.log\\("
                        flags: ["i"]
          budget_tokens: 120 # per-rule token limit
        ```
      - Profile-level caps: `max_rule_tokens: 1600`, `max_active_rules: 30`


      **Loader Responsibility (~40k tokens):**


      - AlignTrue becomes the "loader" that enforces execution policies

      - Preprocessor model: Evaluate conditions at sync time, export only
      matching rules

      - Runtime integration: MCP server or agent extensions for
      conversation-aware injection

      - Conflict resolution: severity wins, last-writer-wins, token budget
      enforcement


      **Manual Invocation UX (~10k tokens):**


      - CLI: `aligntrue apply <rule-id>` or `aligntrue apply --tag logging`

      - Agent palette: "AlignTrue: Apply rule..." commands

      - Chat triggers: `/align <rule-id>` in agent conversations


      **AGENTS.md Round-trip (~5k tokens):**


      - HTML comment markers for machine-parseable sections:
        ```html
        <!-- aligntrue:begin id="base.no-console" mode="intelligent" severity="error" -->
        ### No console in production Use `src/lib/logger.ts` instead.
        <!-- aligntrue:end id="base.no-console" -->
        ```
      - Enables unidirectional sync while preserving human readability


      **Security & Trust (~5k tokens):**


      - Sign rule packs, verify on load, allowlist sources

      - Audit trail of injected content hashes

      - Redact sensitive data in logs


      **Testing Requirements:**


      - Golden tests: Assert active rule sets and token counts for various repo
      contexts

      - Snapshot tests: Exported files match fixtures with conditional logic

      - Conflict tests: Severity tie-breaking and budget enforcement

      - Performance tests: Cold/warm cache evaluation times


      **Tradeoffs:**


      - **Pro:** Solves the core problem of LLM context bloat without requiring
      agent cooperation

      - **Pro:** Deterministic and testable (unlike prompt-based approaches)

      - **Con:** Significant complexity increase (~80k+ tokens for full
      implementation)

      - **Con:** Requires agent APIs for runtime effectiveness (preprocessor
      model as Phase 2.5 compromise)

      - **Risk:** Agent vendors may not expose necessary hooks, limiting runtime
      capabilities


      ---


      # Conditional features (trigger-based)


      ## Migration framework


      **Status:** Not implemented - Waiting for trigger  

      **Trigger:** Post-1.0 schema breaking change required


      ### When to Implement


      **DO NOT build until:**


      - You reach 1.0 stable release, AND

      - You need to ship a breaking schema change, AND

      - User impact justifies tooling investment


      **Why conditional:**


      - Migration framework is ONLY useful for breaking schema changes

      - Without breaking changes, users can manually update YAML files

      - Building migrations speculatively is premature optimization

      - Pre-1.0, schema can iterate freely without migrations

      - Post-1.0, many products never need breaking changes


      ### Scope (When Trigger Met)


      **Before implementation, confirm with user:**


      - What breaking change is needed and why

      - How many user repos would be affected

      - Alternative approaches considered (deprecation, aliases, additive
      changes)

      - Decision to proceed with migration tooling (~60k token investment)


      **Implementation:** ~60k tokens


      1. **IR Versioning System** - 10k tokens
         - `spec_version` migration logic in `packages/schema/src/migrations/`
         - Version adapter interface for schema evolution
         - Migration metadata tracking (from_version, to_version, applied_at)

      2. **Migration Framework Core** - 15k tokens
         - Pure JSON transforms (no I/O, no hashing in transforms)
         - Validation sandwich: validate input IR → transform → validate output IR
         - Deterministic, idempotent transforms only

      3. **Migration CLI** - 10k tokens
         - `aligntrue migrate --from <v> --to <v> --dry-run` (preview changes)
         - Requires `--write` flag to apply changes (safety)
         - Clear diff preview showing before/after
         - Rollback support via backup before migration

      4. **Migration Tests** - 10k tokens
         - Round-trip tests: v1 → v2 → v1 produces identical output
         - Byte-identical transforms for determinism
         - Edge case coverage: empty fields, vendor bags, nested structures
         - Golden migration vectors in `packages/testkit/`

      5. **Migration Documentation** - 5k tokens
         - Create `docs/migration-guide.md` with user-facing examples
         - API documentation in `packages/schema/README.md`
         - Troubleshooting common migration issues

      ### Current status


      **No breaking changes planned.** Schema is stable through Phase 4 launch.


      If this status changes, update this section with:


      - What breaking change is needed and why

      - How many users would be affected

      - Alternative approaches considered

      - Decision to proceed with implementation


      ---


      ## Catalog add command (aligntrue add)


      **Deferred from:** Phase 4 catalog website completion


      **Current approach:** Manual config editing - users must manually add
      catalog sources to `.aligntrue/config.yaml` and run `aligntrue sync`


      **Why deferred:**


      - Catalog website built first to demonstrate vision and validate concept

      - Core catalog provider exists and can fetch packs from GitHub

      - No demand signal yet from users struggling with manual config editing

      - Focus on proving catalog discovery works before CLI integration


      **Implementation trigger:**


      - 10+ user requests for easier catalog pack installation, OR

      - Website analytics show high drop-off on install commands, OR

      - Phase 4.5 polish iteration identifies this as high-impact


      **Implementation notes (~25k tokens):**


      - Add `aligntrue add catalog:<pack-id>@<version>` command

      - Uses existing `CatalogProvider` to fetch and validate packs

      - Automatically adds source to `.aligntrue/config.yaml`

      - Runs `aligntrue sync` to generate agent files

      - Supports `--dry-run` for preview

      - Handles consent flow for catalog access


      **User experience:**


      ```bash

      # Add a catalog pack (currently requires manual config editing)

      aligntrue add catalog:packs/base/base-global@1.0.0


      # This would:

      # 1. Fetch pack from AlignTrue/aligns GitHub repo

      # 2. Add to .aligntrue/config.yaml sources array

      # 3. Run aligntrue sync to export to all agents

      # 4. Generate .cursor/rules/base-global.mdc, AGENTS.md, etc.

      ```


      **Current workaround:**


      ```yaml

      # Manual addition to .aligntrue/config.yaml

      sources:
        - type: catalog
          id: packs/base/base-global
          version: "1.0.0"
      ```


      **Quality requirements:**


      - Byte-identical output to manual config addition

      - Clear error messages for pack not found/network issues

      - Graceful handling of consent requirements

      - Integration tests with catalog provider mocking


      ---


      ## Catalog website with discovery UI


      **Archived:** November 4, 2025  

      **Location:** `archive/apps-web/`


      **What was built:** Full Next.js catalog website with discovery page, pack
      detail pages, search, filters, install flow, share functionality,
      analytics tracking, and SEO infrastructure. Phase 4 Sessions 2-6 complete
      with 11 curated packs from `catalog/examples/`.


      **Why archived:** Pre-launch simplification to reduce complexity and
      maintenance overhead. The dual-app setup (web + docs) created:


      - Deployment coordination issues

      - Broken catalog build references (`temp-build-catalog.mjs`)

      - Heavy pre-commit hooks

      - Rewrite proxy complexity between apps

      - Unnecessary overhead for 11 packs


      **Current approach:** Static catalog page in docs site at
      `/catalog/available-packs` with:


      - Nextra card components for visual display

      - Collapsible markdown table for alternative view

      - Manual updates from `catalog/packs.yaml`

      - Links to GitHub source files


      **Implementation trigger:**


      - **50+ active users** request catalog discovery UI, OR

      - **20+ curated packs** exist and manual list becomes unwieldy, OR

      - **User-generated pack sharing** becomes a priority feature


      **Restoration notes (~120k tokens):**


      If restoring, consider these improvements:


      1. **Unified app approach** - Integrate catalog into docs site instead of
      separate app

      2. **Simplified build** - Generate catalog JSON at build time, not as
      separate step

      3. **No dual deployment** - Single Vercel deployment, no rewrite proxying

      4. **Lighter stack** - Use Nextra's built-in features where possible


      **Architecture (if restored):**


      ```typescript

      // apps/nextra/app/catalog/[slug]/page.tsx

      // Integrate catalog routes into docs app

      // Use Nextra's MDX rendering for pack details

      // Generate static params from catalog/packs.yaml at build time

      ```


      **Build pipeline (if restored):**


      ```bash

      # Generate catalog JSON during docs build

      pnpm tsx scripts/catalog/build-catalog.ts

      # Output: apps/nextra/public/catalog/*.json

      # Consumed by: apps/nextra/app/catalog/*

      ```


      **Key features to preserve:**


      - Search with Fuse.js (client-side, no backend needed)

      - Category and tag filtering

      - Agent compatibility matrix

      - Install command generation

      - GitHub source linking


      **What to skip:**


      - Separate analytics tracking (use Vercel Analytics)

      - Complex share functionality (simple copy-link is enough)

      - Separate search index generation (inline in catalog JSON)


      **Estimated effort if restored:** ~120k tokens (much less than original
      due to lessons learned)


      **Related files:**


      - Archived code: `archive/apps-web/`

      - Catalog data: `catalog/packs.yaml` and `catalog/examples/*.yaml`

      - Build scripts: `scripts/catalog/build-catalog.ts` (still exists)

      - Current static page: `apps/nextra/content/catalog/available-packs.md`


      ---


      ## User-Generated Rule Sharing Platform


      **Deferred from:** Phase 4 catalog completion


      **Current approach:** Curated catalog with manual PR process for pack
      submissions. Basic URL sharing via copy-link functionality.


      **Why deferred:** Core catalog and curated content foundation complete.
      User-generated sharing adds complexity and scale challenges better
      addressed after launch validation.


      **Implementation trigger:**


      - 50+ curated packs in catalog with demonstrated adoption, OR

      - 10+ user requests for publishing their own rules, OR

      - Community shows interest in sharing custom rule sets


      **Implementation notes:**


      **Phase 4.6: User Publishing MVP (~45k tokens)**


      - User namespace schema extensions for catalog

      - CLI `aligntrue publish` command with GitHub verification

      - Dynamic profile pages at `/catalog/@username`

      - Basic social share buttons (Twitter/X, LinkedIn)


      **Phase 4.7: Enhanced Discovery (~30k tokens)**


      - Pack adoption metrics and trending algorithms

      - User reputation system with trust scores

      - Advanced sharing with "Copy for [Agent]" buttons

      - Cross-agent compatibility matrix on pack pages


      **Phase 4.8: Social Features (~25k tokens)**


      - Rich social previews (Open Graph, Twitter Cards)

      - Pack forking and "Remix this pack" functionality

      - Share analytics and engagement tracking

      - Optional community features (comments, ratings)


      **Architecture Foundation:**


      - User packs stored in `catalog/user-packs/@username/`

      - Build-time generation of profile pages

      - GitHub ownership verification for namespaces

      - Trust scores based on GitHub activity and adoption


      **URL Structure:**


      ```

      /catalog/@username              # Profile page

      /catalog/@username/pack-name     # Pack detail

      /catalog/@username/pack-name?agent=cursor  # Agent-specific copy

      ```


      **Key Features:**


      - Cross-agent compatibility assurance (leverages existing 48 exporters)

      - Automatic profile page generation on publish

      - Social sharing with rich previews and pre-filled content

      - Easy copying based on user's IDE/agent preference


      ---


      ### References


      - Zero-users principle:
      `.cursor/rules/no_premature_backwards_compatibility.mdc`

      - Pre-1.0 policy: Schema can iterate freely before 1.0

      - Phase execution plans: See archive/ directory for completed phase
      implementation details
    level: 2
    fingerprint: potential-future-features
    source_file: .aligntrue/rules/potential_future_features.md
    vendor:
      aligntrue:
        frontmatter:
          description:
            Potential future features - deferred ideas and implementation
            triggers
          enabled: false
          gitignore: true
          scope: personal
          content_hash: 46fa74fe6102af5c862838bc627ed938ae275a0181ea1ac4a8b1ea4b190e64de
          title: Potential Future Features
    scope: personal
  - heading: Pull Request Standards
    content: >

      # Pull request standards


      **When to apply:** Before marking any user facing feature as complete. Use
      this as the acceptance gate for all PRs that add or modify behavior.


      Every such PR must pass this checklist before merge.


      ---


      ## Documentation checklist


      Required (unless using the internal code exception below):


      - [ ] **API docs** for public APIs  
             `apps/docs/content/04-reference/{feature-slug}.md`
      - [ ] **User guide** if users must learn new workflows  
             `apps/docs/content/01-guides/{feature-slug}.md` or `apps/docs/content/03-concepts/{feature-slug}.md`
      - [ ] **Example** in `examples/{feature-slug}/README.md` with a runnable
      smoke block

      - [ ] **CHANGELOG.md** updated with a concise entry in the correct section

      - [ ] **Temp docs deleted**  
             No `*_STATUS.md`, `*_CHECKLIST.md`, `*_SUMMARY.md`, `*_PHASE*.md`, `*_IMPLEMENTATION.md`, or similar

      ---


      ## Example validation


      Each example must:


      - [ ] Run top to bottom without errors

      - [ ] Include a smoke block that prints tool version, seed, and platform

      - [ ] Pin randomness (for example `SEED=42`, no `Date.now()` in outputs)

      - [ ] Produce byte identical artifacts across two runs in the same
      environment

      - [ ] Show equivalent CLI usage with `aligntrue` commands

      - [ ] Link to the relevant API docs near the top

      - [ ] Use repo data or small synthetic data only (no downloads)

      - [ ] Stay under 30 sections, prefer 10 to 20


      ---


      ## API documentation validation


      All public symbols affected by the PR must have:


      - [ ] One line purpose statement

      - [ ] Parameters with types and shapes

      - [ ] Return types and shapes

      - [ ] Error cases and when they occur

      - [ ] Determinism notes when relevant (seeds, hashes, ordering)

      - [ ] Minimal example (2 to 5 lines)

      - [ ] Links to example, user guide, CLI command, and source


      ---


      ## Build and CI validation


      Before merge:


      - [ ] Docs site builds clean  
             `pnpm --filter @aligntrue/docs build` (or equivalent for the docs app)
      - [ ] All cross links between examples, API docs, and guides resolve

      - [ ] No references to deleted or renamed files

      - [ ] Type checks pass on changed packages  
             `pnpm exec tsc --noEmit -p packages/schema/tsconfig.json -p packages/cli/tsconfig.json`
      - [ ] Lint passes  
             `pnpm lint`
      - [ ] All tests pass  
             `pnpm test`
      - [ ] Determinism gate passes for any byte stable artifact  
             run under `TZ=UTC` and compare hashes

      ---


      ## UI package validation


      If the PR touches `packages/ui/src/**`:


      - [ ] No asset imports (no `.svg`, `.png`, `.jpg`, `.jpeg`, `.gif`,
      `.webp`)

      - [ ] SVGs are inline JSX or data URIs only

      - [ ] Linter passes `no-asset-imports-in-ui`

      - [ ] All consuming apps build clean  
             for example `pnpm --filter @aligntrue/docs build`
      - [ ] Theming uses CSS variables, not hardcoded colors

      - [ ] Constraints match `implementation_specs.md` Section 12


      ---


      ## Internal code exception path


      Use only when code is strictly internal.


      All must be true:


      - [ ] Code is internal utility, not part of public API

      - [ ] No CLI command imports or calls it

      - [ ] Comprehensive unit tests exist

      - [ ] Type checks pass

      - [ ] Module header includes an internal note  
             `/** @internal: rationale */`
      - [ ] `CHANGELOG.md` still updated with a short note


      Example:


      ```typescript

      /** @internal: hash utility used only by manifest writer */

      ```


      ---


      ## Agent self check before marking "done"


      Do not claim completion unless all relevant items below are true.


      1. Example (if added) runs twice with byte identical outputs

      2. All doc links are clicked locally and resolve

      3. Docs build passes without warnings that indicate missing pages

      4. No temporary `*_*.md` files remain in root or dev directories

      5. `CHANGELOG.md` includes a clear user facing summary

      6. All acceptance criteria in this file that apply to the change are
      satisfied

      7. If `packages/ui` changed, zero build constraints are satisfied and
      enforced


      If any single item fails, the feature is not done.


      ---


      ## What this prevents


      - Features without examples

      - Public APIs without documentation

      - Non deterministic examples that contradict determinism claims

      - Temp docs and status files accumulating in the repo

      - Broken cross links and missing pages

      - Silent user facing changes without `CHANGELOG.md` entries


      ---


      ## Enforcement model


      - AI agents must not mark work complete until this checklist passes

      - Human reviewers use this file as the PR review contract

      - CI should run:
        - docs build
        - type check
        - lint
        - tests
        - determinism checks for stable artifacts

      ---


      ## Quick commands


      ### Full gate (typical baseline)


      ```bash

      TZ=UTC pnpm test

      pnpm lint

      pnpm --filter @aligntrue/docs build

      ```


      ### Determinism spot check for an export


      ```bash

      sha256sum out/export.mdc

      sha256sum out/export.mdc

      # Hashes must match

      ```
    level: 2
    fingerprint: pull-request-standards
    source_file: .aligntrue/rules/pull_request_standards.md
    vendor:
      aligntrue:
        frontmatter:
          description: Pull request (PR) acceptance criteria and self-check gate
          content_hash: 0d08ae447c812bffc1630057a80e84bd0774da70d85ab2e824107dfa22726117
          title: Pull Request Standards
  - heading: Readme
    content: >
      # Remote test fixtures


      This directory contains test fixtures for AlignTrue CLI integration tests.
      These files are copied to the `AlignTrue/examples` GitHub repository to
      enable deterministic testing of remote workflow and large rule set
      performance.


      ## Purpose


      These fixtures enable two critical test scenarios:


      1. **Personal Remote Workflow**: Testing git-based personal rules
      synchronization

      2. **Large Rule Set Performance**: Testing CLI performance with realistic,
      large rule sets


      ## Structure


      ### Personal Rules


      `personal-rules.md` - A realistic personal rules file containing:


      - 10 sections covering typical personal coding preferences

      - Valid frontmatter (id, version, spec_version)

      - Realistic content about editor config, coding style, testing
      preferences, etc.


      Used for testing:


      - Remote git source configuration

      - Personal rules synchronization

      - Conflict detection between team and personal rules


      ### Large Rule Sets


      `large-rules/` - A collection of 9 rule files totaling 99 sections:


      | File                     | Sections |
      Topic                                     |

      | ------------------------ | -------- |
      ----------------------------------------- |

      | `backend-api.md`         | 14       | REST patterns, validation, error
      handling |

      | `frontend-react.md`      | 14       | Component patterns, state,
      hooks          |

      | `database.md`            | 10       | Migrations, queries,
      indexing             |

      | `testing-integration.md` | 9        | Test patterns, fixtures,
      mocking          |

      | `devops-ci.md`           | 11       | CI/CD, deployment,
      monitoring             |

      | `code-review.md`         | 10       | Review standards, PR
      templates            |

      | `documentation.md`       | 10       | API docs, README,
      architecture            |

      | `performance.md`         | 10       | Profiling, optimization,
      caching          |

      | `accessibility.md`       | 11       | WCAG, ARIA, keyboard
      navigation           |


      **Total: 99 sections across 9 files**


      This represents a comprehensive rule set that covers common development
      scenarios while remaining manageable for AI agents given context limits.


      ## Usage in Tests


      ### Remote Workflow Tests


      Tests reference the GitHub repo with pinned commit hash:


      ```typescript

      const EXAMPLES_REPO = "https://github.com/AlignTrue/examples";

      const COMMIT_HASH = "abc123..."; // Pinned for determinism


      // Configure source

      const config = {
        sources: [
          {
            type: "git",
            url: `${EXAMPLES_REPO}@${COMMIT_HASH}`,
            path: "remote-test/personal-rules.md",
          },
        ],
      };

      ```


      ### Performance Tests


      Tests copy large-rules/ fixtures to test projects:


      ```typescript

      // Copy all large rule files

      await fs.cp("examples/remote-test/large-rules", join(testDir, "rules"), {
        recursive: true,
      });


      // Configure sources to load all files

      const config = {
        sources: largeRuleFiles.map((file) => ({
          type: "local",
          path: `rules/${file}`,
        })),
      };


      // Measure sync performance

      const startTime = Date.now();

      await sync(config);

      const duration = Date.now() - startTime;


      // Assert performance thresholds

      expect(duration).toBeLessThan(60000); // <60 seconds

      ```


      ## Maintenance


      ### Updating Fixtures


      When updating these fixtures:


      1. Make changes in this directory

      2. Copy entire `remote-test/` directory to `AlignTrue/examples` repo

      3. Commit and push to GitHub

      4. Get the new commit hash

      5. Update `COMMIT_HASH` constant in test files

      6. Run tests to verify


      ### Adding New Fixtures


      To add new test fixtures:


      1. Create new file in appropriate location

      2. Follow existing frontmatter format

      3. Keep content realistic and meaningful

      4. Update this README with file description

      5. Update section count in table above

      6. Copy to GitHub repo and update tests


      ## Performance Thresholds


      Current performance expectations for large rule sets:


      - **Sync time**: <60 seconds for 100-150 sections

      - **Memory usage**: <500MB heap

      - **File I/O**: No catastrophic slowdown with multiple files


      These thresholds are tested in
      `packages/cli/tests/integration/performance.test.ts`.


      ## Related Documentation


      - Test implementation:
      `packages/cli/tests/integration/personal-remote.test.ts`

      - Performance tests: `packages/cli/tests/integration/performance.test.ts`

      - Git source tests: `packages/cli/tests/integration/git-sources.test.ts`

      - Testing guide: `packages/cli/tests/TESTING.md`

      - CLI testing playbook: `.cursor/rules/cli_testing_playbook.mdc`
    level: 2
    fingerprint: readme
    source_file: .aligntrue/.cache/git/e4b7aecca9d87240/remote-test/README.md
    vendor:
      aligntrue:
        frontmatter:
          title: Readme
    scope: personal
  - heading: Rule Writing
    content: >

      # Cursor & AlignTrue rules authoring guide


      ## Purpose


      Use this when creating or updating any Cursor or AlignTrue rule so
      guidance stays sharp, consistent, and testable.


      ---


      ## Output contract when proposing a rule change


      Every proposed rule or edit must include:


      1. Summary of change

      2. Rationale

      3. Updated rule text only

      4. Impacted areas and precedence notes

      5. Tests or examples if relevant

      6. Conflict check: rules it supersedes, extends, or defers to


      ---


      ## Authoring checklist


      - Write for the agent in imperative voice

      - One topic per rule; split large topics

      - Keep each rule under 500 lines

      - State where it applies and where it does not

      - Lead with hard constraints (must, never, only)

      - Add at least one minimal example for each key directive

      - Encode precedence when overlap is possible

      - Reference real context with `@Cursor Rules`, `@Docs`, and file paths

      - For response shaping rules, define an explicit output contract

      - Prefer paved road patterns over generic prohibitions

      - Ban known anti patterns directly with short examples

      - Keep diffs minimal; avoid full rewrites without cause

      - For parameterized, stack agnostic behavior, use plugs (see `plugs.mdc`)


      ---


      ## Rule structure


      Each rule must follow this shape:


      1. **Header**
         - `id`, `version`, `updated`, `owner`, `status`
      2. **Title**
         - Short, specific topic name
      3. **When this applies**
         - Repo paths, tech stack, scenarios
      4. **Constraints**
         - Explicit must, never, only
      5. **Patterns**
         - Preferred approaches and paved road flows
      6. **Output contract**
         - Required sections for agent replies
      7. **References**
         - `@Cursor Rules`, `@Docs`, files in repo
      8. **Examples**
         - One good, one bad
      9. **Precedence**
         - Which rules it overrides or defers to

      ---


      ## Quality bar


      Rules must be:


      - Clear, concrete, and testable

      - Short sentences, minimal jargon

      - Free of duplicated guidance across rules


      If guidance is duplicated, extract it into one rule and reference it.


      ---


      ## Maintenance


      - Update rules in the same PR as relevant architectural or workflow
      changes

      - Remove obsolete text instead of stacking exceptions

      - Use small, focused diffs

      - Treat rules as code: review, test, and version them


      ---


      ## Do not


      - Do not embed team philosophy or broad narrative

      - Do not use vague terms like "clean" or "simple" without criteria

      - Do not reference docs generically; use explicit `@` links or file paths
    level: 2
    fingerprint: rule-writing
    source_file: .aligntrue/rules/rule_writing.md
    vendor:
      aligntrue:
        frontmatter:
          description: Use this when drafting or updating any Cursor or AlignTrue rules.
          content_hash: a8d2faeca5803ee22d01e2c6eaa58c65952a9b83d351ced0357a73138bb2b0cd
          title: Rule Writing
  - heading: Security Linting Policy
    content: |

      # Security linting policy

      **Applies to**: `scripts/**/*.{js,mjs}`, `packages/**/*.{ts,tsx}`, `apps/**/*.{ts,tsx}`

      ## Overview

      This document defines when to suppress vs fix security warnings from `eslint-plugin-security` to ensure `pnpm check` only shows actionable warnings. It covers both TypeScript source files and JavaScript tooling scripts like build tools, validation scripts, and CLI utilities.

      ## Core principle

      **Suppress false positives with documentation. Fix real vulnerabilities.**

      ## When to Suppress

      ### 1. Safe Internal Paths

      **Suppress**: `security/detect-non-literal-fs-filename` for:

      - Schema files resolved from `__dirname` at build time
      - Paths from `getAlignTruePaths()` helper (all are safe internal paths)
      - Lockfile, bundle, and IR file paths (`.aligntrue/rules`, `.aligntrue/lock.json`, etc.)
      - Test fixtures and temporary files

      **Pattern**:

      ```typescript
      // eslint-disable-next-line security/detect-non-literal-fs-filename
      // Safe: Internal schema file path, resolved from __dirname at build time (not user input)
      const configSchema = JSON.parse(readFileSync(schemaPath, "utf8"));
      ```

      **Rationale**: These paths are not user-controlled and are safe by construction.

      ### 2. Validated User Input

      **Suppress**: `security/detect-non-literal-fs-filename` for paths that:

      - Go through `validateScopePath()` at config load time
      - Are validated for path traversal attacks
      - Are checked for absolute paths

      **Pattern**:

      ```typescript
      // eslint-disable-next-line security/detect-non-literal-fs-filename
      // Safe: Paths from config are validated via validateScopePath() at config load time (packages/core/src/config/index.ts:662)
      content = readFileSync(sourcePath, "utf8");
      ```

      **Rationale**: Validation prevents path traversal attacks, making the path safe.

      ### 3. Prototype Pollution Protection

      **Suppress**: `security/detect-object-injection` for dynamic property access that:

      - Has explicit `__proto__`, `constructor`, `prototype` checks before access
      - Uses `Object.prototype.hasOwnProperty.call()` for property checks
      - Validates keys before accessing object properties

      **Pattern**:

      ```typescript
      // eslint-disable-next-line security/detect-object-injection
      // Safe: Prototype pollution prevented by explicit __proto__/constructor/prototype checks above (lines 38-46)
      current[segment] = {};
      ```

      **Rationale**: Explicit checks prevent prototype pollution attacks.

      ### 4. Static Regex Patterns

      **Suppress**: `security/detect-unsafe-regex` and `security/detect-non-literal-regexp` for:

      - Static regex patterns (not constructed from user input)
      - Patterns with bounded quantifiers (no nested quantifiers)
      - Patterns used for parsing known-safe formats (markdown, JSON, etc.)

      **Pattern**:

      ```typescript
      // eslint-disable-next-line security/detect-unsafe-regex
      // Safe: Static regex pattern for parsing markdown links, bounded quantifiers prevent ReDoS
      const LINK_PATTERN = /\[([^\]]+)\]\(\/docs\/([^)#]+)(?:#[^)]+)?\)/g;
      ```

      **Rationale**: Static patterns are not vulnerable to ReDoS attacks.

      ### 5. Safe Child Process Execution

      **Suppress**: `security/detect-child-process` for:

      - `execSync()` with static, known commands (not user input)
      - Pre-defined command allowlists
      - Output that is parsed with static patterns only
      - Build/validation scripts where commands are controlled

      **Pattern** (JavaScript tooling scripts):

      ```javascript
      // eslint-disable-next-line security/detect-child-process
      // Safe: execSync runs static known command "pnpm lint", output parsed with static patterns
      output = execSync("pnpm lint --max-warnings 0", { encoding: "utf-8" });
      ```

      **Rationale**: Static commands with no user input are safe. Output parsing with static patterns prevents injection attacks.

      **When to Fix**: If a script accepts user arguments to a command, validate and escape them before passing to `execSync()`.

      ## When to Fix

      ### 1. Unvalidated User Paths

      **Fix**: All FS operations with user-provided paths must:

      - Go through `validateScopePath()` or similar validation
      - Check for path traversal (`..`)
      - Reject absolute paths
      - Normalize paths properly

      **Example**:

      ```typescript
      // ❌ Don't do this
      readFileSync(userProvidedPath, "utf8");

      // ✅ Do this
      validateScopePath(userProvidedPath);
      readFileSync(userProvidedPath, "utf8");
      ```

      ### 2. Unsafe Regex from User Input

      **Fix**: All regex patterns constructed from user input must:

      - Validate pattern length (max 200 characters)
      - Escape special characters properly
      - Check for nested quantifiers that could cause ReDoS
      - Use `safeRegExp()` helper from `packages/core/src/security/regex-validator.ts`

      **Example**:

      ```typescript
      // ❌ Don't do this
      const regex = new RegExp(`^${userPattern}$`);

      // ✅ Do this
      if (userPattern.length > 200) {
        throw new Error("Pattern too long");
      }
      const escaped = escapeForRegex(userPattern);
      const regex = safeRegExp(`^${escaped}$`);
      ```

      ### 3. Unprotected Object Property Access

      **Fix**: All dynamic property access with user input must:

      - Check for `__proto__`, `constructor`, `prototype` before access
      - Use `Object.prototype.hasOwnProperty.call()` for property checks
      - Validate keys before accessing

      **Example**:

      ```typescript
      // ❌ Don't do this
      obj[userKey] = value;

      // ✅ Do this
      if (
        userKey === "__proto__" ||
        userKey === "constructor" ||
        userKey === "prototype"
      ) {
        throw new Error("Invalid key");
      }
      obj[userKey] = value;
      ```

      ## Suppression documentation requirements

      All suppressions must include:

      1. **Rule name**: Which security rule is being suppressed
      2. **Rationale**: Why the code is safe (internal path, validated input, protection in place)
      3. **Reference**: Line numbers or function names where protection/validation occurs

      **Good example**:

      ```typescript
      // eslint-disable-next-line security/detect-non-literal-fs-filename
      // Safe: Path is typically from getAlignTruePaths().lockfile (safe internal path)
      const content = readFileSync(path, "utf8");
      ```

      **Bad example** (missing rationale):

      ```typescript
      // eslint-disable-next-line security/detect-non-literal-fs-filename
      const content = readFileSync(path, "utf8");
      ```

      ## ESLint Overrides

      For files where all operations are known-safe, use file-specific overrides in `eslint.config.js`:

      ```javascript
      {
        files: ["packages/core/src/paths.ts"],
        rules: {
          // All paths from getAlignTruePaths() are safe internal paths (not user input)
          "security/detect-non-literal-fs-filename": "off",
        },
      }
      ```

      ### JavaScript Tooling Scripts

      For build and validation scripts in `scripts/`, override rules when appropriate:

      ```javascript
      {
        files: ["scripts/**/*.mjs", "scripts/**/*.js"],
        rules: {
          // Scripts use static known commands via execSync, parsed with static patterns
          "security/detect-child-process": "off",
          // Scripts use safe internal paths from getAlignTruePaths() or __dirname
          "security/detect-non-literal-fs-filename": "off",
        },
      }
      ```

      **Use overrides for**:

      - Utility files where all paths are safe
      - Test files (if warnings are excessive)
      - Tooling scripts where all commands and paths are static/hardcoded
      - Files with many safe operations where inline suppressions would be noisy

      **Do NOT use overrides for**:

      - Scripts that accept command-line arguments
      - Scripts that dynamically construct commands or paths
      - Scripts that process user input

      ## Review process

      Before suppressing:

      1. Verify the code is actually safe (not just convenient to suppress)
      2. Check if validation/protection exists
      3. Document the rationale clearly
      4. Consider if a fix would be better (e.g., adding validation)
      5. For tooling scripts: Ensure commands and paths are static/hardcoded, not derived from user input

      ## Examples

      ### Good suppression

      ```typescript
      // eslint-disable-next-line security/detect-non-literal-fs-filename
      // Safe: Internal schema file path, resolved from __dirname at build time (not user input)
      const configSchema = JSON.parse(readFileSync(schemaPath, "utf8"));
      ```

      ### Bad suppression (missing validation)

      ```typescript
      // eslint-disable-next-line security/detect-non-literal-fs-filename
      // Safe: User provided path (WRONG - needs validation!)
      const content = readFileSync(userPath, "utf8");
      ```

      ### Good fix

      ```typescript
      // Validate user path first
      validateScopePath(userPath);
      const content = readFileSync(userPath, "utf8");
      ```

      ### Tooling script example (JavaScript)

      **Good suppression**:

      ```javascript
      // eslint-disable-next-line security/detect-child-process
      // Safe: execSync runs static known command, output parsed with static patterns only
      const output = execSync("pnpm lint --max-warnings 0", { encoding: "utf-8" });
      const lines = output.split("\n");
      ```

      **Bad suppression** (would need fixing):

      ```javascript
      // eslint-disable-next-line security/detect-child-process
      // Safe: executing user command (WRONG - needs validation!)
      const output = execSync(userCommand, { encoding: "utf-8" });
      ```

      **Correct approach**:

      ```javascript
      // Validate command against allowlist
      const ALLOWED_COMMANDS = ["lint", "test", "build"];
      if (!ALLOWED_COMMANDS.includes(userCommand)) {
        throw new Error(`Command not allowed: ${userCommand}`);
      }
      const output = execSync(`pnpm ${userCommand}`, { encoding: "utf-8" });
      ```

      ## GitHub CodeQL Alerts

      **Critical distinction**: CodeQL alerts are NOT suppressed with inline comments like ESLint. Use GitHub's security UI to dismiss false positives.

      ### Why lgtm comments don't work

      The `lgtm[rule]` format was used by the deprecated LGTM.com service. Modern GitHub CodeQL does not reliably honor these inline suppressions. Remove any `// lgtm[...]` comments to avoid confusion.

      ### How to dismiss false positive CodeQL alerts

      1. Go to https://github.com/AlignTrue/aligntrue/security/code-scanning
      2. Click the alert
      3. Select "Dismiss alert"
      4. Choose category:
         - **False positive**: Alert is incorrect or code is genuinely safe
         - **Won't fix**: Alert is valid but intentionally not addressed
      5. Add justification explaining:
         - Why the alert doesn't apply (validation, safe by construction, etc.)
         - Any safety measures in place

      ### Batch dismissal workflow

      When dismissing multiple related alerts:

      1. List alert numbers in ascending order (e.g., #366, #367, #368...) for easier tracking
      2. GitHub UI shows alerts newest-first by default; sort by "Alert number" ascending if dismissing many
      3. Use consistent justification text across related alerts for maintainability

      **Template justification for test fixture temp files:**

      > Test fixtures use isolated temp directories with crypto.randomBytes() for unpredictable paths and proper cleanup in afterEach(). Safe by construction per security_linting_policy.mdc.

      ### Documentation requirement

      When dismissing CodeQL alerts, the justification must explain the safety measure:

      **Good justification**:

      > Temp file uses same-directory pattern with crypto randomness (not OS temp dir). Atomic rename on same filesystem prevents TOCTOU. See packages/file-utils/src/atomic-writer.ts.

      **Poor justification**:

      > False positive

      ### Examples of safe patterns that trigger alerts

      | Alert                   | Safe Pattern                                         | Why                                                                        |
      | ----------------------- | ---------------------------------------------------- | -------------------------------------------------------------------------- |
      | insecure-temporary-file | Same-dir temp with crypto randomness + atomic rename | Atomic same-dir operations are always atomic across platforms              |
      | http-to-file-access     | Fetch validated URL → write to internal cache path   | URL validated at construction; cache path is internal `.aligntrue/.cache/` |
      | file-access-to-http     | Read file for HTTP headers (etag, etc.)              | Headers come from response object, not user input                          |

      ## Maintenance

      - Review suppressions during code reviews
      - Update suppressions if code changes
      - Remove suppressions if validation is added
      - Document new patterns as they arise
      - Remove `// lgtm[...]` comments when found (they're ineffective with GitHub CodeQL)
    level: 2
    fingerprint: security-linting-policy
    source_file: .aligntrue/rules/security_linting_policy.md
    vendor:
      aligntrue:
        frontmatter:
          description: Security linting policy for scripts and packages
          globs:
            - scripts/**/*.js
            - scripts/**/*.mjs
            - packages/**/*.ts
            - packages/**/*.tsx
            - apps/**/*.ts
            - apps/**/*.tsx
          content_hash: 92c4cfe00c8c351067b76178d6547e4cd14d60c5c79aa44cc22f4820a33f7b7b
          title: Security Linting Policy
  - heading: Test Log Template
    content: |

      # Test run template

      Use this template for documenting test runs.

      ## Test run {YYYY-MM-DD HH:MM}

      **Environment:**

      - Commit: {git commit hash}
      - Node: {node --version}
      - Platform: {darwin|linux|win32}
      - Test Type: {local|ci|manual}

      **Test Execution:**

      - Code Source: {local workspace|remote commit}
      - Environment: {hermetic|workspace}
      - Test Directory: {path to test dir}

      ---

      ## Findings

      ### Confirmed bugs

      #### [P0] {Bug Title}

      **Description:** {What's broken}

      **Root cause:** {Why it's broken}

      **Reproduction:**

      ```bash
      # Steps to reproduce
      ```

      **Fix:** {How to fix it}

      **Files affected:**

      - `{file path}`
      - `{file path}`

      ---

      #### [P1] {Bug Title}

      {Same structure as P0}

      ---

      ### Test execution issues

      #### {Issue Title}

      **What went wrong:** {Description of test setup/execution problem}

      **Impact:** {Did this invalidate test results?}

      **How to fix:** {For next test run}

      ---

      ### Coverage gaps

      #### {Gap Title}

      **What wasn't tested:** {Description}

      **Why:** {Reason - time, complexity, dependencies, etc.}

      **Plan:** {When/how to test this}

      ---

      ## Summary

      **Bugs found:** {count} ({P0 count} P0, {P1 count} P1, {P2 count} P2)

      **Tests passed:** {count}/{total}

      **Coverage:** {percentage or description}

      **Release readiness:** {Ready|Blocked|Needs work}

      **Blockers:**

      - {List any P0 bugs blocking release}

      **Next steps:**

      1. {Action item}
      2. {Action item}
      3. {Action item}
    level: 2
    fingerprint: test-log-template
    source_file: .aligntrue/rules/test_log_template.md
    vendor:
      aligntrue:
        frontmatter:
          description: Use this template for documenting test runs.
          content_hash: 4baf2c1d5f7be283a09f4390fe2a15f0978441fa60272d9115fe8c907f4d7394
          title: Test Log Template
  - heading: Testing
    content: >

      # Testing decision framework


      > Core principle: Tests must catch real bugs and enforce contracts, not
      add cruft.


      Use this when adding, editing, or deleting tests.


      ---


      ## External testing requirement (critical)


      ** NEVER TEST IN WORKSPACE ROOT **


      **All CLI testing must happen outside the workspace root and from isolated
      `/tmp/` directories.**


      ### Why


      - Detecting existing `.aligntrue/` can corrupt or halt tests

      - Running from root risks modifying the user's configuration

      - External directories force real-user workflows and keep git clean


      ### Where to test


      ```bash

      # CORRECT: isolate every run in /tmp/

      cd /tmp

      TEST_DIR="aligntrue-test-$(date +%s)"

      mkdir "$TEST_DIR" && cd "$TEST_DIR"

      # NOW you're in a clean test directory, safe to run CLI commands


      # Use absolute path to CLI binary (never pnpm link --global)

      /path/to/workspace/packages/cli/dist/index.js init --yes


      # WRONG: running from workspace root triggers safety guards and risks
      corruption

      cd /path/to/workspace

      aligntrue init  # this will detect existing .aligntrue/ and fail or
      corrupt

      ```


      ### Safety guards (automatic)


      All structured CLI testing runs include automatic safety checks that
      verify:


      - current directory is under `/tmp/`

      - TEST_WORKSPACE env var points to the isolated directory

      - ALIGNTRUE_CLI env var targets the built binary

      - LOG_FILE env var is set for outputs


      When safety checks fail, commands exit with a clear error before touching
      the workspace.


      ### Manual test scripts


      - Keep them in separate repos or temp directories

      - Always use `/tmp/` paths in documentation

      - Do not commit manual scripts to the repo

      - Reference patterns in `.internal_docs/external-cli-testing.md`


      ### Integration tests


      **Location:** `packages/*/tests/integration/`


      **Rules:**


      - Use `mkdtemp` from `os.tmpdir()` or create `/tmp/` fixtures

      - Clean up in `afterEach` or `finally`

      - No artifacts left in repo dirs

      - Never run integration suites from the workspace root; always operate
      inside temp dirs

      - Prefer absolute CLI binary paths instead of `pnpm link --global`


      ---


      ## Hybrid testing strategy (CLI)


      AlignTrue CLI uses a mix of integration, smoke, and contract tests.


      ### Integration tests


      - Real filesystem via temp dirs

      - Real `@aligntrue/*` imports

      - Verify actual outputs and side effects

      - Target: 80%+ coverage for core commands


      **Examples:**


      - `packages/cli/tests/integration/init-command.test.ts`

      - `packages/cli/tests/integration/sync-command.test.ts`

      - `packages/core/tests/`


      ### Smoke tests


      - Fast

      - 3 to 5 assertions per command

      - Check `--help`, argument parsing, basic wiring

      - Minimal mocking


      **Examples:**


      - `packages/cli/tests/commands/sync.test.ts`

      - `packages/cli/tests/commands/override-add.test.ts`


      ### Contract tests


      - Public APIs, schema, exporters, core invariants

      - Stable over refactors


      **Examples:**


      - `packages/schema/tests/canonicalize.test.ts`

      - `packages/exporters/tests/cursor.test.ts`

      - `packages/core/tests/sync/`


      ---


      ## Never mock internal packages (critical)


      Do not mock `@aligntrue/*` in our tests.


      ### Allowed mocks


      - External services

      - `process.exit`

      - Time or randomness for determinism

      - UI prompts


      ### Delete tests that


      - Mock `@aligntrue/core`, `@aligntrue/schema`, etc

      - Duplicate integration coverage

      - Only assert calls on mocks


      If removing the test would not increase real bug risk, remove it.


      ---


      ## Data flow and what to test


      ### Authoritative flow


      ```

      Source: .aligntrue/rules/*.md (user-editable, canonical)
        → IR: in-memory representation (internal, never written to disk)
        → Agent exports: .cursor/*.mdc, AGENTS.md, etc (read-only, generated)
      ```


      ### Rules


      - Test through public surfaces and exports

      - Do not assert internal IR layout unless it is a documented contract

      - Agent files are read-only exports; `.aligntrue/rules/*.md` is the source
      of truth

      - Sync overwriting agent files is expected behavior


      ---


      ## 5 question test filter


      Apply in order:


      1. **Has this broken in CI or real usage?**  
         Yes → write a regression test.  
         No → go to 2.

      2. **Does it assert a clear boundary or contract?**  
         Yes → keep or add as contract test.  
         No → go to 3.

      3. **Does it duplicate coverage?**  
         Yes → delete or merge.  
         No → go to 4.

      4. **Does it test implementation details?**  
         Yes → rewrite against observable behavior or delete.  
         No → go to 5.

      5. **Is it just for coverage percentage?**  
         Yes → delete.  
         No → keep.

      ### Golden rule


      If deleting the test does not measurably increase risk of real
      regressions, delete it.


      ---


      ## What to keep


      1. **Integration tests**
         - Real workflow, temp dirs, no internal mocks

      2. **Contract tests**
         - Public APIs
         - Schema behavior
         - Deterministic outputs

      3. **Smoke tests**
         - Fast checks for each command

      4. **Critical regression tests**
         - One small test per real bug

      5. **Performance guards**
         - Loose thresholds to catch major regressions

      ---


      ## What to avoid or delete


      ### Delete


      - Import only tests

      - Coverage shims

      - Pure implementation detail tests

      - Duplicates of stronger integration or contract tests

      - Tests that rely on heavy internal mocking


      ### Be cautious with


      - **Parameterized tests:**
        - Cap at 10 cases
        - Only when they clarify a real contract
      - **Edge cases:**
        - Add only for realistic or observed issues

      ---


      ## Test organization


      ### Structure per package


      Each package maintains its own `tests/` directory with subfolders that
      align with the package's surface area. For example, `packages/cli/tests/`
      currently looks like:


      ```

      packages/cli/tests/
        check-empty-yaml.test.ts  # YAML validation tests
        commands/                 # CLI command smoke and unit tests
        comprehensive/            # Charter layers and command coverage helpers
        COVERAGE.md               # Test coverage documentation
        drift.test.ts             # Drift detection tests
        e2e/                      # End-to-end workflow tests
          sync-workflow.test.ts
        fixtures/                 # Static files consumed by tests
        helpers/                  # Reusable fixtures and utilities
        integration/              # Real workflows and git-backed scenarios
        scripts/                  # Shell helpers for local runs
        TESTING.md                # Testing documentation
        tmp/                      # Temporary test outputs (gitignored)
        unit/                     # Focused parsing/unit tests
        utils/                    # Supporting utilities and their tests
        version-sync.test.ts      # Version sync tests
      ```


      Other packages follow the same principle (`packages/core/tests/`,
      `packages/exporters/tests/`, `packages/schema/tests/`, etc.), so new
      packages should adopt a similar layout that reflects their needs.


      Per package, mirror `src/` paths when it keeps tests close to the code
      they exercise.


      ---


      ## Temporary file rules (critical)


      All AI or test-generated artifacts in repo must use the `temp-` prefix.


      ### Allowed


      - `temp-test-output.md`

      - `temp-bundle.yaml`

      - `temp-config.yaml`

      - `temp-test-project/`


      ### Forbidden in repo root or packages


      - `test_*.md`, `test-*.yaml`

      - `audit*.html`

      - `*_config.yaml` without `temp-`

      - Generic `audit.*` or `report.*` outside `artifacts/`


      ### Testing artifacts handled automatically


      - Test directories (e.g., `/tmp/aligntrue-*`) are cleaned automatically:
      keep the last 3 runs or directories newer than 24 hours.

      - Package tarballs in `packages/cli/aligntrue-cli-*.tgz` are removed after
      Layer 1 runs.

      - Cleanup executes before and after comprehensive test suites.

      - Cleanup script for manual or bulk cleanup:
        ```bash
        pnpm cleanup:temps       # Delete all orphaned test directories
        pnpm cleanup:temps:dry   # Preview what would be deleted (with sizes)
        ```
      - Direct manual cleanup (if script unavailable):
        ```bash
        rm -rf /tmp/aligntrue-* /tmp/test-* /tmp/ruler-* /tmp/solo-test* /tmp/team-*
        find packages/cli -name "aligntrue-cli-*.tgz" -exec rm {} \;
        ```

      ### Permanent names only in


      - `examples/`

      - `artifacts/`

      - `docs/`


      ### Optional scratch


      ```

      .ai-scratch/
        temp-*.*
      ```


      ---


      ## Local workflow


      ### Pre commit


      - Format and lint staged files

      - Fast


      ### Pre push


      - Typecheck

      - Tests

      - Build (where configured)


      Bypass only when hooks are broken, not to skip validation.


      ## AI testing constraints (critical)


      When AI agents perform CLI testing:


      ### AI must always


      - Create isolated `/tmp/aligntrue-test-{timestamp}` directories before
      running commands

      - Change into that directory before invoking the CLI

      - Use the absolute CLI binary path:
      `/path/to/workspace/packages/cli/dist/index.js`

      - Set `TZ=UTC` and `NODE_ENV=test`

      - Capture stdout, stderr, exit codes, and execution time

      - Record findings with severity (P0-P3)

      - Clean up the test environment once done


      ### AI must never


      - Modify source files outside the hermetic test directory

      - Attempt to fix or implement code changes

      - Run CLI commands from the workspace root

      - Use `pnpm link --global` (fails with workspace:\* refs)

      - Leave artifacts in the workspace (temp dirs only)


      ### Cleanup after exploratory testing


      After any exploratory or manual testing session, AI agents must:


      1. **Clean up test directories** created during the session:

         ```bash
         rm -rf /tmp/aligntrue-*  # Remove all AlignTrue test dirs
         rm -rf /tmp/test-*       # Remove common test dirs
         ```

      2. **Or use the cleanup script**:

         ```bash
         pnpm cleanup:temps       # Delete all orphaned test directories
         pnpm cleanup:temps:dry   # Preview what would be deleted (verbose)
         ```

      3. **Verify cleanup** before ending the session:
         ```bash
         ls /tmp | grep -E '^(aligntrue-|test-|ruler-|solo-test|team-)'
         # Should return empty or only very recent directories
         ```

      Automated tests clean up via `afterEach` hooks, but interrupted tests and
      manual sessions often leave orphans. The cleanup script matches these
      patterns:


      - `aligntrue-*` (all test/backup/perf directories)

      - `test-*` (exploratory testing)

      - `ruler-*`, `solo-test*`, `team-*` (specific test types)

      - `exploratory-*`, `split-test*` (manual testing)


      ### Safety verification


      Structured tests now assert:


      - Current directory is under `/tmp/`

      - TEST_WORKSPACE env var points to the temp directory

      - ALIGNTRUE_CLI env var targets the built CLI

      - LOG_FILE env var is set for capturing logs


      ---


      ## Handling core format or path changes


      When changing core formats or paths:


      1. **Search affected tests:**


      ```bash

      grep -r "old-path-or-pattern" packages/*/tests/

      ```


      2. **Update:**
         - File paths
         - Expectations
         - Config references

      3. **Run targeted and full suites:**


      ```bash

      pnpm --filter @aligntrue/cli test

      pnpm test

      ```


      Same PR must update tests. No "fix tests later."


      ---


      ## Test coverage strategy


      Design a tight red green path covering:


      - **Determinism:** fixed seeds, stable sort, byte identical exports where
      relevant

      - **Boundaries:** missing files, invalid schema, corrupt data, wrong types

      - **Integration:** config loading, bundling, exporters, MCP server, CLI
      wiring

      - **Performance sanity:** fast unit tests by default, heavy paths behind
      marks


      ---


      ## TDD workflow


      Use TDD for new deterministic features.


      1. Write contract tests first

      2. Keep fixtures minimal and local

      3. Use temp dirs and helpers

      4. Implement only what tests require

      5. Run with `TZ=UTC` for everything


      ### Standard


      ```bash

      TZ=UTC pnpm test --silent

      TZ=UTC pnpm --filter @aligntrue/cli vitest run <file> -t "<name>"

      ```


      ---


      ## Determinism checklist (for tests and code)


      - `TZ=UTC` for CI

      - No raw `Date.now()` or `Math.random()` in deterministic paths

      - Stable sort for set like arrays

      - Newlines normalized to `\n`

      - Use shared canonicalization helpers where applicable


      ---


      ## CI quality gates


      CI should enforce:


      - Lint clean

      - `tsc --noEmit` clean

      - Tests green

      - No lingering `test.skip` or `test.todo` for shipped features


      ---


      ## Related rules


      - `debugging.md` for systematic debugging

      - `implementation_specs.md` for determinism rules and IR data flow

      - `security_linting_policy.md` for security linting policy
    level: 2
    fingerprint: testing
    source_file: .aligntrue/rules/testing.md
    vendor:
      aligntrue:
        frontmatter:
          description: Testing decision framework and quality guidelines
          content_hash: 731e477609804ea24d7d02d56edf7491bca3e7d0220e3d9a5fc25e98abd60d05
          title: Testing
  - heading: Typescript
    content: |

      # TypeScript development guide

      TypeScript rules for correctness, determinism, and AI friendly maintenance. For tests, see `testing.mdc`. For determinism details, see `implementation_specs.mdc`.

      ---

      ## Core principles

      1. Types first, then implementation.
      2. No `any` creep.
      3. Narrow at boundaries, stay precise inside.
      4. Prefer simple data + pure functions over classes.
      5. Fail fast with clear errors.

      ---

      ## tsconfig baseline (required)

      Every project extends a strict shared config. Do not turn strictness off.

      ```json
      {
        "compilerOptions": {
          "target": "ES2022",
          "module": "ES2022",
          "moduleResolution": "bundler",
          "jsx": "react-jsx",
          "strict": true,
          "noUncheckedIndexedAccess": true,
          "exactOptionalPropertyTypes": true,
          "noImplicitOverride": true,
          "noPropertyAccessFromIndexSignature": true,
          "noFallthroughCasesInSwitch": true,
          "forceConsistentCasingInFileNames": true,
          "useUnknownInCatchVariables": true,
          "allowUnusedLabels": false,
          "importsNotUsedAsValues": "error",
          "resolveJsonModule": true,
          "skipLibCheck": true
        }
      }
      ```

      If a third party library is wrong, use `// @ts-expect-error <short reason>` on that line only.

      ---

      ## Linting and formatting

      - Use `@typescript-eslint` with type aware config.
      - Enforce:
        - `no-explicit-any`
        - `no-floating-promises`
        - `no-unsafe-argument`
        - `consistent-type-imports`
        - `no-unnecessary-type-assertion`
      - Prefer Prettier as the single formatter.
      - CI must run lint with type checking.

      ### Minimal eslint config

      ```json
      {
        "extends": [
          "plugin:@typescript-eslint/recommended-type-checked",
          "plugin:@typescript-eslint/stylistic-type-checked"
        ],
        "parserOptions": { "project": true },
        "rules": {
          "@typescript-eslint/consistent-type-imports": [
            "error",
            { "prefer": "type-imports" }
          ],
          "@typescript-eslint/no-explicit-any": "error",
          "@typescript-eslint/no-floating-promises": "error",
          "@typescript-eslint/no-unsafe-argument": "error",
          "@typescript-eslint/no-unnecessary-type-assertion": "error",
          "@typescript-eslint/require-await": "error",
          "no-restricted-syntax": [
            "error",
            {
              "selector": "TSEnumDeclaration",
              "message": "Use unions of string literals instead of enums"
            }
          ]
        }
      }
      ```

      ---

      ## Module and API boundaries

      - Only named exports. No default exports.
      - Barrel files only at package boundaries. Avoid deep barrels.
      - Public APIs are small and explicit.
      - Internals use relative imports within the package.
      - Use `import type` for types.

      ```typescript
      import type { User } from "./types";
      ```

      ---

      ## exactOptionalPropertyTypes pattern

      Optional means "present with value" or "not present". Never assign `undefined` directly.

      ```typescript
      interface Result {
        data: string;
        error?: string;
        metadata?: Record<string, unknown>;
      }

      // Good: omit when undefined
      const error: string | undefined = getError();
      const metadata: Record<string, unknown> | undefined = getMetadata();

      const result: Result = {
        data: "success",
        ...(error !== undefined && { error }),
        ...(metadata !== undefined && { metadata }),
      };
      ```

      Pattern: `...(value !== undefined && { key: value })` for optional fields.

      ---

      ## noUncheckedIndexedAccess pattern

      All indexed access is `T | undefined`. Narrow before use.

      ```typescript
      const mapping: Record<string, string> = {
        "import-cursor": "cursor",
        "import-agents": "agents",
      };

      const agent = mapping[context];
      if (!agent) {
        throw new Error(`Unknown context: ${context}`);
      }
      useAgent(agent);
      ```

      Use `if (!value)`, `??`, or validation helpers instead of assuming presence.

      ---

      ## Boundary validation

      At all external boundaries (CLI args, env, HTTP, files):

      - Accept `unknown`.
      - Validate with a schema library (Zod or equivalent).
      - Throw small, actionable errors.

      ```typescript
      import { z } from "zod";

      const UserSchema = z.object({
        id: z.string().uuid(),
        email: z.string().email(),
        roles: z.array(z.enum(["admin", "member"])).default([]),
      });

      export type User = z.infer<typeof UserSchema>;

      export function parseUser(input: unknown): User {
        const res = UserSchema.safeParse(input);
        if (!res.success) {
          const msg = res.error.issues
            .map((i) => `${i.path.join(".")}: ${i.message}`)
            .join("; ");
          throw new Error(`Invalid user: ${msg}`);
        }
        return res.data;
      }
      ```

      Never trust raw JSON, env, or config without validation.

      ---

      ## Prefer data + functions over classes

      - Use plain objects and functions.
      - Use discriminated unions for states.

      ```typescript
      type Loading = { kind: "loading" };
      type Success<T> = { kind: "success"; data: T };
      type Failure = { kind: "failure"; error: string };
      type RemoteData<T> = Loading | Success<T> | Failure;

      export function fold<T, R>(
        rd: RemoteData<T>,
        fns: {
          loading: () => R;
          success: (t: T) => R;
          failure: (e: string) => R;
        },
      ): R {
        switch (rd.kind) {
          case "loading":
            return fns.loading();
          case "success":
            return fns.success(rd.data);
          case "failure":
            return fns.failure(rd.error);
          default:
            return assertNever(rd);
        }
      }

      function assertNever(x: never): never {
        throw new Error(`Unhandled case: ${JSON.stringify(x)}`);
      }
      ```

      ---

      ## Exhaustiveness and narrowing

      - Always exhaust unions.
      - Use `assertNever` in default to force compiler checks.

      ```typescript
      type Shape =
        | { tag: "circle"; radius: number }
        | { tag: "rect"; w: number; h: number };

      export function area(s: Shape): number {
        switch (s.tag) {
          case "circle":
            return Math.PI * s.radius * s.radius;
          case "rect":
            return s.w * s.h;
          default:
            return assertNever(s);
        }
      }
      ```

      ---

      ## Unknown over any

      - Use `unknown`.
      - Narrow with `typeof`, `in`, or schema parse before use.

      ```typescript
      function parseJson(input: string): unknown {
        return JSON.parse(input);
      }
      ```

      ---

      ## Prefer unions over enums

      ```typescript
      export const Roles = ["admin", "member", "viewer"] as const;
      export type Role = (typeof Roles)[number];
      ```

      ---

      ## Immutability defaults

      - Prefer `Readonly` and `ReadonlyArray` at edges.
      - Mutate only when needed and local.

      ```typescript
      type Point = Readonly<{ x: number; y: number }>;
      const points: ReadonlyArray<Point> = [{ x: 0, y: 0 }];
      ```

      ---

      ## File operations and safety

      Avoid TOCTOU (time-of-check to time-of-use) race conditions. ESLint rule `no-check-then-operate` flags these patterns.

      ### Safe patterns

      | Operation  | Pattern                                                                   | Reason                            |
      | ---------- | ------------------------------------------------------------------------- | --------------------------------- |
      | Read       | `readFileSync(path)`                                                      | Safe - no check needed            |
      | Create dir | `ensureDirectoryExists(dir)`                                              | Atomic, handles concurrent access |
      | Write      | `new AtomicFileWriter().write(path, content)`                             | Atomic, no intermediate state     |
      | Delete     | `try { unlinkSync(path); } catch (e) { if (e.code !== "ENOENT") throw; }` | Handle file already gone          |

      ### Unsafe patterns (avoid)

      ```typescript
      // ❌ TOCTOU: file could be deleted between check and write
      if (!existsSync(file)) {
        writeFileSync(file, content);
      }

      // ❌ TOCTOU: directory could be created between check and mkdir
      if (!existsSync(dir)) {
        mkdirSync(dir);
      }

      // ✅ Instead use:
      import { ensureDirectoryExists, AtomicFileWriter } from "@aligntrue/file-utils";
      ensureDirectoryExists(dir);
      const writer = new AtomicFileWriter();
      await writer.write(file, content);
      ```

      Use `ensureDirectoryExists()` and `AtomicFileWriter` from `@aligntrue/file-utils` for all production code.

      ---

      ## Error handling

      - Throw `Error`, not strings.
      - For expected failures, use Result style types.

      ```typescript
      type Ok<T> = { ok: true; value: T };
      type Err<E = Error> = { ok: false; error: E };
      export type Result<T, E = Error> = Ok<T> | Err<E>;

      export function toErr(e: unknown): Error {
        return e instanceof Error ? e : new Error(String(e));
      }
      ```

      ---

      ## Async discipline

      - No unhandled promises.
      - Use `no-floating-promises` in lint.
      - Fire and forget only with explicit `void` and containment.

      ```typescript
      void runBackground().catch((err) => {
        console.error("Background task failed", err);
      });
      ```

      ---

      ## API and component typing

      - All exported functions and components are typed.
      - Use `satisfies` to keep config narrow.

      ```typescript
      type Config = { region: "iad" | "dub"; retries: number };

      export const config = {
        region: "iad",
        retries: 2,
      } as const satisfies Config;
      ```

      ---

      ## Naming and structure

      - Files: kebab case.
      - React components: PascalCase.
      - Functions and vars: camelCase.
      - One module per concern.
      - Tests mirror source tree.
      - Prefer clear function/variable names over inline comments

      ```
      src/
        core/
        features/
        components/
        types/
      tests/
        core/
        features/
        components/
      ```

      ---

      ## Pitfalls to avoid

      - Default exports.
      - `as any` to silence errors.
      - Optional booleans. Prefer unions like `type Flag = "on" | "off"`.
      - `{}` or `object` as catch all types.
      - Wildcard barrels that hide dependencies.
      - Over generic abstractions without need.
      - Types derived from runtime data without validation.
      - Don't unnecessarily add try / catch
      - Don't cast to 'any
      - Avoid helper functions when a simple inline expression would suffice

      ---

      ## Pre commit checklist

      ```bash
      tsc -p tsconfig.json --noEmit
      pnpm exec eslint . --max-warnings=0
      pnpm exec prettier -w .
      ```

      For large refactors, run `pnpm exec knip` to find and remove unused exports, dependencies, and files.

      ---

      ## Related rules

      - `testing.mdc`
      - `security_linting_policy.mdc`
      - `implementation_specs.mdc`
      - `pull_request_standards.mdc`
    level: 2
    fingerprint: typescript
    source_file: .aligntrue/rules/typescript.md
    vendor:
      aligntrue:
        frontmatter:
          description: TypeScript standards for safe deterministic code
          globs:
            - "**/*.{ts,tsx}"
            - tsconfig*.json
            - .eslintrc*
            - eslint.config.*
            - biome.*
          content_hash: 6a9bf8db68a93de7e0d7c6a6365978bc4b45b0b2ec0ed63c0b9b056e85ab822e
          title: Typescript
  - heading: Vision Strategy Roadmap
    content: |

      # AlignTrue — Vision and Strategy Roadmap

      **Last updated:** Nov 30, 2025

      ---

      ## Vision

      AlignTrue is the alignment control plane. One shared, versioned rule layer that keeps AI agents, developers, product managers, and leadership operating from the same priorities. Drift becomes a signal that improves the rules. The system meets people where they work and quietly keeps everything in sync.

      **One line:** Source of truth for how you want work done, wired into every agent and workflow.

      ---

      ## North Star and 60-Second Wow

      **Promise**

      Align rules across agents in 60 seconds & your team in 5 minutes.

      **Quick demo**

      ```bash
      npx aligntrue init    # Auto-detects agents, creates AGENTS.md
      aligntrue sync        # Exports to all detected agents
      ```

      **Result**

      - Rules synced to all your agents (Cursor, Copilot, Claude, VS Code MCP, etc.)
      - Edit AGENTS.md or any agent file; sync keeps them in sync
      - Team mode available: lockfiles, drift detection, CI validation

      ---

      ## Positioning

      - **Category:** AI and org alignment control plane
      - **Starting wedge:** OSS CLI that syncs rules across agents and repos
      - **Core mechanic:** Scopes and storage policies on rules, plus unidirectional sync
      - **Signature move:** Treat drift as a signal, not a crime
      - **Promise:** Clarity in a week, compounding alignment over time

      ---

      ## First Principles

      1. Clarity beats clever. Rules must be explicit, testable, and versioned.
      2. Determinism by default. Canonicalization and hashing to remove ambiguity.
      3. Unidirectional sync keeps truth in one place. Edit in `.aligntrue/rules/`, sync flows to all agents.
      4. Drift is data. Use it to update rules or fix behavior.
      5. Meet people where they work. IDEs, Linear, Slack, Docs, not a new inbox.
      6. Privacy first. Scopes and storage policies prevent leaks.

      ---

      ## Product Thesis

      AI only helps when guidance is clear. Writing rules forces priorities and tradeoffs to be explicit. That clarity aligns humans and agents and removes most friction. Start with developers because they feel the pain today. Use that wedge to bring PMs, then leadership, then the whole org.

      ---

      ## Technical Invariants

      - **IR spec:** YAML with sections[] that each have heading, body, scope in {team, personal}, storage in {local, repo, remote:<name>, cloud}, id.
      - **Canonical form:** JCS style JSON plus SHA-256 of normalized content for stable IDs.
      - **Scope wins over heuristics:** Once a section has a scope, it cannot be auto re scoped by headings.
      - **Sync rules:** IR is complete. Exports filter by scope and storage. Lockfile contains team scope only.
      - **Safety:** In team mode, no personal with storage repo in shared repos.
      - **Status checks:** aligntrue status and aligntrue doctor show where rules live and if anything leaks.

      ---

      ## Roadmap Overview

      | Phase | Name              | Goal                                       | Key Outputs                                                                                               | Gate Metrics                                                               |
      | ----- | ----------------- | ------------------------------------------ | --------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
      | 0     | OSS Default       | Become the obvious CLI for agent rule sync | IR v1, scope and storage, unidirectional sync, 25+ exporters, detectors, lockfile, status, doctor, aligns | 5k GitHub stars, 1k weekly active repos, 50% success rate on status checks |
      | 1     | Teams             | Multiplayer and governance                 | Team mode, policy inheritance, allow list, CI checks, PR annotations, audit log                           | 200 paying teams, NRR 120, CI adoption 70 percent of repos using checks    |
      | 2     | PM Bridge         | Turn PM vision into dev reality            | Linear and Jira integration, rule to backlog mapping, priority guardrails, PRD and doc checks             | 1k PM weekly users, 30 percent of merged PRs linked to rules               |
      | 3     | Org Control Plane | Central source of truth in cloud           | Workspaces, SSO, SCIM, data residency, drift dashboard, Slack and Docs add ons, scheduled scans           | 200 enterprise trials, 50 enterprise wins, NRR 130                         |
      | 4     | Platform          | Make it a standard                         | Rule align marketplace, compliance aligns, hiring signal, analytics API                                   | 10k orgs using aligns, 20 percent revenue from add ons                     |
      | 5     | Civic Pilot       | Prove it beyond companies                  | Public rule spaces, candidate rule sets, citizen feedback flows                                           | 3 pilots with credible NGOs or municipalities                              |

      ---

      ## Phase 0 — OSS Default

      **Objective:** Become the default way developers sync rules across agents.

      ### Milestones

      - IR v1 with scope and storage
      - Unidirectional sync to AGENTS.md, CLAUDE.md, .mdc
      - Lockfile and allow list with team scope only
      - status, doctor, diff, check --sarif
      - 50+ exporters and detectors with golden tests
      - Aligns for common stacks

      ### 80/20 Focus

      - Nail stability of unidirectional sync and section IDs
      - Status and doctor UX that explains exactly what will happen before it happens
      - Exporter coverage for Cursor, Claude, Gemini, VS Code, AGENTS.md, MCP configs

      ### Risks

      - Perceived as a thin sync tool
      - Exporters flaky

      ### Mitigation

      - Deterministic tests, snapshots, and public CI
      - Clear spec docs, short recipes, and quick wins

      ---

      ## Phase 1 — Teams

      **Objective:** Multiplayer alignment in repos and CI.

      ### Milestones

      - Team mode with policy inheritance and exceptions
      - CI checks with PR comments and required status
      - Audit log, provenance, and signed lockfiles
      - aligntrue approve workflow with CODEOWNERS

      ### 80/20 Focus

      - CI checks that catch real drift and produce helpful fixes
      - Simple inheritance model that people grasp in one read

      ### Risks

      - Change management friction

      ### Mitigation

      - Zero config path, clear diff output, short video demos

      ---

      ## Phase 2 — PM Bridge

      **Objective:** Let PMs encode vision, priorities, and tradeoffs that drive the backlog.

      ### Milestones

      - Linear and Jira connectors
      - Rules to backlog mapping and guardrails
      - Doc and PRD checkers
      - Drift signals sent to PMs when teams diverge or when rules go stale

      ### 80/20 Focus

      - One view where a PM can see priorities and active work linked to rules
      - A single killer guardrail that prevents common misalignment

      ### Risks

      - PMs see it as yet another tool

      ### Mitigation

      - Live inside Linear and Jira, not next to them

      ---

      ## Phase 3 — Org Control Plane

      **Objective:** Cloud source of truth and cross tool checks.

      ### Milestones

      - Workspaces, SSO, SCIM
      - Data residency and customer keys
      - Slack slash commands and listeners
      - Google Docs and Office add ons
      - Drift dashboard and rule health scores

      ### 80/20 Focus

      - Slack and Docs checks that feel like magic and do not nag
      - Drift insights that explain the why, not just the what

      ### Risks

      - Overreach on scanning and privacy concerns

      ### Mitigation

      - Opt in scopes, transparent logs, privacy by design

      ---

      ## Phase 4 — Platform

      **Objective:** Become the standard alignment layer.

      ### Milestones

      - Align marketplace and verified aligns
      - Compliance and industry aligns
      - Hiring signal and public rule profiles
      - Analytics API and partner ecosystem

      ### 80/20 Focus

      - High quality official aligns that save months of work
      - Two or three anchor partnerships

      ---

      ## Phase 5 — Civic Pilot

      **Objective:** Validate the model in public interest settings.

      ### Milestones

      - Candidate and policy rule sets
      - Drift feedback from citizens
      - Moderation and transparency features

      ### Guardrails

      - Non partisan posture and strict transparency

      ---

      ## Go To Market

      - **Bottom up:** OSS first, templates, quick wins, community
      - **Product led:** Free to try, checks that prove value in a week
      - **Lightweight sales:** Land teams through CI checks, expand to PMs and org
      - **Enterprise:** Control plane features, security reviews, data residency

      ### Pricing Spine

      | Tier     | For         | Price                                  | Key Value                           |
      | -------- | ----------- | -------------------------------------- | ----------------------------------- |
      | Free OSS | Individuals | Free                                   | Rule sync and core exporters        |
      | Pro      | Teams       | 6 to 12 per user per month             | CI checks, team mode, inheritance   |
      | Platform | Orgs        | 150 to 300 per user per year plus base | SSO, SCIM, drift dashboard, add ons |

      ---

      ## Metrics That Matter

      - Weekly active rule checks per repo or seat
      - Percent of PRs linked to rules
      - Drift resolved within target days
      - PM adoption and depth across teams
      - NRR and team to org expansion rate

      ---

      ## Brutal Analysis

      ### Strengths

      - Starts with a painful, concrete dev problem and ships a fast win
      - Clear path from local rules to org alignment without changing story
      - Drift as signal is a unique, compounding insight

      ### Weak Spots

      - Incumbents can bolt on rule sync to their surfaces
      - Change management is hard if value is not obvious in week one
      - Risk of being seen as policy or OKR tooling

      ### How to De-Risk

      - Be the best in class at unidirectional sync and exporter coverage
      - Make CI checks and Slack checks obviously useful on day one
      - Speak in outcomes, not governance. Ship recipes that save time

      ---

      ## 80/20 per Phase

      - **Phase 0:** Unidirectional sync that never loses a section. Best in class status and doctor. Exporter coverage for the top agents and IDEs.
      - **Phase 1:** CI checks that prevent real mistakes and are easy to approve. Inheritance that is simple and predictable.
      - **Phase 2:** Linear and Jira flows that help PMs steer a sprint with one view and one guardrail. No new inbox.
      - **Phase 3:** Slack and Docs checks that feel native. Drift dashboard that shows why and what to change.
      - **Phase 4:** A small set of official rule aligns that set the standard. A few deep partners.
      - **Phase 5:** One credible civic pilot with clear transparency.

      ---

      ## Validation Plan and Kill Switches

      - **Phase 0 gates:** If unidirectional sync stability or exporter quality stays below target after three iterations, cut long tail exporters and refocus on top five.
      - **Phase 1 gates:** If CI checks do not drive adoption, simplify checks and raise signal quality before adding features.
      - **Phase 2 gates:** If PM attach is weak, add one killer guardrail that saves a sprint. Do not build dashboards until attach is real.
      - **Phase 3 gates:** If privacy pushback rises, pivot to on prem and private indexing for checks.

      ---

      ## Naming and Messaging Options

      - Alignment control plane
      - Rules backbone for AI and orgs
      - Source of truth for how you want work done

      ---

      ## What Would Change My Mind

      - If incumbents ship true unidirectional sync across agents and tools and win usage fast
      - If PM attach does not materialize after strong integrations
      - If teams resist writing rules even with clear wins

      ---

      ## Immediate Next Steps

      1. Lock IR v1 with scope and storage
      2. Finish unidirectional sync with stable IDs and conflict rules
      3. Ship status, doctor, and CI check with helpful diffs
      4. Add Linear integration with one guardrail and one view
      5. Publish three high quality aligns with tests
    level: 2
    fingerprint: vision-strategy-roadmap
    source_file: .aligntrue/rules/vision_strategy_roadmap.md
    vendor:
      aligntrue:
        frontmatter:
          description: AlignTrue vision and strategy roadmap
          enabled: false
          gitignore: true
          scope: personal
          content_hash: 8dd672a7ea4f36d7a4b6cfa4717e9d7cc16598f3675c68da7946e775606ca23f
          title: Vision Strategy Roadmap
    scope: personal
  - heading: Web Stack Nextra Docs
    content: >

      # Web stack guide


      **Applies to:** `apps/docs/` documentation site only


      Guide for the Nextra-based AlignTrue docs site: App Router, MDX content,
      `@aligntrue/ui`, and Vercel deployment. Keep it simple, fast, and boring.


      ---


      ## Core principles


      1. Use Nextra defaults with minimal custom code.

      2. Author content in MDX under `apps/docs/content/`.

      3. Use Nextra built-in components where possible.

      4. Deploy a single docs site to Vercel at the main domain.

      5. Share branding via `@aligntrue/ui`.

      6. Prefer changes that stay compatible with Nextra minor upgrades.


      ---


      ## Performance and best practices


      - Prefer fetching data in RSC (page can still be static)

      - Use next/font and next/script when applicable

      - next/image above the fold should use `loading="eager"` or `priority`
      sparingly

      - Be mindful of serialized prop size for RSC to child components


      ---


      ## Nextra 4.6 App Router setup (critical)


      AlignTrue uses Nextra `nextra-theme-docs` with Next.js App Router.


      ### Theme config


      `apps/docs/theme.config.tsx` defines the Nextra theme. Nextra auto-loads
      this. Do not wire it through `next.config.mjs`.


      ```tsx

      // apps/docs/theme.config.tsx

      import { AlignTrueLogo } from "@aligntrue/ui";


      const config = {
        logo: <AlignTrueLogo size="md" />,
        project: {
          link: "https://github.com/AlignTrue/aligntrue",
        },
        docsRepositoryBase:
          "https://github.com/AlignTrue/aligntrue/tree/main/apps/docs",
        toc: {
          backToTop: true,
        },
      };


      export default config;

      ```


      Keep theme config minimal. Complex behavior is handled in the docs layout
      instead.


      ### Next.js config


      Use Nextra plugin. Do not set theme or themeConfig here. Those are Pages
      Router only.


      ```javascript

      // apps/docs/next.config.mjs

      import nextra from "nextra";


      const withNextra = nextra({
        latex: true,
        search: {
          codeblocks: false,
        },
        defaultShowCopyCode: true,
      });


      export default withNextra({
        output: "export",
        reactStrictMode: true,
        transpilePackages: ["@aligntrue/ui"],
      });

      ```


      ### App Router layout


      Nextra wires most behavior automatically. Use App Router layouts and
      import Nextra styles in the docs layout only.


      **Root layout** (`app/layout.tsx`): Setup SEO, analytics, theming
      providers. Do NOT import Nextra styles here.


      ```tsx

      // apps/docs/app/layout.tsx (root layout does NOT import Nextra styles)

      import type { ReactNode } from "react";

      import type { Metadata } from "next";

      import { Head } from "nextra/components";

      import { ThemeProvider } from "next-themes";

      import { Analytics } from "@vercel/analytics/react";


      export const metadata: Metadata = {
        title: { default: "AlignTrue", template: "%s – AlignTrue" },
        description:
          "Instantly sync rules across agents, people, projects and teams.",
        // ... additional metadata for SEO, OpenGraph, Twitter
      };


      export default function RootLayout({ children }: { children: ReactNode })
      {
        return (
          <html lang="en" suppressHydrationWarning>
            <Head>{/* Analytics and global scripts here */}</Head>
            <body>
              <ThemeProvider attribute="class" defaultTheme="system" enableSystem>
                {children}
                <Analytics />
              </ThemeProvider>
            </body>
          </html>
        );
      }

      ```


      **Docs layout** (`app/docs/layout.tsx`): Import Nextra styles and wire
      theme components.


      ```tsx

      // apps/docs/app/docs/layout.tsx (docs layout imports Nextra styles)

      import "nextra-theme-docs/style.css";

      import type { ReactNode } from "react";

      import { Layout, Navbar } from "nextra-theme-docs";

      import { Search } from "nextra/components";

      import { getPageMap } from "nextra/page-map";

      import themeConfig from "../../theme.config";


      export default async function DocsLayout({
        children,
      }: {
        children: ReactNode;
      }) {
        const pageMap = await getPageMap();
        return (
          <Layout
            pageMap={pageMap}
            navbar={
              <Navbar
                logo={themeConfig.logo}
                projectLink={themeConfig.project.link}
              />
            }
            search={<Search placeholder="Search documentation..." />}
            footer={<DocsFooter />}
            sidebar={{ defaultMenuCollapseLevel: 1, autoCollapse: true }}
          >
            {children}
          </Layout>
        );
      }

      ```


      For nested docs layout, use Nextra primitives instead of forking theme
      config. Wrap, do not reimplement.


      ### Do not


      - Add theme or themeConfig to `nextra()` options.

      - Pass a themeConfig prop into `<Layout>`.

      - Use legacy `createAlignTrueNextraTheme()` helpers.


      If a feature is not in Nextra docs, prefer upgrading Nextra or opening an
      upstream issue.


      ---


      ## Nextra layout and content


      ### Directory structure


      ```

      apps/docs/
        app/
          layout.tsx                  # Root layout (SEO, analytics, theme provider)
          page.tsx                    # Home page
          docs/
            layout.tsx                # Docs layout (Nextra Layout, styles)
            [[...mdxPath]]/page.tsx   # Dynamic route for all docs pages
        content/
          _meta.js                    # Navigation config
          index.mdx                   # Docs landing
          about.md                    # About page
          00-getting-started/
          01-guides/
          02-customization/
          03-concepts/
          04-reference/
          05-troubleshooting/
          06-development/
          07-contributing/
        mdx-components.tsx            # Shared MDX components
        theme.config.tsx              # Nextra theme config
        next.config.mjs
        vercel.json
      ```


      ### Rules


      - Use numeric prefixes for content folders: `00-*`, `01-*`, etc.

      - Use `index.mdx` or `index.md` for section roots.

      - Keep nesting shallow (max 2 levels within a section).

      - Navigation comes from `_meta.json` files in each folder.

      - Add `about.md` at content root for landing info.


      ---


      ## MDX authoring


      ### Frontmatter


      Every page:


      ```markdown

      ---

      description: Quick intro to AlignTrue

      ---


      # Getting started

      ```


      ### Components


      Prefer Nextra components. Re-export them in `mdx-components.tsx` for
      consistency:


      ```jsx

      import { Callout, Cards, Tabs, Steps } from "nextra/components"

      import { Mermaid } from "@theguild/remark-mermaid/mermaid";


      <Callout type="info">This is informational.</Callout>


      <Cards>
        <Cards.Card title="Core" href="/concepts/architecture" />
        <Cards.Card title="CLI" href="/reference/cli" />
      </Cards>


      <Tabs items={["Option 1", "Option 2"]}>
        <Tabs.Tab>Content for option 1</Tabs.Tab>
        <Tabs.Tab>Content for option 2</Tabs.Tab>
      </Tabs>


      <Steps>
        ### Step 1
        Do this first
        ### Step 2
        Do this second
      </Steps>


      <Mermaid>{`graph LR
        A --> B
      `}</Mermaid>

      ```


      ### Guidelines


      - Use semantic MDX, not custom divs.

      - Short sections, concrete examples.

      - No marketing fluff. Neutral and factual, per documentation standards.


      ---


      ## Images and media


      - Use `next/image` in MDX.

      - Always specify width and height.

      - Prefer SVG or small assets.

      - No raw `<img>` without dimensions.


      ```jsx

      import Image from "next/image";

      import hero from "./hero.png";


      <Image src={hero} alt="AlignTrue overview" width={960} height={540}
      priority />;

      ```


      ---


      ## Performance budgets (docs)


      ### Per initial route (gzipped)


      | Type          | Limit    |

      | ------------- | -------- |

      | JavaScript    | ≤ 150 KB |

      | CSS           | ≤ 50 KB  |

      | Single image  | ≤ 200 KB |

      | Fonts (total) | ≤ 150 KB |


      If a change exceeds a budget, explain in the PR and file a follow up.


      ### Web vitals targets (mobile p75)


      - LCP ≤ 2.5 s

      - INP ≤ 200 ms

      - CLS ≤ 0.10

      - TTFB ≤ 800 ms


      Breaking these in production blocks release.


      ---


      ## Vercel deployment


      Single docs app deployed to `aligntrue.ai`.


      ### Setup


      - Use Vercel Development, Preview, Production envs.

      - Never commit `.env*`.

      - Client env vars must start with `NEXT_PUBLIC_`.

      - Document env usage in `documentation.mdc`.


      ### Minimal vercel.json


      Include security headers and redirects for old URLs. Actual config also
      includes:


      - `buildCommand`, `devCommand`, `installCommand` (explicit commands for
      reproducibility)

      - `framework: "nextjs"` (explicit Next.js framework)

      - `regions: ["iad1"]` (specific region for latency)

      - Permanent redirects (`301`) for renamed docs pages

      - Security headers: `X-Frame-Options`, `X-Content-Type-Options`,
      `Referrer-Policy`, `Strict-Transport-Security`


      ```json

      {
        "$schema": "https://openapi.vercel.sh/vercel.json",
        "buildCommand": "pnpm build",
        "framework": "nextjs",
        "redirects": [
          {
            "source": "/quickstart",
            "destination": "/docs/00-getting-started/00-quickstart",
            "permanent": true
          }
        ],
        "headers": [
          {
            "source": "/(.*)",
            "headers": [
              { "key": "X-Frame-Options", "value": "DENY" },
              { "key": "X-Content-Type-Options", "value": "nosniff" },
              {
                "key": "Referrer-Policy",
                "value": "strict-origin-when-cross-origin"
              },
              {
                "key": "Strict-Transport-Security",
                "value": "max-age=31536000; includeSubDomains"
              }
            ]
          }
        ]
      }

      ```


      ### Each PR


      - Must have a Preview URL.

      - Must not depend on Production-only secrets.


      ---


      ## Logging and analytics


      - Use server console logs as structured lines.

      - Keep browser logs minimal and non-sensitive.

      - If using Vercel Analytics, wire it in `app/layout.tsx` once.

      - Configure external log drains only for Production.


      ---


      ## Accessibility


      - Use `plugin:jsx-a11y/recommended` for docs app.

      - All interactive elements keyboard accessible.

      - Respect WCAG AA contrast.

      - Prefer native semantics, minimal `aria-*`.


      Optional Playwright + axe check is encouraged for root and key pages.


      ---


      ## Pre merge checks for docs


      Run from repo root:


      ```bash

      pnpm lint

      pnpm --filter docs build

      ```


      ### Optional


      ```bash

      pnpm --filter docs exec playwright test

      ```


      If checks fail on performance or a11y, note it in the PR with a plan.
    level: 2
    fingerprint: web-stack-nextra-docs
    source_file: .aligntrue/rules/web_stack_nextra_docs.md
    vendor:
      aligntrue:
        frontmatter:
          description:
            Web stack guide for Nextra documentation site (auto-applies in
            apps/docs/)
          nested_location: apps/docs
          content_hash: ee9820763d93577738484fa5ae3df06e24e45bc9b6ebea607ff8e78043789e23
          title: Web Stack Nextra Docs
  - heading: Web Stack Website Catalog
    content: >

      # Web stack guide for homepage/catalog


      **Applies to:** `apps/web/` (marketing homepage + catalog)


      Keep the site fast, accessible, and predictable. Use **vanilla shadcn/ui +
      Tailwind only**—no bespoke CSS, inline styles, or one-off class names that
      override shadcn defaults.


      ---


      ## Core principles


      1. shadcn/ui + Tailwind utilities only. Do not add custom CSS, inline
      styles, or ad-hoc class names that override defaults. Favor utility
      classes and shadcn props.

      2. Mobile-first, accessible by default. Maintain keyboard navigation and
      semantics.

      3. Keep styling semantic: use shadcn color tokens (`primary`, `secondary`,
      `muted`, etc.). Do not hardcode hex values.

      4. Prefer server components; add `"use client"` only when necessary.

      5. Minimize surface area: reuse primitives, avoid new patterns unless
      justified.

      6. If a layout issue appears, first use Tailwind spacing/grid/flex or
      shadcn variants. Do not hide scrollbars or add backdrop/blur/shadow tweaks
      beyond shadcn defaults.


      ---


      ## Tech stack


      - Next.js 16 (App Router), React 19

      - shadcn/ui (style: new-york) with Radix primitives and
      `class-variance-authority`

      - Tailwind CSS with CSS variables (`tailwind.config.js`,
      `app/globals.css`)

      - `next-themes` for dark mode (class strategy)

      - `lucide-react` icons, `next/font` for Plus Jakarta Sans + JetBrains Mono


      ---


      ## Project layout (apps/web)


      - `app/` — layouts, pages, and route handlers (`app/api/**`)

      - `components/` — shared marketing/catalog components

      - `components/ui/` — shadcn primitives (use these first)

      - `lib/` — data utilities, fetchers, transforms

      - `types/` — shared type declarations


      Do not introduce parallel component systems. Extend existing shadcn
      primitives via variants rather than new bespoke components.


      ---


      ## Styling rules (critical)


      - Use only Tailwind utilities and shadcn variants. No new global CSS.
      Existing `globals.css` includes legacy hero styling; do not add more
      custom selectors, animations, or masks. Prefer replacing custom blocks
      with Tailwind utilities when touching those areas.

      - Keep class names semantic and minimal. Do not introduce non-standard
      names to override defaults.

      - Use semantic tokens: `bg-card`, `text-muted-foreground`,
      `border-border`, `bg-primary`, etc. Avoid hardcoded
      colors/shadows/blur/backdrop/opacity hacks.

      - Spacing and layout: Tailwind `flex`, `grid`, `gap`, `space-y/x`,
      `mx/px/py`, `max-w-*`, `min-h-*`. Avoid manual pixel nudges when a utility
      exists.

      - Component elevation: follow the pattern in `components/ui/card.tsx`
      (variants `surface`, `elevated`, `feature`). Add variants via cva, not
      ad-hoc classes.

      - Scroll behavior: do not hide scrollbars; use native overflow utilities
      (`overflow-auto`, `overflow-hidden` only when necessary and justified).


      ---


      ## Component patterns


      - Use shadcn primitives from `components/ui/` (e.g., Button, Card, Tabs,
      Input, Badge, Select).

      - Extend with cva variants (see `card.tsx` for the pattern). Keep variants
      small, named, and semantic.

      - Icons: prefer `lucide-react`, size with utilities or cva defaults
      (`[&_svg]:size-4` pattern in Button). Keep icons decorative unless
      conveying meaning; set `aria-hidden` when appropriate.

      - Buttons: use `variant` and `size` props; avoid inline colors. Use
      `asChild` for links.

      - Tabs, Select, Input: rely on existing styles; do not restyle via custom
      CSS.


      ---


      ## Layout & pages


      - Root layout: `app/layout.tsx` sets fonts and theme provider. Keep it
      minimal; no page-specific styles or scripts here.

      - Pages and sections: use semantic HTML (`section`, `nav`, `header`,
      `main`, `footer`). Include skip links where relevant.

      - Grids and cards: use Tailwind `grid`/`flex` with responsive columns
      (`grid-cols-1 sm:grid-cols-2 lg:grid-cols-3`) and `gap-*`.

      - Content width: cap with `max-w-*` and center with `mx-auto`; avoid
      arbitrary widths.

      - Animations: avoid adding new keyframes or motion; prefer CSS transitions
      on existing shadcn surfaces. If animation is essential, justify and keep
      to Tailwind-friendly patterns.


      ---


      ## Data & APIs


      - Route handlers live under `app/api/**`. Return `Response.json()` for
      JSON. Example: `app/api/aligns/recent/route.ts` with `dynamic =
      "force-dynamic"` for dynamic data.

      - Parse and validate query params defensively (see `parseLimit` pattern);
      cap limits for safety.

      - Client components should fetch via `fetch` with graceful error handling
      and minimal serialized props.


      ---


      ## Theming and colors


      - `next-themes` with `class` strategy; HTML tag has
      `suppressHydrationWarning`.

      - Colors and radius come from CSS variables in `globals.css` and
      `tailwind.config.js`. Always use semantic tokens; do not hardcode
      light/dark values.

      - Respect light/dark contrast. Avoid custom backdrops, blurs, or drop
      shadows beyond shadcn defaults.


      ---


      ## Typography and icons


      - Fonts: `Plus_Jakarta_Sans` (`--font-sans`), `JetBrains_Mono`
      (`--font-mono`) via `next/font` in `app/layout.tsx`. Do not add additional
      web fonts.

      - Use `text-balance`/`text-pretty` sparingly where readability helps.
      Avoid excessive letter/word spacing tweaks.

      - Icons: prefer consistent sizing via utilities (`size-4`/`size-5`) and
      align with flex gaps.


      ---


      ## Images and media


      - Use `next/image` with explicit `width`/`height`. Prefer SVG or small
      assets.

      - Avoid background images and heavy gradients. If needed, use Tailwind
      utilities and semantic colors, not new CSS blocks.

      - Do not lazy-load above-the-fold hero imagery that should be `priority`;
      use sparingly.


      ---


      ## Performance and RSC usage


      - Default to server components; add `"use client"` only when state/effects
      are required.

      - Keep serialized props small; derive data on the server when possible.

      - Use `next/font` for fonts; avoid self-hosted or extra fonts.

      - Avoid adding global scripts. If needed, use `next/script` with
      `strategy`.

      - Budget guidance (mobile p75): LCP ≤ 2.5s, INP ≤ 200ms, CLS ≤ 0.10, TTFB
      ≤ 800ms. Keep per-route JS/CSS lean; avoid new heavy deps.


      ---


      ## Accessibility


      - Provide skip links for `main`. Maintain logical heading order.

      - All interactive elements must be keyboard reachable; use native elements
      or proper ARIA roles.

      - Form controls need labels/aria-label. Buttons should have discernible
      text.

      - Maintain WCAG AA contrast via semantic tokens; do not override with
      low-contrast colors.


      ---


      ## Deployment and config


      - Vercel rewrites in `vercel.json` forward `/docs/*` to docs domain. Keep
      configs minimal and deterministic.

      - Environment variables: never commit secrets. Client vars must be
      `NEXT_PUBLIC_*`.

      - Keep `next.config.mjs` lean; avoid custom webpack unless essential.


      ---


      ## Pre-merge checks


      Run from repo root (or filter):


      ```bash

      pnpm lint

      pnpm --filter web build

      ```


      Add tests only when behavior warrants; avoid snapshotting rendered markup
      unless stable and valuable.


      ---


      ## Prohibited


      - Custom CSS blocks, keyframes, masks, or backdrops beyond existing legacy
      hero styles (do not extend them).

      - Inline styles or ad-hoc class names to override shadcn defaults.

      - Hiding scrollbars or adding blur/shadow tweaks not in shadcn defaults.

      - Adding new fonts or heavy dependencies without justification.
    level: 2
    fingerprint: web-stack-website-catalog
    source_file: .aligntrue/rules/web_stack_website_catalog.md
    vendor:
      aligntrue:
        frontmatter:
          description:
            Web stack guide for the homepage and catalog (auto-applies in
            apps/web/)
          nested_location: apps/web
          content_hash: e57fd37e552bac7880bef10c4884f30d90f15b70726448d4a4c76f3fe8019b5c
          title: Web Stack Website Catalog
