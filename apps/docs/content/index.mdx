---
title: "Introduction"
description: "AlignTrue AI ops platform (alpha) — supervised AI execution with receipts and auditability."
---

# Introduction

> ⚠️ **Alpha:** AlignTrue AI ops platform is in active development. Expect substantial changes while we dogfood the architecture.

AlignTrue is the system of record for AI. Models commoditize, trust doesn't. We lead with receipts and auditability, emphasizing deterministic behavior, envelopes-first design, and rebuildable projections so teams can trust AI outputs.

## What it does

- Separates commands (intent) from events (what happened), with explicit time and causality.
- Stores receipts and artifacts so executions are explainable and replayable.
- Keeps behavior out of the core event log; policies and packs are versioned and testable.

## Current status

- Alpha-quality; APIs and contracts may change.
- Local-first: core flows run without cloud dependencies.
- Dogfooding across tasks/notes; broader capabilities will evolve.

## Learn more

- Architecture: [ops-platform docs](/docs/ops-platform/index)
- Receipts and artifacts: [ops-platform/derived-artifacts](/docs/ops-platform/derived-artifacts)
- Feedback loop: [ops-platform/feedback](/docs/ops-platform/feedback)
- Query artifacts: [ops-platform/query-artifacts](/docs/ops-platform/query-artifacts)
- Work ledger: [ops-platform/work-ledger](/docs/ops-platform/work-ledger)

## Contributing & security

- Security: [policy](/docs/security)
- About: [project background](/docs/about)
