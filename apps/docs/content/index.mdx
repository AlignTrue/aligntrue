---
title: "Introduction"
description: "AlignTrue AI ops platform (beta) — supervised AI execution with receipts and auditability."
---

# Introduction

> ⚠️ **Beta:** AlignTrue AI ops platform is in active development. Expect substantial changes while we dogfood the architecture.

_Note: The AlignTrue Sync tool for managing AI rules was split out to its own repo [here](https://github.com/AlignTrue/aligntrue-sync)_

AlignTrue is the system of record for AI. Models commoditize, trust doesn't. We lead with receipts and auditability, emphasizing deterministic behavior, envelopes-first design, and rebuildable projections so teams can trust AI outputs.

## What it does

- **AI without receipts is a liability.** If you can’t prove what it saw, why it decided, and what it did, you can’t trust it in production.
- **Behavior drift is a death spiral.** Agents copy inconsistency at machine speed; a system of record keeps behavior governable.
- **If you can’t replay it, you can’t run it.** Real operations need auditability, rollback, and deterministic recovery.

## Current status

- Beta-quality; APIs and contracts may change.
- Local-first: core flows run without cloud dependencies.
- Dogfooding across tasks/notes; broader capabilities will evolve.

## Learn more

- Architecture: [/docs/architecture](/docs/architecture)
- Invariants: [/docs/architecture/invariants](/docs/architecture/invariants)
- Trajectories: [/docs/architecture/trajectories](/docs/architecture/trajectories)
- Simulation: [/docs/architecture/simulation](/docs/architecture/simulation)
- Concepts: [/docs/concepts/derived-artifacts](/docs/concepts/derived-artifacts)

## Contributing & security

- Security: [policy](/docs/security)
- About: [project background](/docs/about)
