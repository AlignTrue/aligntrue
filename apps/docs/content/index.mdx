---
title: "Introduction"
description: "AlignTrue AI ops platform (beta) — supervised AI execution with receipts and auditability."
---

# Introduction

> ⚠️ **Beta:** AlignTrue AI ops platform is in active development. Expect substantial changes while we dogfood the architecture.

AlignTrue is the system of record for AI. Models commoditize, trust doesn't. We lead with receipts and auditability, emphasizing deterministic behavior, envelopes-first design, and rebuildable projections so teams can trust AI outputs.

## What it does

- **AI without receipts is a liability.** If you can’t prove what it saw, why it decided, and what it did, you can’t trust it in production.
- **Behavior drift is a death spiral.** Agents copy inconsistency at machine speed; a system of record keeps behavior governable.
- **If you can’t replay it, you can’t run it.** Real operations need auditability, rollback, and deterministic recovery.

## Current status

- Beta-quality; APIs and contracts may change.
- Local-first: core flows run without cloud dependencies.
- Dogfooding across tasks/notes; broader capabilities will evolve.

## Learn more

- Architecture: [ops-platform docs](/docs/ops-platform/index)
- Receipts and artifacts: [ops-platform/derived-artifacts](/docs/ops-platform/derived-artifacts)
- Feedback loop: [ops-platform/feedback](/docs/ops-platform/feedback)
- Query artifacts: [ops-platform/query-artifacts](/docs/ops-platform/query-artifacts)
- Work ledger: [ops-platform/work-ledger](/docs/ops-platform/work-ledger)

## Contributing & security

- Security: [policy](/docs/security)
- About: [project background](/docs/about)
