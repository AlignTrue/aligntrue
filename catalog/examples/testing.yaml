id: "packs/base/base-testing"
version: "1.0.0"
profile: "align"
spec_version: "1"
summary: "Testing baseline: fast, deterministic, useful tests with clear strategy"
tags: ["testing", "quality", "determinism", "paved-road"]
deps: ["packs/base/base-global"]
scope:
  applies_to: ["*"]
  includes: ["**/*.{test,spec}.{ts,tsx,js,jsx,py,rs,go}", "tests/**", "test/**"]
  excludes: ["vendor/**", "node_modules/**", "dist/**"]
rules:
  - id: "test-pyramid-balance"
    severity: "SHOULD"
    check:
      type: "command_runner"
      inputs:
        command: "find tests -type f | grep -c unit | awk '{u=$1} END {if(u<10) exit 1}'"
        expect_exit_code: 0
      evidence: "Test pyramid imbalance: need more unit tests"
    autofix:
      hint: "Add more unit tests; prefer unit over integration over e2e"

  - id: "no-sleeps-in-tests"
    severity: "MUST"
    check:
      type: "regex"
      inputs:
        include: ["**/*.{test,spec}.{ts,tsx,js,jsx,py}"]
        pattern: "(sleep|setTimeout|time\\.sleep|Thread\\.sleep)"
        allow: false
      evidence: "Sleep-based synchronization found in tests"
    autofix:
      hint: "Wait on explicit conditions with timeouts instead"

  - id: "tests-are-fast"
    severity: "SHOULD"
    check:
      type: "command_runner"
      inputs:
        command: "pnpm test --reporter=json | jq '.testResults[].perfStats.runtime' | awk '$1 > 1000 {exit 1}'"
        timeout_ms: 60000
        expect_exit_code: 0
      evidence: "Slow tests found (>1s per test)"
    autofix:
      hint: "Optimize test or use isolated units and local fakes"

  - id: "coverage-threshold"
    severity: "SHOULD"
    check:
      type: "command_runner"
      inputs:
        command: "pnpm test --coverage --coverageThreshold=80"
        timeout_ms: 120000
        expect_exit_code: 0
      evidence: "Coverage below threshold"
    autofix:
      hint: "Add tests for critical paths and public APIs"

  - id: "no-flaky-tests-without-issue"
    severity: "MUST"
    check:
      type: "regex"
      inputs:
        include: ["**/*.{test,spec}.{ts,tsx,js,jsx,py}"]
        pattern: "(skip|xit|xdescribe|@Ignore).*flaky"
        allow: false
      evidence: "Flaky test without issue link"
    autofix:
      hint: "Add issue link or fix/delete the test"

integrity:
  algo: "jcs-sha256"
  value: "1e5e2cc3249503a62c7c7f7b18edf63ba602c9fad2ad212010fb0b7aee744042"

notes: |
  Precedence: complements global, tdd; defers to security

guidance: |
  # Testing Baseline

  ## 5-Question Test Decision

  Before adding a test:
  1. Has this broken in CI or real usage?
  2. Is this a public contract or critical behavior?
  3. Can a unit test prove it deterministically?
  4. Will it remain fast and stable?
  5. Is maintenance worth it?

  ## Test Pyramid

  - Default to unit tests
  - Use integration only for cross-cutting seams
  - Minimal e2e where system seams require it

  ## Determinism Requirements

  - No real network
  - No filesystem side effects
  - No clocks or randomness without fakes
  - Freeze time, seed randomness, stub boundaries
  - No sleeps for sync; wait on conditions with timeouts

  ## Speed Requirements

  - Target sub-second per test
  - Investigate tests >1s
  - Prefer isolated units
  - Use local fakes instead of e2e

  ## Structure

  - Organize by type: unit, integration, e2e
  - One behavioral topic per test file
  - Name files after behavior under test

  ## Assertions

  - Prove behavior, not implementation
  - Prefer public interfaces
  - Observable outcomes

  ## Fixtures

  - Keep small and local
  - Prefer builders/factories
  - Golden files only for stable outputs

  ## External Systems

  - Use fakes or emulators
  - Database, queue, cache, HTTP replaced
  - Isolate true e2e, keep minimal

  ## Flakiness

  - Don't mark flaky by default
  - Quarantine with issue link
  - Short timebox
  - Fix or delete

  ## Coverage

  - Enforce threshold in CI if configured
  - Don't chase 100%
  - Focus on critical paths

  ## CI

  - Block on test failures
  - Publish reports
  - Fail on coverage threshold miss
